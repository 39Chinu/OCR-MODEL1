# An Exact Solver for Maximizing a Submodular Function Subject to a Knapsack Constraint

Sabine Münch, Stephen Raach Trier University, 54286 Trier, Germany {muench / raach}@uni-trier.de

We study the problem of maximizing a monotone increasing submodular function over a set of weighted elements subject to a knapsack constraint.

Although this problem is *NP*-hard, many applications require exact solutions, as approximate solutions are often insufficient in practice.

To address this need, we propose an exact branch-and-bound algorithm tailored for the submodular knapsack problem and introduce several acceleration techniques to enhance its efficiency. We evaluate these techniques on instances of three benchmark problems and compare the proposed solvers to two solvers by Sakaue and Ishihata [\[22\]](#page-25-0), which are considered state-ofthe-art, demonstrating that the presented methods outperform the existing methods.

**Keywords** : *Submodular Maximization, Knapsack Constraint, Branch-and-Bound, Lazy Evaluations, Candidate Reduction*

# **1. Introduction.**

Submodular maximization is a key component of various classical combinatorial optimization problems including graph cuts [see e.g., [11\]](#page-24-0), set cover [see e.g., [6\]](#page-24-1), facility location [see e.g., [4,](#page-24-2) [1\]](#page-23-0), and generalized assignment problems [see e.g., [10,](#page-24-3) [7,](#page-24-4) [9,](#page-24-5) [2\]](#page-23-1).

In addition, submodular maximization plays a crucial role in numerous application domains such as non-parametric learning [see e.g., [19\]](#page-25-1), sensor placement [see e.g., [15,](#page-25-2) [16\]](#page-25-3), data subset selection [see e.g., [27\]](#page-26-0), influence maximization in social networks [see e.g., [14\]](#page-25-4), and extractive document and image summarization [see e.g., [17,](#page-25-5) [25\]](#page-26-1).

**Definition.** *In the following, let I be a finite set of cardinality n* ∈ N*, and f* : 2*<sup>I</sup>* → R≥<sup>0</sup> *be a* submodular *(f*(*X* ∪ {*i*}) − *f*(*X*) ≥ *f*(*Y* ∪ {*i*}) − *f*(*Y* ) *for X* ⊆ *Y* ⊆ *I, i* ∈ *I* \ *Y ),* monotone increasing *(f*(*X*) ≤ *f*(*Y* ) *for any X* ⊆ *Y* ⊆ *I), and* normalized *(f*(∅) = 0*) function. We assume that every i* ∈ *I is associated with a weight w<sup>i</sup>* ∈ R*>*0*, and denote by w*(*X*) := P *<sup>i</sup>*∈*<sup>X</sup> w<sup>i</sup> the weight of a set X* ⊆ *I.*

We consider the classical Submodular Knapsack-Constrained Maximization problem, which is given by

<span id="page-0-0"></span>
$$
\max\{f(X): w(X) \le B, X \subseteq I\},\tag{1}
$$

where *B* ∈ R≥<sup>0</sup> is the knapsack capacity.

**Definition.** *We encode an* instance *of* Submodular Knapsack-Constrained Maximization *by a tuple* (*I, f, w, B*)*, in which w* = (*wi*)*i*∈*<sup>I</sup> is the weight vector, and B* ∈ R≥<sup>0</sup> *is the knapsack capacity. The* set of all instances *of* Submodular Knapsack-Constrained Maximization *is denoted by* I*.*

*For any* (*I, f, w, B*) ∈ I*, we call a set X* ⊆ *I an* optimal solution *if w*(*X*) ≤ *B and f*(*X*) *attains the value given by* [\(1\)](#page-0-0)*.*

There are several well-known results for solving instances of Submodular Knapsack-Constrained Maximization approximately [see e.g., [28,](#page-26-2) [23,](#page-25-6) [24,](#page-25-7) [8\]](#page-24-6). Among these, the algorithm proposed by Sviridenko [\[23\]](#page-25-6) stands out, since it provides an approximation factor of 1 − 1 *<sup>e</sup>* = 0*.*63 *. . .*, which is the best achievable approximation factor unless *P* = *NP*, as shown by Feige [\[6\]](#page-24-1).

However, achieving an approximation guarantee of 1 − 1 *<sup>e</sup>* may not be sufficient in many applications. Therefore, our focus is on the exact solution of the Submodular Knapsack-Constrained Maximization problem.

### **1.1. Results.**

We introduce a basic solver for Submodular Knapsack-Constrained Maximization that queries the objective function *f* via a value oracle. To enhance efficiency, we incorporate several acceleration techniques.

The basic solver is a branch-and-bound algorithm that leverages the submodularity of the objective function to prune nodes effectively. The acceleration methods are inspired by those proposed by Woydt et al. [\[29\]](#page-26-3) for Submodular Capacity-Constrained Maximization, which is a special case of Submodular Cardinality-Constrained Maximization, where all elements have unit weight. However, our methods differ significantly from those of Woydt et al. [\[29\]](#page-26-3), as we must account for a general knapsack constraint with non-unit weights. This places us in a more challenging setting, since Woydt et al. [\[29\]](#page-26-3) did not have to consider weights at all, whereas in our case, the weights of the elements play a crucial role and require special attention.

We evaluate the effectiveness of the proposed techniques on both artificial instances of three benchmark problems and instances based on real-world data and compare them with those methods presented by Sakaue and Ishihata [\[22\]](#page-25-0), which are considered state-ofthe-art. The experimental results show that some of the presented acceleration methods are highly successful and consistently outperform the algorithms by Sakaue and Ishihata [\[22\]](#page-25-0).

### **1.2. Related work.**

Since the Submodular Knapsack-Constrained Maximization problem is NP-hard, previous research has focused primarily on developing approximation algorithms to tackle it. As mentioned above, Sviridenko [\[23\]](#page-25-6) showed that combining partial enumeration with the classical greedy algorithm – originally analyzed by Wolsey [\[28\]](#page-26-2) – achieves a 1 − 1 *e*

approximation of the optimal solution value. Moreover, Feige [\[6\]](#page-24-1) proved that this is the best possible approximation ratio, unless *P* = *NP*.

In addition to these greedy-based approximate optimal solvers for Submodular Knapsack-Constrained Maximization, Chen et al. [\[3\]](#page-23-2) introduced a best-first search algorithm for Submodular Knapsack-Constrained Maximization. This algorithm includes a hyperparameter that controls its approximation guarantee, allowing it to function as an exact solver for Submodular Knapsack-Constrained Maximization. Based on this work, Sakaue and Ishihata [\[22\]](#page-25-0) proposed two accelerated best-first search algorithms, called Umod and Udom, both of which incorporate new termination conditions, with one additionally utilizing a novel heuristic function.

Several exact solvers have been proposed for the special case of Submodular Knapsack-Constrained Maximization, where all elements in the ground set have unit weights, which is the Submodular Cardinality-Constrained Maximization problem. Nemhauser and Wolsey [\[20\]](#page-25-8) introduced two exact methods for solving this problem: a constraint generation algorithm that employs a binary integer linear program with exponentially many constraints and a branch-and-bound algorithm that utilizes linear programming relaxations.

An exact cutting-plane method for Submodular Cardinality-Constrained Maximization, implemented as a binary integer linear program with iterative constraint generation, was introduced by Kawahara et al. [\[13\]](#page-24-7). Uematsu et al. [\[26\]](#page-26-4) enhanced [Nemhauser and Wolsey'](#page-25-8)s constraint generation algorithm by integrating it into a branch-and-cut framework. More recently, Csókás and Vinkó [\[5\]](#page-24-8) improved the solver by Uematsu et al. [\[26\]](#page-26-4) further by introducing alternative constraint generation heuristics and exploiting structural properties of specific problem instances.

Woydt et al. [\[29\]](#page-26-3) introduced a search tree algorithm with an efficient node-pruning heuristic for Submodular Cardinality-Constrained Maximization, along with several acceleration techniques to enhance the search tree algorithm. The basic branchand-bound algorithm and acceleration techniques for solving Submodular Knapsack-Constrained Maximization presented in this paper are motivated by their work, since Submodular Cardinality-Constrained Maximization is a special case of Submodular Knapsack-Constrained Maximization.

### **1.3. Outline.**

In Section [2,](#page-3-0) we introduce a basic branch-and-bound algorithm for Submodular Knapsack-Constrained Maximization, which employs a pruning method based on a linear relaxation of an integer program. We also compare this basic algorithm to a variant that directly solves the linear program using Gurobi.

Next, in Section [3,](#page-7-0) we propose several acceleration techniques for this basic branchand-bound algorithm.

Section [4](#page-13-0) presents our experimental results, where we evaluate the acceleration techniques on three benchmark problems. We also compare the presented algorithms to the solvers Umod and Udom by Sakaue and Ishihata [\[22\]](#page-25-0), which can be considered state-ofthe-art, showing that the presented solvers consistently outperform both. For algorithm comparison, we generated artificial instances following the method of Sakaue and Ishihata [\[22\]](#page-25-0) and also created additional instances using our own approach, aiming to construct more challenging instances than those by Sakaue and Ishihata [\[22\]](#page-25-0). In addition, we evaluate all algorithms on instances based on real-world data.

Section [5](#page-23-3) briefly outlines potential directions for additional acceleration techniques.

# <span id="page-3-0"></span>**2. A basic branch-and-bound algorithm.**

In this section, we present a basic algorithm for Submodular Knapsack-Constrained Maximization. Given an instance (*I, f, w, B*) ∈ I, it iteratively constructs a *search tree*, e.g., a directed graph *T* = (*V, A*), in a depth-first manner.

**Definition.** *A* basic search tree *T* = (*V, A*) *of an instance* (*I, f, w, B*) ∈ I *is a search tree with V* = {*S* : *S* ⊆ *I, w*(*S*) ≤ *B*} *and A* ⊆ {(*S, S* ∪ {*x*}): *S, S* ∪ {*x*} ∈ *V, x* ∈ *I* \ *S*} *such that if* (*S, S* ∪ {*x*})*,*(*S* ∪ {*x*}*, S* ∪ {*x, y*}) ∈ *A, then* (*S, S* ∪ {*y*}) ∈ *A.*

*For any S* ∈ *V , we call C*(*S*) := {*x*: (*S, S* ∪ {*x*}) ∈ *A*} *the* candidate set of *S, and for any* ∅ ̸= *S* ∈ *V , we denote the parent node of S by S P .*

Basic search trees of an instance (*I, f, w, B*) ∈ I will be constructed iteratively as follows: We start with an empty search tree *T* = (∅*,* ∅). The root node ∅ is added to *V* , and the candidate set of the node ∅ is *I*. For every node *S* in the current node set *V* , let the candidate set *C*(*S*) = {*c*1*, . . . , c*|*C*(*S*)|} ⊆ *I* \ *S* be ordered by a fixed permutation. Then, any *S* ∪ {*ci*} with *w*(*S* ∪ {*ci*}) ≤ *B* is added to *V* and its candidate set *C*(*S* ∪ {*ci*}) is set as *C*(*S*) \ {*c*1*, . . . , ci*}. Furthermore, the arc pointing from *S* to *S* ∪ {*ci*} is added to the set of arcs.

The structure of a basic search tree is determined by the permutation of the set *C*(*S*) for any node *S* that is added to *V* . In fact, this choice of the permutation plays a crucial role in the performance of our algorithms.

Basic search trees can be used to determine an optimal solution to any instance (*I, f, w, B*) ∈ I by evaluating the objective function at each node during the search tree's construction and continuously tracking the best solution found so far. It is straightforward that this search procedure returns the optimal solution value, as it evaluates all feasible solutions to the original problem. However, as any basic search tree might have exponentially many (in the number of elements) nodes, it is usually impractical.

As we go along, to avoid visiting each node of any basic search tree, we incorporate a simple pruning test in the iterative construction of a basic search tree that attempts to determine whether any descendant of the current node can improve on the current best-known solution value. If no such improvement is possible, we skip constructing the children of the current node.

### **2.1. A basic pruning method.**

Consider an instance (*I, f, w, B*) ∈ I with a basic search tree *T* = (*V, A*), and any *S* ∈ *V* . To decide whether a node *S* can be pruned, we must determine whether any of its descendants can yield an improvement on the current best-known solution value, denoted as *s* ∗ . In particular, *S* can be pruned if

<span id="page-4-0"></span>
$$
\max_{X \subseteq C(S), w(X) \le B - w(S)} f(S \cup X) \le s^*.
$$
\n(2)

However, this requires solving a submodular knapsack problem, which is NP-hard. Nevertheless, we can prune *S* if we can show that an upper bound on the left hand side of Inequality [\(2\)](#page-4-0) is smaller than or equal to *s* ∗ . To this end, we first define the marginal gain and relative marginal gain of an element *i* ∈ *I*, when added to a set *X* ⊆ *I*.

**Definition.** *Let* (*I, f, w, B*) ∈ I*. For any X, Y* ⊆ *I , we define the* marginal gain of *Y* with respect to *X as f*(*Y* |*X*) := *f*(*Y* ∪ *X*) − *f*(*X*)*. If Y* = {*i*} *for some i* ∈ *I, we write f*(*i*|*X*) *for short. Further, we define the* relative marginal gain *of an element i* ∈ *I with respect to a set X* ⊆ *I as f*(*i*|*X*) *wi .*

By exploiting the submodularity of *f*, we obtain the following upper bound on the left hand side of Inequality [\(2\)](#page-4-0):

$$
\max_{X \subseteq C(S), w(X) \le B - w(S)} f(S \cup X) \le f(S) + \max_{X \subseteq C(S), w(X) \le B - w(S)} \sum_{x \in X} f(x|S). \tag{3}
$$

Notice that the second summand on the right hand side of Inequality [\(3\)](#page-4-1) is the optimal solution to the following integer program:

<span id="page-4-2"></span><span id="page-4-1"></span>
$$
\max \sum_{x \in C(S)} p_x f(x|S)
$$
  
s.t. 
$$
\sum_{x \in C(S)} p_x w_x \le B - w(S),
$$
  
$$
p_x \in \{0, 1\} \text{ for } x \in C(S).
$$
 (4)

The optimal solution value of this integer program is upper bounded by the optimal solution value of the corresponding linear program, in which *p<sup>x</sup>* is relaxed to [0*,* 1], for all *x* ∈ *C*(*S*). In the spirit of this linear program, we define the following:

**Definition.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*)*. For any S* ∈ *V and J* ⊆ *C*(*S*)*, define*

$$
l(S, J) := \max \left\{ \sum_{x \in J} p_x f(x|S) \colon \sum_{x \in J} p_x w_x \le B - w(S), p_x \in [0, 1] \text{ for } x \in J \right\}.
$$

Notice that any value *l*(*S, J*) can be computed efficiently by using a simple greedy algorithm. This greedy algorithm initializes the fractional value *p<sup>x</sup>* of each element *x* ∈ *J* as zero. It then processes the elements in non-increasing order of their relative marginal gain with respect to *S*, setting each *p<sup>x</sup>* to the largest possible value such that the knapsack constraint is still satisfied.

**Definition.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*)*. For any S* ∈ *V and J* ⊆ *C*(*S*)*, the* fractional knapsack value *of S and J is defined by*

$$
FKV(S, J) := f(S) + l(S, J).
$$

Given an instance (*I, f, w, B*) ∈ I, assume that we iteratively construct a basic search tree and proceed as described above to determine an optimal solution during its construction. Let *S* be a node in the basic search tree, and let *s* <sup>∗</sup> be the current best-known solution value. If FKV(*S, C*(*S*)) ≤ *s* ∗ , then, by the definition of FKV, it follows that max*X*⊆*C*(*S*)*,w*(*X*)≤*B*−*w*(*S*) *f*(*S* ∪ *X*) ≤ *s* ∗ , implying that *S* can be pruned. Hence, by incorporating a pruning procedure via FKV into the search process, the resulting solution remains exact.

Recall that the structure of a basic search tree is determined by the permutation of the candidate set *C*(*S*) of any *S* ∈ *V* . A natural choice for the ordering of the candidate sets is the order in which the greedy algorithm described above considers elements.

**Definition.** *Let* (*I, f, w, B*) ∈ I*, S* ⊆ *I, and C* ⊆ *I* \ *S. We call an order* ≺ *on C a* greedy order *with respect to S if for any c, d* ∈ *C with c* ≺ *d, we have*

$$
\frac{f(c|S)}{w_c} \ge \frac{f(d|S)}{w_d}.
$$

*If the set S is clear from context, we refer to* ≺ *simply as a greedy order.*

Note that several greedy orders may exist on a set due to tie-breaking. While it is possible to enforce uniqueness by defining a tie-breaking rule by a permutation of the set, such a restriction is unnecessary in our case; any greedy order will suffice.

In the following, we assume that the candidate set of each node is ordered according to a greedy order. Hence, the first leaf node reached when traversing the basic search tree in a depth-first manner corresponds to the solution produced by the greedy algorithm for Submodular Knapsack-Constrained Maximization, which tries to pack the elements based on their relative marginal gain, until each element is either packed or discarded, as described, e.g., by Tang et al. [\[24\]](#page-25-7). Since Feldman et al. [\[8\]](#page-24-6) showed that the objective value of the solution computed by this greedy algorithm achieves at least a 0*.*427-approximation of the optimal solution, the same guarantee holds for the first leaf node reached.

<span id="page-5-0"></span>The algorithm resulting from ordering each node's candidate set according to a greedy order and incorporating a pruning test based on FKV into the search process is presented in Algorithm [1.](#page-5-0)

#### **Algorithm 1:**

<span id="page-6-1"></span><span id="page-6-0"></span>**Input:** An instance (*I, f, w, B*) ∈ I. **Output:** Optimal objective value *s* ∗ **<sup>1</sup> Function** SearchNode(*S*)**: 2** *s* <sup>∗</sup> ← max{*s* ∗ *, f*(*S*)} **3 if** *C*(*S*) = ∅ **then return** *s* ∗ **4 if** FKV(*S, C*(*S*)) ≤ *s* ∗ **then return** *s* ∗ **<sup>5</sup>** Let *c*1*, . . . , c<sup>k</sup>* be the elements of *C*(*S*) ordered by a greedy order. **6 for** *i* = 1*, . . . , k* **do <sup>7</sup> if** *w*(*S* ∪ {*ci*}) ≤ *B* **then** *s* <sup>∗</sup> ← SearchNode(*S* ∪ {*ci*}) **8 return** *s* ∗ **9 Main: 10** Initialize *s* <sup>∗</sup> ← −∞ **<sup>11</sup> return** SearchNode(∅)

<span id="page-6-2"></span>A natural idea to accelerate Algorithm [1](#page-5-0) is to improve the pruning test in Line [4](#page-6-0) by using a stronger upper bound on the left hand side of Inequality [\(2\)](#page-4-0).

#### **2.1.1. Improving the pruning method in Algorithm [1.](#page-5-0)**

Given an instance (*I, f, w, B*) ∈ I and a node *S* for which SearchNode is called in Algorithm [1,](#page-5-0) Algorithm [1](#page-5-0) uses a pruning test to determine whether any of the descendants of *S* can achieve an improvement over the current best-known solution value *s* ∗ . If no such improvement is possible, Algorithm [1](#page-5-0) avoids considering the descendants of *S*. To improve the performance of Algorithm [1,](#page-5-0) it is therefore an intuitive idea to enhance the quality of the pruning test.

Recall that a node *S* can be pruned if Inequality [\(2\)](#page-4-0) is valid, implying that *S* can be pruned if any upper bound on the left hand side of Inequality [\(2\)](#page-4-0) is smaller than or equal to *s* ∗ . The pruning method used in Algorithm [1](#page-5-0) checks, in every call to SearchNode(*S*), whether FKV(*S, C*(*S*)) ≤ *s* ∗ , where the fractional knapsack value FKV(*S, C*(*S*)) is an upper bound on the left hand side of Inequality [\(2\)](#page-4-0), which is based on the linear relaxation of problem [\(4\)](#page-4-2). Instead of solving this linear relaxation, we could also solve problem [\(4\)](#page-4-2) exactly.

Although problem [\(4\)](#page-4-2) is NP-hard, modern solvers for integer problems with linear objective functions, such as Gurobi, are highly efficient, allowing exact solutions to be found relatively quickly. Therefore, it may be worthwhile to invest the effort in solving problem [\(4\)](#page-4-2) in each call of SearchNode exactly, as this enhances the quality of the pruning test. To this end, we define the following:

**Definition.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*)*. For any S* ∈ *V and J* ⊆ *C*(*S*)*, the knapsack value of S and J is defined by*

$$
KV(S, J) := f(S) + \max \left\{ \sum_{x \in J} p_x f(x|S) : \sum_{x \in J} p_x w_x \le B - w(S), p_x \in \{0, 1\} \text{ for } x \in J \right\}.
$$

Notice that for any instance (*I, f, w, B*) ∈ I and any node *S* in a basic search tree, the upper bound KV(*S, C*(*S*)) is closer to max*X*⊆*C*(*S*)*,w*(*X*)≤*B*−*w*(*S*) *f*(*S* ∪ *X*) than the upper bound FKV, since

$$
\max \left\{ \sum_{x \in C(S)} p_x f(x|S) \colon \sum_{x \in C(S)} p_x w_x \le B - w(S), p_x \in \{0, 1\} \text{ for } x \in C(S) \right\}
$$
  
$$
\le \max \left\{ \sum_{x \in C(S)} p_x f(x|S) \colon \sum_{x \in C(S)} p_x w_x \le B - w(S), p_x \in [0, 1] \text{ for } x \in C(S) \right\}.
$$

Hence, a pruning test based on KV has a higher quality than the one based on FKV, as it is supposed to prune more nodes than the one based on FKV. However, it is currently unclear whether the higher quality of the pruning test based on KV justifies the computational effort required to solve the *NP*-hard problem [\(4\)](#page-4-2) in each call to SearchNode in Algorithm [1.](#page-5-0) To address this question, we modify Algorithm [1,](#page-5-0) by replacing the condition FKV(*S, C*(*S*)) ≤ *s* ∗ in Line [4](#page-6-0) by KV(*S, C*(*S*)) ≤ *s* ∗ . This change applies a pruning test based on KV instead of FKV.

We refer to this modified version of Algorithm [1](#page-5-0) as Algorithm [1](#page-5-0)+. We evaluate the performance of both algorithms in Section [4](#page-13-0) on instances of three benchmark problems. To compute KV(*S, C*(*S*)) in each call to SearchNode in Algorithm [1](#page-5-0)+, we solve problem [\(4\)](#page-4-2) using Gurobi version 12.0.1. We describe our experimental setup and present the results of our experiments in detail in Section [4.](#page-13-0) However, we would like to preemptively highlight here that Algorithm [1](#page-5-0) consistently outperformed Algorithm [1](#page-5-0)<sup>+</sup> in all of our tests. Hence, the improvement in pruning quality achieved by using KV instead of FKV does not justify the effort of solving the *NP*-hard problem [\(4\)](#page-4-2). Consequently, we use Algorithm [1](#page-5-0) as the basic solver in the remainder of this paper.

# <span id="page-7-0"></span>**3. Acceleration techniques.**

In this section, we present three acceleration techniques for Algorithm [1:](#page-5-0) *Lazy Evaluations*, *Early Pruning*, and *Candidate Reduction*. All three aim to reduce computational effort by limiting either expensive objective function evaluations or unnecessary branching during the search.

Lazy Evaluations improve the efficient computation of FKV by selectively avoiding evaluations of the objective function, thereby accelerating the pruning test in Algorithm [1.](#page-5-0) Similarly, Early Pruning seeks to avoid evaluations of the objective function by performing a pruning test as early as possible. If a node cannot be pruned, Candidate Reduction reduces the number of considered descendants of this node by preventing the generation of branches that cannot improve the so far best-known solution value.

### **3.1. Lazy Evaluations**

Given an instance (*I, f, w, B*) ∈ I, Algorithm [1](#page-5-0) uses the fractional knapsack value to determine whether a node *S* in the current call of SearchNode can be pruned. Recall that to compute FKV(*S, C*(*S*)), for any node *S* with candidate set *C*(*S*), we need to solve

$$
l(S, C(S)) = \max\{\sum_{c \in C(S)} p_c f(c|S) : \sum_{c \in C(S)} p_c w(c) \le B - w(S), p_c \in [0, 1] \text{ for } c \in C(S)\}.
$$

As described in Section [2,](#page-3-0) this can be done efficiently using a greedy algorithm that requires comparing *<sup>f</sup>*(*c*|*S*) *wc* for all *c* ∈ *C*(*S*). To possibly reduce computations of (relative) marginal gains, we apply the concept of Lazy Evaluations, introduced by Minoux [\[18\]](#page-25-9), to find approximately optimal solutions for Submodular Knapsack-Constrained Maximization:

In fact, to compute *l*(*S, C*(*S*)) using the greedy algorithm, computing *f*(*c*|*S*) for some element *c* ∈ *C*(*S*) may be avoided if it is known – for example, because an upper bound on *f*(*c*|*S*) is available – that the greedy algorithm reaches a total weight of *B* − *w*(*S*) without considering element *c* for inclusion. The basic idea of Lazy Evaluations is, for *S* ̸= ∅ and some *c* ∈ *C*(*S*), to avoid computing *f*(*c*|*S*) explicitly but using *f*(*c*|*S <sup>P</sup>* ), which is a natural upper bound on *f*(*c*|*S*), as an approximation. To specify for which elements we omit the exact computation of *f*(*c*|*S*), we need the following two definitions:

**Definition.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*)*. For any* ∅ ̸= *S* ∈ *V , we call any function π S* : *C*(*S*) → {0*,* 1} *a* decision function*.*

**Definition.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*)*, and for any* ∅ ̸= *S* ∈ *V , let π S* : *C*(*S*) → {0*,* 1} *be a decision function. Then, for any S* ∈ *V , the function u T S* : *C*(*S*) → R≥0*,*

$$
u_S^T(c) := \begin{cases} f(c) & \text{if } S = \emptyset, \\ \pi^S(c)f(c|S) + (1 - \pi^S(c))u_{S^P}^T(c) & \text{if } S \neq \emptyset, \end{cases}
$$

*is called a* lazy evaluation scheme in *S* on *T, and <sup>u</sup> T S* (*c*) *wc is called the* lazy relative marginal gain *of c with respect to S regarding T. If the context clearly indicates which search tree T we refer to, we use u<sup>S</sup> to represent u T S .*

Given an instance (*I, f, w, B*) with a basic search tree and a node *S* ̸= ∅ with a decision function *π S* , the computation of the marginal gain of an element *c* ∈ *C*(*S*) is avoided if *π S* (*c*) = 0. In this case, a corresponding lazy evaluation scheme inherits the upper bound *u T <sup>S</sup><sup>P</sup>* (*c*) on the marginal gain of *c* from the parent node *S <sup>P</sup>* to the current node *S*.

To formally incorporate the concept of lazy evaluation schemes in Algorithm [1,](#page-5-0) we define the analogous to the fractional knapsack value with respect to a given lazy evaluation scheme.

**Definition.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*)*. For any S* ∈ *V , and any J* ⊆ *C*(*S*)*, we define the* lazy fractional knapsack value *with respect to the lazy evaluation scheme u T S in S on T by*

$$
LV(S, J, u_S^T) := f(S) + \max \left\{ \sum_{c \in J} p_c u_S^T(c) \colon \sum_{c \in J} p_c w(c) \le B - w(S), p_c \in [0, 1], c \in J \right\}.
$$

Algorithm [1](#page-5-0) is exact, and for any lazy evaluation scheme *u T S* in *S* on a basic search tree *T*, we have LV(*S, C*(*S*)*, u<sup>T</sup>* ) ≥ FKV(*S, C*(*S*)). Therefore, Algorithm [1](#page-5-0) remains exact when replacing FKV(*S, C*) with LV(*S, C*(*S*)*, u<sup>T</sup>* ) in Line [4.](#page-6-0) Since the lazy evaluation scheme in a node *S* of a basic search tree *T* depends primarily on the chosen decision function, we specify a decision function that aligns naturally with the lazy fractional knapsack value.

**Definition.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*) *and let k* : *V* → R≥<sup>0</sup> *be a function with k* ≥ *f. For any node* ∅ ̸= *S* ∈ *V , let u T <sup>S</sup><sup>P</sup> be a lazy evaluation scheme in S <sup>P</sup> on T. Then, the* average decision rule *π S* : *C*(*S*) → R≥<sup>0</sup> *is defined by*

$$
\pi^{S}(c) := \begin{cases} 1 & \text{if } \frac{u_{S}^{T}p(c)}{w_{c}} \ge \frac{k(S)-f(S)}{B-w(S)}, \\ 0 & otherwise. \end{cases}
$$

In our modification of Algorithm [1,](#page-5-0) the lazy evaluation scheme uses the average decision rule with *k*(*S*) = *s* ∗ in each call to SearchNode. Hence, the calculation of the marginal gain *f*(*c*|*S*), for some *c* ∈ *C*(*S*), in the call SearchNode(*S*), is avoided when the lazy relative marginal gain of *c* with respect to *S <sup>P</sup>* is smaller than or equal to the average relative marginal gain required for any element in *C*(*S*) to potentially improve the current best-known solution value *s* ∗ in any descendant of *S*.

Furthermore, we modify Algorithm [1](#page-5-0) by ordering the candidate set *C*(*S*) in each call to SearchNode(*S*) according to the "lazy" equivalent of a greedy order.

**Definition.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*) *and S* ∈ *V . For any lazy evaluation scheme u T S , we call an order* ≺ *on C*(*S*) *a u T S* -greedy order *if for any c, d* ∈ *C*(*S*) *with c* ≺ *d, we have*

$$
\frac{u_S^T(c)}{w_c} \ge \frac{u_S^T(d)}{w_d}.
$$

Notice that in general, for any node *S* in a decision tree *T*, a greedy order on the candidate set *C*(*S*) does not coincide with a *u T S* -greedy order on *C*(*S*).

In summary, the modification of Algorithm [1](#page-5-0) to incorporate Lazy Evaluations is achieved by replacing Lines [4](#page-6-0) and [5](#page-6-1) with

**4 LE if** LV(*S, C*(*S*)*, uS*) ≤ *s* ∗ **then return** *s* ∗ **5 LE** Let *c*1*, . . . , c<sup>k</sup>* be the elements of *C*(*S*) ordered by a *uS*-greedy order.

### **3.2. Early Pruning.**

Given an instance (*I, f, w, B*) ∈ I with a basic search tree *T* = (*V, E*), the idea behind Lazy Evaluations is to accelerate the pruning test in Line [4](#page-6-0) of Algorithm [1](#page-5-0) by avoiding the computation of each marginal gain *f*(*c*|*S*), with ∅ ̸= *S* ∈ *V* and *c* ∈ *C*(*S*). Instead, it is substituted by an upper bound.

Similarly, Early Pruning aims to reduce the number of computations of marginal gains. However, unlike Lazy Evaluation, Early Pruning does not aim to replace the marginal gains with an upper bound. Instead, as the name Early Pruning suggests, it aims to perform a pruning test earlier than in Algorithm [1,](#page-5-0) specifically while ordering the elements in the candidate set *C*(*S*) of a node *S* ̸= ∅ by a greedy order.

In any call SearchNode(*S*) in Algorithm [1,](#page-5-0) we let, in Line [4,](#page-6-0) be *c*1*, . . . , c<sup>k</sup>* the elements of *C*(*S*) ordered by a greedy order. In practice, we order the candidate set *C*(*S*) iteratively by considering each element *c<sup>i</sup>* ∈ *C*(*S*), computing its marginal gain *f*(*c<sup>i</sup>* |*S*), and inserting it into the correct position within the current partial greedy ordering of the previously considered elements {*c*1*, . . . , ci*−1}.

To avoid computing marginal gains *f*(*c*|*S*) for *c* ∈ *C*(*S*), we incorporate a pruning test into the iterative calculation of the marginal gains, based on the marginal gains computed in earlier iterations and the marginal gains *f*(*c*|*S <sup>P</sup>* ) with respect to the parent node *S <sup>P</sup>* of all *c* ∈ *C*(*S*).

<span id="page-10-0"></span>**Theorem 1.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*) *and let k* : *V* → R≥<sup>0</sup> *be a function with k* ≥ *f. Let* ∅ ̸= *S* ∈ *V and let U* = {*c*1*, . . . , ci*}*, with i* ≤ |*C*(*S*)|*, be a subset of C*(*S*) *that is ordered according to a greedy order and satisfies w*(*U*) ≥ *B* −*w*(*S*) *and* FKV(*S, U*) ≤ *k*(*S*)*. Further, let j* <sup>∗</sup> = min{*j* ∈ {1*, . . . , i*}: *w*({*c*1*, . . . , cj*}) ≥ *B* − *w*(*S*)} *with <sup>f</sup>*(*cj*<sup>∗</sup> <sup>|</sup>*S*) *wcj*<sup>∗</sup> ≥ max{ *f*(*c*|*S <sup>P</sup>* ) *wc* : *c* ∈ *C*(*S*) \ *U*}*.*

*Then, for any X* ⊆ *C*(*S*) *with w*(*X*) ≤ *B* − *w*(*S*)*, we have*

$$
f(S \cup X) \le k(S).
$$

*Proof.* Since *f* is a monotone increasing function, we have, for each *c* ∈ *C*(*S*) \ *U*,

$$
\frac{f(c_{j^*}|S)}{w_{c_{j^*}}} \ge \frac{f(c|S^p)}{w_c} \ge \frac{f(c|S)}{w_c},
$$

and, by *j* <sup>∗</sup> = min{*j* ∈ {1*, . . . , i*}: *w*({*c*1*, . . . , cj*}) ≥ *B* − *w*(*S*)}, this directly implies FKV(*S, U*) = FKV(*S, C*(*S*)).

Assume that there exists a set *X* ⊆ *C*(*S*) with *w*(*X*) ≤ *B*−*w*(*S*) and *f*(*S*∪*X*) *> k*(*S*). Then, we have

$$
f(S \cup X) > k(S) \geq \text{FKV}(S, U) = \text{FKV}(S, C(S)) = f(S) + l(S, C(S))
$$
  
$$
\geq \max_{Y \subseteq C(S), w(Y) \leq B - w(S)} f(S \cup Y),
$$

which yields a contradiction and thereby proves the claim.

Theorem [1](#page-10-0) provides a straightforward method for applying a pruning test during the iterative ordering of the candidate set *C*(*S*) of a node *S* ̸= ∅. To incorporate this pruning test into each call of SearchNode, a natural choice is to set *k*(*S*) = *s* ∗ for every node *S* where SearchNode is invoked, with *s* <sup>∗</sup> denoting the best-known objective value in the current call SearchNode(*S*). Accordingly, we define:

**Definition.** *Let* (*I, f, w, B*) ∈ I *with basic search tree T* = (*V, A*)*. Let* ∅ ̸= *S* ∈ *V be a node* SearchNode *is called for in Algorithm [1](#page-5-0) and let s* ∗ *be the best-known objective value* *in the call* SearchNode(*S*)*. Further, let U* ⊆ *C*(*S*)*. If S and U satisfy the conditions in Theorem [1](#page-10-0) with k*(*S*) = *s* ∗ *, we say that S and U satisfy the early pruning conditions.*

*If S and U only satisfy w*(*U*) ≥ *B* − *w*(*S*) *and <sup>f</sup>*(*cj*<sup>∗</sup> <sup>|</sup>*S*) *wcj*<sup>∗</sup> ≥ max{ *f*(*c*|*S <sup>P</sup>* ) *wc* : *c* ∈ *C*(*S*) \ *U*}*, where j* <sup>∗</sup> = min{*j* ∈ {1*, . . . , i*}: *w*({*c*1*, . . . , cj*}) ≥ *B*−*w*(*S*)}*, but not* FKV(*S, U*) ≤ *k*(*S*)*, we say that S and U satisfy the early no-pruning conditions.*

Consider an instance (*I, f, w, B*) ∈ I with basic search tree *T* = (*V, E*). Let ∅ ̸= *S* ∈ *V* be a node and let {*c*1*, . . . , ci*} ⊂ *C*(*S*). If *S* and {*c*1*, . . . , ci*} satisfy the early pruning conditions, it follows by Theorem [1,](#page-10-0) that we can prune node *S* without calculating the marginal gains *f*(*c*|*S*) for *c* ∈ *C*(*S*) \ {*c*1*, . . . , ci*}.

If *S* and {*c*1*, . . . , ci*} satisfy the early no-pruning conditions, it follows directly that FKV(*S,* {*c*1*, . . . , ci*}) = FKV(*S, C*(*S*)) *> s*<sup>∗</sup> . Therefore, *S* cannot be pruned, and the early pruning conditions cannot be satisfied for any subset of *C*(*S*); thus, there is no need to check them for any further subset of *C*(*S*).

To incorporate a pruning test based on the early pruning conditions (and the early no-pruning conditions) into Algorithm [1,](#page-5-0) we replace Lines [4](#page-6-0) and [5](#page-6-1) in each call to SearchNode(*S*), with *S* ̸= ∅, by the following:

<span id="page-11-1"></span><span id="page-11-0"></span>

| 4       | P .<br>EP Let<br>c1, , ck<br>be the elements of<br>C(S)<br>ordered by a greedy order w.r.t.<br>S |
|---------|--------------------------------------------------------------------------------------------------|
| 5       | EP for<br>i<br>= 1, , k<br>do                                                                    |
| EP<br>6 | f(ci S)<br>Compute<br>wi                                                                         |
| EP<br>7 | Insert<br>ci<br>into a correct position within the elements<br>c1, , ci−1<br>ordered by a        |
|         | greedy order w.r.t.<br>S.                                                                        |
| EP<br>8 | ∗<br>if<br>S<br>and<br>{c1, , ci}<br>satisfy the early pruning conditions<br>then return<br>s    |
| EP<br>9 | else if<br>S<br>and<br>{c1, , ci}<br>satisfy the early no-pruning conditions<br>then break       |

**<sup>10</sup>EP** Let *c*1*, . . . , c<sup>k</sup>* be the elements of *C*(*S*) ordered by a greedy order w.r.t. *S*.

<span id="page-11-2"></span>Notice that in Line 4[EP](#page-11-0), the elements of *C*(*S*) are ordered according to a greedy order with respect to *S <sup>P</sup>* . This ordering ensures that, in each iteration *i* ∈ {1*, . . . , k*} of the for-loop in Line 5[EP](#page-11-1), we can check whether the conditions for early pruning or early no-pruning are satisfied without explicitly computing the maximum relative marginal gain of adding an element from *C*(*S*) \ {*c*1*, . . . , ci*} to *S <sup>P</sup>* , since this maximum is always attained by the next element *ci*+1 in the order. Moreover, the elements in *C*(*S*) are already ordered by a greedy order with respect to *S <sup>P</sup>* during the call to SearchNode(*S <sup>P</sup>* ), so no additional sorting is required in Line 4[EP](#page-11-0).

Further, observe that if the for-loop in Line 5[EP](#page-11-1) runs to completion, the elements in *C*(*S*) are already ordered by a greedy order with respect to *S*, and in Line [10](#page-11-2)EP no further computations are needed.

### **3.3. Candidate Reduction.**

Given an instance (*I, f, w, B*) ∈ I, and a node *S* in a basic search tree that cannot be pruned in Algorithm [1,](#page-5-0) we aim to avoid considering all children of *S*. We only wish to explore children (and their descendants) that may lead to an improvement over the currently best-known solution value. To this end, we assume in the following that each node *S* in a basic search tree is associated not only with a candidate set *C*(*S*), but also with a subset of *C*(*S*) called *reduction set*.

**Definition.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*)*, and let k* : *V* → R≥<sup>0</sup> *be a function with k* ≥ *f. Then, the* reduction set *of S with respect to k is defined as*

$$
R^k(S) := \{c \in C(S) \colon f(c|S) + \text{FKV}(S, C(S) \setminus \{c\}) \le k(S)\}.
$$

An element *r* ∈ *C*(*S*) is contained in *R<sup>k</sup>* (*S*) if the marginal gain *f*(*r*|*S*) plus the fractional knapsack value of *S* and *C*(*S*) \ {*r*} is less than or equal to *k*(*S*).

We demonstrate that for any *r* ∈ *R<sup>k</sup>* (*S*), there exists no set *X* ⊆ *C*(*S*) \ {*r*} such that *S* ∪ {*r*} ∪ *X* is a feasible solution with objective value greater than *k*(*S*).

<span id="page-12-0"></span>**Theorem 2.** *Let* (*I, f, w, B*) ∈ I *with a basic search tree T* = (*V, A*) *and let k* : *V* → R≥<sup>0</sup> *be a function with k* ≥ *f. Let S* ∈ *V and r* ∈ *R<sup>k</sup>* (*S*)*. Then, for any X* ⊆ *C*(*S*) \ {*r*} *with w*(*X*) ≤ *B* − *w*(*S* ∪ {*r*})*, we have*

$$
f(S \cup \{r\} \cup X) \le k(S).
$$

*Proof.* Assume that there exists a set *X* ⊆ *C*(*S*) \ {*r*} with *w*(*X*) ≤ *B* − *w*(*S* ∪ {*r*}) and *f*(*S* ∪ {*r*} ∪ *X*) *> k*(*S*). Then, we have

$$
f(S \cup X) \geq f(S \cup \{r\} \cup X) - f(S \cup \{r\}) + f(S)
$$
  
submodularity  
$$
\geq k(S) - f(r|S) \geq \text{FKV}(S, C(S) \setminus \{r\}),
$$
  
assumption

which yields a contradiction by the definition of FKV. This concludes the proof.

Given an instance (*I, f, w, B*), suppose that for every *S* ∈ *V* , the value *k*(*S*) is a *lower* bound on the optimal objective value of (*I, f, w, B*). Then, by Theorem [2,](#page-12-0) it follows that for any *S* ∈ *V* and any *r* ∈ *R<sup>k</sup>* (*S*), the subtree rooted at *S* ∪ {*r*} can be pruned, since the lower bound *k*(*S*) on the optimal objective value cannot be exceeded by the objective value of *S*∪{*r*} or any of its descendants. To exclude as many children of *S* and their descendants from consideration as possible, we aim to choose *k*(*S*) to be a lower bound on the optimal objective value that is as large as possible. Since *s* ∗ represents the best-known objective value in each call of SearchNode, and is itself a lower bound on the optimal objective value, a natural choice is to set *k*(*S*) = *s* ∗ for every *S* where SearchNode is invoked. We refer to this approach as Candidate Reduction, and for the reduction set of a node *S* resulting from this particular choice of *k*, we write *R*(*S*).

To incorporate Candidate Reduction into Algorithm [1,](#page-5-0) we replace in each call to SearchNode(*S*), with *S* ̸= ∅, Lines [4](#page-6-0) and [7](#page-6-2) with

**4CR if** FKV(*S, C*(*S*) \ *R*(*S <sup>P</sup>* )) ≤ *s* ∗ **then return** *s* ∗ **<sup>7</sup>CR if** *w*(*S* ∪ {*ci*}) ≤ *B and c<sup>i</sup>* ̸∈ *R*(*S*) **then** *s* <sup>∗</sup> ← SearchNode(*S* ∪ {*ci*})

We refer to the algorithm resulting from these modifications as CR.

Notice that reduction sets in CR are inherited by descendant nodes. Specifically, let *S* be a node for which SearchNode is called in CR. Then, any element *r* ∈ *R*(*S*) is also contained in the reduction set *R*(*S* ′ ) of any child *S* ′ of *S* if *r* ∈ *C*(*S* ′ ). Hence, when calling SearchNode(*S*) in CR for a node *S* ̸= ∅, it is sufficient to check if FKV(*S, C*(*S*) \ *R*(*S <sup>P</sup>* )) ≤ *s* ∗ to prune *S*.

# <span id="page-13-0"></span>**4. Experiments.**

In this section, we present the results of our computational experiments. We evaluate the performance of our basic algorithm (Algorithm [1\)](#page-5-0) and its variation Algorithm [1](#page-5-0)+, as well as the accelerated variants of Algorithm [1,](#page-5-0) which incorporate Lazy Evaluations (LE), Early Pruning (EP), Candidate Reduction (CR), and a combination of Lazy Evaluations and Candidate Reduction (LE+CR), on instances of three benchmark problems.

To ensure a comprehensive comparison, we additionally conduct all tests using the solvers Umod and Udom by Sakaue and Ishihata [\[22\]](#page-25-0), which can be considered state-of-theart. Briefly described, the solvers Umod and Udom are both *best-first search* algorithms that, given an instance (*I, f, w, B*) ∈ I, explore a corresponding basic search tree. Both solvers rely on heuristic functions to determine which node *S* in a basic search tree should be considered next. Umod employs a heuristic which is closely related to FKV, while Udom utilizes a more complex heuristic based on a greedy algorithm for Submodular Knapsack-Constrained Maximization. For details about both algorithms, we refer to Sakaue and Ishihata [\[22\]](#page-25-0).

### **4.1. Experimental setup and data.**

All algorithms are implemented in C++ using the C++17 standard. The code is compiled with GCC version 13.3.0, using the -O2 flag to optimize for efficient machine code. To solve the linear integer problem [\(4\)](#page-4-2) in each call to SearchNode in Algorithm [1](#page-5-0)+, we use Gurobi version 12.0.2. All experiments were conducted on a workstation with an AMD EPYC 7552 processor (48 cores, 2.2 GHz base frequency) and 503 GiB of RAM.

In line with Sakaue and Ishihata [\[22\]](#page-25-0), we report computational results for the following well-known benchmark problems:

(a) Weighted Coverage (COV). Let *I* = {1*, . . . , n*} and *E* = {1*, . . . , m*} be a ground set of elements, with *m, n* ∈ N. Further, let {*E<sup>i</sup>* : *E<sup>i</sup>* ⊆ *E, i* ∈ *I*} be a set of subsets of *E*. Each element *e* ∈ *E* is associated with a value *v<sup>e</sup>* ≥ 0 and each *i* ∈ *I* costs *w<sup>i</sup> >* 0. The Weighted Coverage problem consists of selecting a subset of *I* with total costs less than or equal to a given budget *B* to maximize the weighted coverage function

$$
f\colon 2^I\to \mathbb{R}_{\geq 0}, X\mapsto \sum_{e\in \bigcup_{i\in X}E_i}v_e.
$$

(b) Facility Location (LOC). Let *I* = {1*, . . . , n*} be a set of locations and *M* = {1*, . . . , m*} be a set of customers, with *n, m* ∈ N. Each location *i* is associated with some costs *w<sup>i</sup> >* 0, and *vij* ≥ 0 is the benefit that customer *j* attains from a facility in location *i*. For a subset *X* ⊆ *I* of locations, each customer attains the benefit from the facility in the most beneficial location. The objective is to select a subset of locations whose total cost does not exceed a budget *B* ≥ 0, to maximize the total benefit of all customers, which is given by

$$
f: 2^I \to \mathbb{R}_{\geq 0}, X \mapsto \sum_{j \in M} \max_{i \in X} v_{ij}.
$$

(c) Bipartite Influence (INF). Let *I* = {1*, . . . , n*} be a set of sources and *M* = {1*, . . . , m*} be a set of targets, with *n, m* ∈ N. Given a bipartite directed graph *G* = (*I* ∪ *M, A*), where *A* ⊆ *I* × *M* is a set of arcs, we consider an influence maximization problem on *G*. The probability that a target *j* ∈ *M* is activated by a set *X* ⊆ *I* is 1 − Q *<sup>i</sup>*∈*<sup>X</sup>* : (*i,j*)∈*A*(1 − *pi*), where 0 ≤ *p<sup>i</sup>* ≤ 1 is the activation probability of source *i* ∈ *I*. Every source *i* ∈ *I* is associated with activation costs *w<sup>i</sup> >* 0. The goal is to select a set of sources with total costs less than or equal to a given budget *B* ≥ 0 to maximize the expected number of activated targets, which is formally defined by

$$
f: 2^I \to \mathbb{R}_{\geq 0}, X \mapsto \sum_{j \in M} \left(1 - \prod_{i \in X \colon (i,j) \in A} (1 - p_i)\right).
$$

#### **4.1.1. Artificial instances.**

For each of the problems, we construct 100 artificial instances following the methodology by Sakaue and Ishihata [\[22\]](#page-25-0). Hence, we set *n* = 100 and *m* = 1000 for each *n* and *m* appearing in the definitions of COV, LOC, and INF. We set the budget to *B* = 1 in all instances of all problems and draw the costs, in each instance of each problem, from a uniform distribution on [0*.*01*,* 1]. Note that Sakaue and Ishihata [\[22\]](#page-25-0) originally draw the costs from a uniform distribution on [0*.*0*,* 1]. However, we adjusted this distribution to avoid division by zero and the resulting issues with undefined expressions. For COVinstances, we draw the values of the elements in the ground set *E* from the uniform distribution on [0*,* 1] and each subset *E<sup>i</sup>* ⊆ *E*, as defined in COV, includes each element of the ground set with probability 0*.*3. For LOC-instances, we draw the benefit customer *j* attains from a facility in location *i* independently from a uniform distribution over [0*,* 1]. For INF-instances, we randomly draw the activation probabilities for each source from a uniform distribution on [0*,* 1], and an arc (*i, j*) from source *i* to target *j* is constructed randomly with probability 0*.*3. For all tests, we set the time limit to one hour.

### **4.1.2. Discussion of the artificial instances constructed following Sakaue and Ishihata [\[22\]](#page-25-0).**

We constructed artificial test instances following the methodology used by Sakaue and Ishihata [\[22\]](#page-25-0). However, we have reservations about these construction methods, as they seem to favor constructing instances that are inherently 'easy' to solve. Therefore, we further examine how instances of the benchmark problems are constructed by Sakaue and Ishihata [\[22\]](#page-25-0), outline our concerns with the current approach, and suggest an alternative method for constructing these instances.

We first analyze the construction of COV-instances by Sakaue and Ishihata [\[22\]](#page-25-0) in detail. In the following, let *I* = {1*, . . . ,* 100} and *E* = {1*, . . . ,* 1000} be the sets from the definition of COV as set by Sakaue and Ishihata [\[22\]](#page-25-0). Since Sakaue and Ishihata [\[22\]](#page-25-0) draw each value of an element in the ground set *E* from a uniform distribution on [0*,* 1] (in our case from [0*.*01*,* 1]), and each subset *E<sup>i</sup>* ⊆ *E*, with *i* ∈ *I*, includes each element from the ground set with probability 0*.*3, the expected value of the weighted coverage function, for each *i* ∈ *I*, is 150. Since Sakaue and Ishihata [\[22\]](#page-25-0) draw the costs of each *i* ∈ *I* independently of the weighted coverage function values from a uniform distribution on [0*,* 1], elements *i* ∈ *I* with low costs often have relatively high coverage function values, making them more likely to be included in an optimal solution than elements with higher costs. Hence, an optimal solution for such a COV-instance consists, in expectation, almost exclusively of elements *i* ∈ *I* with low costs. Consequently, elements with greater costs can essentially be ignored when searching for an optimal solution. Moreover, this biased structure of the coverage instances favors greedy algorithms for submodular maximization, which are likely to yield objective values that closely approximate the optimal objective value. At the same time, this structure causes the fractional knapsack value FKV, and similarly the lazy fractional knapsack value LV, to be relatively close to the knapsack value KV of nearly every node and associated candidate set, considered by the proposed algorithms. This significantly strengthens the performed pruning tests. The same holds for the heuristics used in the algorithms Umod and Udom, to determine which node in a basic search tree should be considered next. For these reasons, we assume that the COV-instances, which are constructed according to the method by Sakaue and Ishihata [\[22\]](#page-25-0), are relatively 'easy' to solve.

The construction of LOC- and INF-instances, as performed by Sakaue and Ishihata [\[22\]](#page-25-0), exhibits issues similar to the construction of COV-instances. In the LOC-instances, the benefit of each customer *j* to be served by a facility in location *i* is drawn uniformly from [0*,* 1], and all costs are drawn uniformly from [0*,* 1] ([0*.*01*,* 1] respectively). This introduces a structural bias in the LOC-instances, similar to that in the COV-instances, leading to the same effects, since locations with lower costs tend to have disproportionately high objective function values. The same applies to the INF-instances, since the activation probabilities of the sources are drawn uniformly from [0*,* 0*.*1], an arc from source *i* to target *j* is constructed with probability 0*.*3, and, independently of both the activation probabilities and the edge construction, the activation costs for the sources are drawn from [0*,* 1] ([0*.*01*,* 1] respectively).

To compensate for these issues in our empirical test, we construct 100 new instances for each of the three problems as follows:

For COV, we set *n* and *m* appearing in the definition to *n* = 150 and *m* = 1000. We draw the cost of an element *i* ∈ *I* = {1*, . . . ,* 150} from a uniform distribution on [0*.*1*,* 1] and set the budget to *B* = 5. The value of each element in the ground set *E* is drawn from a uniform distribution on [0*,* 1] and each subset *E<sup>i</sup>* ⊆ *E*, with *i* ∈ *I*, includes each element from the ground set with probability *<sup>w</sup><sup>i</sup>* <sup>10</sup> , where *w<sup>i</sup>* refers to the costs associated with the element *i* ∈ *I*. Hence, the number of elements contained in a subset *E<sup>i</sup>* , with *i* ∈ *I*, is no longer independent of the costs associated with *i*. If *i* ∈ *I* is associated with higher costs, the subset *E<sup>i</sup>* ⊆ *E* has a higher probability of containing elements from the ground set *E* than those subsets *E<sup>j</sup>* , with *j* ∈ *I*, where *j* has lower costs. Consequently, in expectation, all elements *i* ∈ *I* exhibit similar marginal gains, making the COV-instances more difficult to solve.

For LOC-instances, we set the number of locations to *n* = 200 and the number of customers to *m* = 1000. We sample the cost of each location *i* from a uniform distribution on [0*.*1*,* 1], and for each customer, we draw the benefit they receive from a facility in location *i* from a uniform distribution on [0*,* 2*w<sup>i</sup>* ], where *w<sup>i</sup>* is the cost of location *i*. We set the budget to *B* = 6.

For INF-instances, we set the number of targets to *n* = 150 and the number of sources to *m* = 1000. We draw the costs of each source from a uniform distribution on [0*.*1*,* 1] and the activation probability from a uniform distribution on [0*,* 1]. We construct an arc from source *i* to target *j* randomly with probability *<sup>w</sup><sup>i</sup>* 5 , where *w<sup>i</sup>* refers to the costs associated with source *i*. We set the budget to *B* = 5. As before, we set the time limit for all tests to one hour.

#### **4.1.3. Instances based on real-world data.**

Beyond the tests on artificially constructed instances, we also evaluate all algorithms on COV- and INF-instances generated from real-world data.

For COV, we generated an instance based on real-world data using the Facebook-like Forum Network (weighted by the number of messages) dataset on message exchanges among 899 users across 522 topics, as provided by Opsahl [\[21\]](#page-25-10) and also used by Sakaue and Ishihata [\[22\]](#page-25-0). This dataset contains information about which users post messages on which topics, as well as a metric based on the number of messages that reflects the importance of a topic to a user. According to the definition of COV, we define the set of users as *I* = {1*, . . . ,* 899} and the set of topics as *E* = {1*, . . . ,* 522}. A topic *e* ∈ *E* is included in the set *E<sup>i</sup>* , with *i* ∈ *I*, if user *i* has posted messages on topic *e* (i.e., user *i* covers topic *e*). The value of a topic *e* is defined as the sum of the importance metrics of all users who post on that topic. The cost of a user *i* is given by the ratio of the number of topics that user *i* posts messages on to the total number of topics multiplied by 100. We set the budget to *B* = 2.

To generate an INF-instance based on real-world data, we use the MovieLens 100K dataset by Harper and Konstan [\[12\]](#page-24-9), which was also employed by Sakaue and Ishihata [\[22\]](#page-25-0) for this purpose. The dataset contains ratings on a scale from 1 to 5, provided by 943 users for 1682 movies. Following the definition of INF, we define the set of sources as the set of movies, *I* = {1*, . . . ,* 1682}, and the set of targets as the set of users, *M* = {1*, . . . ,* 943}. An arc from movie *i* to user *j* exists if user *j* has rated movie *i*. The activation probability *p<sup>i</sup>* of movie *i* is set to its average rating divided by 10. The activation cost of a movie *i* is defined as 2*p<sup>i</sup>* , and the budget is set to *B* = 7*.*5. For both real-world data instances, we round costs, benefits, and activation probabilities to two decimal places.

### **4.2. Results of the comparison.**

First, we evaluate the performance of the basic solver (Algorithm [1\)](#page-5-0) and its variant with enhanced pruning (Algorithm [1](#page-5-0)+) on the artificially generated instances. We compare them based on three metrics: the number of instances solved within a 1-hour time limit, the average running time across all solved instances, and the average number of nodes considered during the solution process.

Table [1](#page-17-0) presents the results of these tests on all instances generated according to the methodology described by Sakaue and Ishihata [\[22\]](#page-25-0), while Table [2](#page-17-1) shows the results for instances generated using our methodology. In both tables, the values in parentheses represent the average running time and average number of considered nodes for Algorithm [1,](#page-5-0) taken over the subset of instances successfully solved by both algorithms. If a solver cannot solve any instance of a benchmark problem within the given time limit, we indicate this with '/'.

|     |         | solved | time (s)       | nodes            |
|-----|---------|--------|----------------|------------------|
| COV | Alg. 1  | 100    | 155.11 (14.26) | 1290204 (120071) |
|     | Alg. 1+ | 42     | 1741.86        | 95464            |
| LOC | Alg. 1  | 100    | 24.05 (7.44)   | 284023 (109474)  |
|     | Alg. 1+ | 69     | 1589.86        | 80491            |
| INF | Alg. 1  | 100    | 14.24 (10.63)  | 59970 (43424)    |
|     | Alg. 1+ | 96     | 820.9          | 36082            |

<span id="page-17-0"></span>Table 1: Number of solved instances, average computation time (s), and average number of processed nodes for Algorithm [1](#page-5-0) and [1](#page-5-0)<sup>+</sup> on artificial COV-, LOC-, and INFinstances generated following Sakaue and Ishihata [\[22\]](#page-25-0).

|     |         | solved | time (s)         | nodes            |
|-----|---------|--------|------------------|------------------|
| COV | Alg. 1  | 41     | 1898.53          | 155778623        |
|     | Alg. 1+ | /      | /                | /                |
| LOC | Alg. 1  | 72     | 2529.53          | 7139023          |
|     | Alg. 1+ | /      | /                | /                |
| INF | Alg. 1  | 37     | 2123.91 (157.88) | 2408375 (141316) |
|     | Alg. 1+ | 2      | 1977.43          | 122309           |

<span id="page-17-1"></span>Table 2: Number of solved instances, average computation time (s), and average number of processed nodes for Algorithm [1](#page-5-0) and [1](#page-5-0)<sup>+</sup> on artificial COV-, LOC-, and INFinstances generated following our methodology.

As mentioned in Section [2,](#page-3-0) Algorithm [1](#page-5-0) consistently outperforms Algorithm [1](#page-5-0)<sup>+</sup> in all our tests. It solves more instances, both those generated using the method by Sakaue and Ishihata [\[22\]](#page-25-0) and those generated using our approach, and does so in less time. Although Algorithm [1](#page-5-0)<sup>+</sup> examines fewer nodes, it is overall less effective. The fact that Algorithm [1](#page-5-0)<sup>+</sup> considers fewer nodes than Algorithm [1](#page-5-0) provides empirical evidence that the pruning test in Algorithm [1](#page-5-0)<sup>+</sup> based on KV is more effective than the pruning test based on FKV used in Algorithm [1.](#page-5-0) However, the higher quality of the pruning test in Algorithm [1](#page-5-0)<sup>+</sup> comes at the cost of solving an NP-hard problem in each call to SearchNode, which remains computationally expensive even when using state-of-the-art solvers like Gurobi. Our results indicate that this additional effort is not justified: although the pruning test improves in quality, the associated time cost is too high to improve overall performance compared to Algorithm [1.](#page-5-0)

Next, we evaluate the performance of the accelerated versions of Algorithm [1](#page-5-0) on the artificially generated instances. Specifically, we compare Lazy Evaluations, Early Pruning, Candidate Reduction, and the combination of Lazy Evaluations and Candidate Reduction (LE+CR) against Algorithm [1](#page-5-0) and the solvers Umod and Udom by Sakaue and Ishihata [\[22\]](#page-25-0). As before, the comparison is based on the number of instances solved within a 1-hour time limit, the average running time, and the average number of nodes considered.

|     |        | solved | time (s) | nodes   |
|-----|--------|--------|----------|---------|
|     | Alg. 1 | 100    | 155.11   | 1290204 |
|     | LE     | 100    | 49.77    | 1582353 |
|     | EP     | 100    | 148.14   | 1290204 |
| COV | CR     | 100    | 139.97   | 416637  |
|     | LE+CR  | 100    | 59.86    | 620550  |
|     | Umod   | 98     | 261.43   | 29166   |
|     | Udom   | 96     | 409.29   | 70221   |
|     | Alg. 1 | 100    | 24.05    | 284023  |
|     | LE     | 100    | 5.48     | 399478  |
|     | EP     | 100    | 23.34    | 284023  |
| LOC | CR     | 100    | 7.68     | 84952   |
|     | LE+CR  | 100    | 2.29     | 141541  |
|     | Umod   | 100    | 21.71    | 7849    |
|     | Udom   | 100    | 49.83    | 15790   |
|     | Alg. 1 | 100    | 14.24    | 59970   |
|     | LE     | 100    | 2.01     | 83075   |
|     | EP     | 100    | 11.56    | 59970   |
| INF | CR     | 100    | 3.54     | 16972   |
|     | LE+CR  | 100    | 1.05     | 26933   |
|     | Umod   | 100    | 24.72    | 2202    |
|     | Udom   | 100    | 166.03   | 19112   |

<span id="page-18-0"></span>Table 3: Number of solved instances, average computation time (s), and average number of processed nodes for all solvers on artificial COV-, LOC-, and INF-instances generated following the method by Sakaue and Ishihata [\[22\]](#page-25-0).

|     |        | solved | time (s) | nodes     |
|-----|--------|--------|----------|-----------|
|     | Alg. 1 | 41     | 1898.53  | 155778623 |
|     | LE     | 74     | 1013.24  | 98520775  |
|     | EP     | 35     | 1734.463 | 135848743 |
| COV | CR     | 55     | 1177.77  | 8761085   |
|     | LE+CR  | 86     | 756.87   | 57276858  |
|     | Umod   | 12     | 2079.34  | 96084     |
|     | Udom   | /      | /        | /         |
|     | Alg. 1 | 72     | 2529.53  | 7139023   |
|     | LE     | 100    | 202.27   | 8828172   |
|     | EP     | 70     | 2572.66  | 7096005   |
| LOC | CR     | 98     | 1818.49  | 5713070   |
|     | LE+CR  | 100    | 137.18   | 6672304   |
|     | Umod   | 90     | 2277.72  | 63642     |
|     | Udom   | /      | /        | /         |
|     | Alg. 1 | 37     | 2123.91  | 2408375   |
|     | LE     | 95     | 522.54   | 13698321  |
|     | EP     | 38     | 2144.91  | 2452561   |
| INF | CR     | 82     | 1029.85  | 2105902   |
|     | LE+CR  | 99     | 423.78   | 7993367   |
|     | Umod   | 7      | 1975.26  | 21852     |
|     | Udom   | /      | /        | /         |

<span id="page-19-0"></span>Table 4: Number of solved instances, average computation time (s), and average number of processed nodes (both averaged over the solved instances) for all solvers on artificial COV-, LOC-, and INF-instances generated following our method.

The results of our tests are summarized in Tables [3](#page-18-0) and [4,](#page-19-0) and Figures [1](#page-20-0) and [2.](#page-21-0)

Both Umod and Udom are decisively outperformed by the algorithms we proposed. Despite considering significantly fewer nodes on average, Udom solves far fewer instances of all problem types within the time limit and has a higher running time for the instances it solves. In particular, Udom fails to solve any of the instances generated by our method within the given time limit. Umod performs slightly better than Udom, but it is significantly slower than Algorithm [1](#page-5-0) across all problem instances, except for the LOC instances generated following Sakaue and Ishihata [\[22\]](#page-25-0). In this case, Umod is somewhat faster than Algorithm [1;](#page-5-0) however, overall, Algorithm [1](#page-5-0) is the stronger solver, as it solves more instances within the given time limit across all problem types and achieves lower average running times.

Incorporating Lazy Evaluations (LE) significantly reduces the running time of Algorithm [1](#page-5-0) across all instances of all three problems. Among the instances generated using our method, LE solves 33% more COV-instances, 28% more LOC- instances, and 58% more INF-instances than Algorithm [1.](#page-5-0) The instances constructed according to the method of Sakaue and Ishihata [\[22\]](#page-25-0) are solved significantly faster by LE than by Algorithm [1.](#page-5-0) On average, COV-instances are solved three times faster, LOC-instances four times faster, and INF-instances even seven times faster.

Unfortunately, EP provides only limited acceleration of the basic algorithm. Although the instances constructed according to [Sakaue and Ishihata'](#page-25-0)s method are solved slightly faster, this marginal benefit disappears when considering the instances generated by our method. For these, EP yields a positive effect only for the INF instances, and even then, the improvement is negligible. Since EP essentially applies the same pruning test as Algorithm [1,](#page-5-0) both algorithms explore the same number of nodes for any given instance they both solve. The main difference is that EP makes pruning decisions earlier, thereby avoiding some marginal gain computations. However, this comes at the cost of frequently checking the early-pruning and early no-pruning conditions. Our experimental results indicate that the computational overhead introduced by these additional checks outweighs their benefits.

![](_page_20_Figure_2.jpeg)

<span id="page-20-0"></span>Figure 1: Number of solved instances for all solvers on artificial COV-, LOC-, and INFinstances generated following the method by Sakaue and Ishihata [\[22\]](#page-25-0).

![](_page_21_Figure_0.jpeg)

<span id="page-21-0"></span>Figure 2: Number of solved instances for all solvers on artificial COV-, LOC-, and INFinstances generated following our method.

Compared to Algorithm [1,](#page-5-0) CR performs better on all instances across all problem types. Although its running time improvements are not as large as those achieved by LE, CR still represents a consistent speedup of Algorithm [1.](#page-5-0)

The combination of Lazy Evaluations and Candidate Reduction seems to be the most efficient of all solvers. Apart from the COV-instances generated according to Sakaue and Ishihata [\[22\]](#page-25-0), where LE+CR achieves only the second-best performance after LE, LE+CR outperforms all other algorithms by a wide margin in all other tests. Considering the instances constructed following the method by Sakaue and Ishihata [\[22\]](#page-25-0), LOCinstances are solved on average ten times faster and INF-instances 13*.*5 times faster by LE+CR than by Algorithm [1.](#page-5-0) Among the instances constructed by our method, LE+CR solves 45% more COV-instances, 28% more LOC- instances, and 62% more INF-instances than Algorithm [1.](#page-5-0)

Additionally, the tests empirically prove our assumption that the instances constructed according to the method by Sakaue and Ishihata [\[22\]](#page-25-0) are generally 'easy' to solve. Both Umod and Udom, as well as the algorithms proposed by us, tend to solve fewer instances or require more time when applied to instances generated using our method compared to those generated following Sakaue and Ishihata [\[22\]](#page-25-0).

Finally, we compare all solvers on the two instances derived from real-world data. As before, we evaluate both the running time (in seconds) and the number of nodes explored. For these experiments, we increase the time limit to 24 hours. Table [5](#page-22-0) presents the results of these experiments.

|     |        | time (s) | nodes     |
|-----|--------|----------|-----------|
|     | Alg. 1 | 5567.61  | 94428669  |
|     | LE     | 7146.01  | 232238653 |
|     | EP     | 6414.22  | 94428669  |
| COV | CR     | 113.19   | 6735599   |
|     | LE+CR  | 102.42   | 11240995  |
|     | Umod   | 6699.91  | 151673    |
|     | Udom   | /        | /         |
|     | Alg. 1 | /        | /         |
|     | LE     | 2546.69  | 22648276  |
|     | EP     | /        | /         |
| INF | CR     | 18319.5  | 4005760   |
|     | LE+CR  | 502.84   | 5498329   |
|     | Umod   | 82694.2  | 8167      |
|     | Udom   | /        | /         |

<span id="page-22-0"></span>Table 5: Computation time (in seconds) and number of processed nodes for instances based on real-world data.

Consistent with the results on artificial instances, LE+CR remains the strongest solver, achieving the fastest running times on both real-data instances and outperforming the solvers Umod and Udom presented by Sakaue and Ishihata [\[22\]](#page-25-0). Interestingly, LE performs poorly on the COV instance based on real data, while CR provides a significant acceleration over Algorithm [1.](#page-5-0) Additionally, Umod can solve the INF instance within the given time limit of 24 hours, unlike Algorithm [1.](#page-5-0) However, in general, our methods – particularly LE+CR – consistently solve the instances considered substantially faster than Umod and Udom by Sakaue and Ishihata [\[22\]](#page-25-0).

### **4.2.1. Brief discussion of experimental results for Umod and Udom.**

Sakaue and Ishihata [\[22\]](#page-25-0) claim that Udom substantially outperforms Umod in all aspects, which is supported by the experimental results in their paper. However, we were unable to reproduce the positive test results reported for Udom. In our tests, Umod proved to be the stronger of the two solvers.

Notice that we conducted the test of Umod and Udom using reimplementations of both algorithms, as the original implementations were neither publicly available nor provided upon request. A detailed discussion of our implementations and the description of Udom by Sakaue and Ishihata [\[22\]](#page-25-0) is deferred to the Appendix.

Interestingly, our findings align with those reported by Uematsu et al. [\[26\]](#page-26-4), where both Umod and Udom, referred to as A<sup>∗</sup> -MOD and A<sup>∗</sup> -DOM, were evaluated for Submodular Cardinality-Constrained Maximization.

# <span id="page-23-3"></span>**5. Discussion.**

We presented a new branch-and-bound algorithm (Algorithm [1\)](#page-5-0) for solving the Submodular Knapsack-Constrained Maximization problem and several acceleration techniques for this basic algorithm. As our experimental results show, our methods are highly effective, particularly the combination of the two acceleration techniques Lazy Evaluations and Candidate Reduction (LE+CR). The state-of-the-art solvers Umod and Udom by Sakaue and Ishihata [\[22\]](#page-25-0) are strictly outperformed by the combined approaches.

A promising direction for future research is to reduce the running time of the proposed algorithms by parallelizing them. Given an instance of the Submodular Knapsack-Constrained Maximization problem and a fixed node in a basic search tree, the calls to SearchNode for the children of that node, as they appear in the proposed algorithms, can be executed in parallel. The results from the subtrees rooted at these child nodes can then be used to select the optimal solution for the instance.

Another direction is to further enhance the efficiency of the pruning test. For example, one can consider other decision functions for the lazy evaluation of a search tree than the average decision rule. The average decision rule is chosen to align with the pruning test we use. However, instance-specific decision functions may improve performance.

# **References**

- <span id="page-23-0"></span>[1] A.A. Ageev and M.I. Sviridenko. An 0.828-approximation algorithm for the uncapacitated facility location problem. *Discrete Applied Mathematics*, 93(2-3):149–156, 1999. ISSN 0166-218X. doi: https://doi.org/10.1016/S0166-218X(99)00103-1.
- <span id="page-23-1"></span>[2] Chandra Chekuri and Sanjeev Khanna. A polynomial time approximation scheme for the multiple knapsack problem. *SIAM Journal on Computing*, 35(3):713–728, 2005. doi: https://doi.org/10.1137/S0097539700382820.
- <span id="page-23-2"></span>[3] Wenlin Chen, Yixin Chen, and Kilian Q. Weinberger. Filtered search for submodular maximization with controllable approximation bounds. In *Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics*, volume 38 of *Proceedings of Machine Learning Research*, pages 156–164. PMLR, 2015.

- <span id="page-24-2"></span>[4] Gerard Cornuejols, Marshall L. Fisher, and George L. Nemhauser. Exceptional paper - location of bank accounts to optimize float: An analytic study of exact and approximate algorithms. *Management science*, 23(8):789–810, 1977. doi: https: //doi.org/10.1287/mnsc.23.8.789.
- <span id="page-24-8"></span>[5] Eszter Csókás and Tamás Vinkó. Constraint generation approaches for submodular function maximization leveraging graph properties. *Journal of Global Optimization*, 88(2):377–394, 2024. doi: https://doi.org/10.1007/s10898-023-01318-4.
- <span id="page-24-1"></span>[6] Uriel Feige. A threshold of ln n for approximating set cover. *J. ACM*, 45(4):634–652, 1998. doi: 10.1145/285055.285059.
- <span id="page-24-4"></span>[7] Uriel Feige and Jan Vondrák. Approximation algorithms for allocation problems: Improving the factor of 1-1/e. In *2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06)*, pages 667–676. IEEE, 2006. doi: 10.1109/FOCS.2006.14.
- <span id="page-24-6"></span>[8] Moran Feldman, Zeev Nutov, and Elad Shoham. Practical budgeted submodular maximization. *Algorithmica*, 85(5):1332–1371, 2023. doi: https://doi.org/10.1007/ s00453-022-01071-2.
- <span id="page-24-5"></span>[9] Lisa Fleischer, Michel X. Goemans, Vahab S. Mirrokni, and Maxim Sviridenko. Tight approximation algorithms for maximum general assignment problems. In *Proceedings of the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithm*, SODA '06, page 611–620. Society for Industrial and Applied Mathematics, 2006.
- <span id="page-24-3"></span>[10] Lisa Fleischer, Michel X. Goemans, Vahab S. Mirrokni, and Maxim Sviridenko. Tight approximation algorithms for maximum separable assignment problems. *Mathematics of Operations Research*, 36(3):416–431, 2011. doi: https://doi.org/ 10.1287/moor.1110.0499.
- <span id="page-24-0"></span>[11] Michel X. Goemans and David P. Williamson. Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. *J. ACM*, 42(6):1115–1145, 1995. doi: 10.1145/227683.227684.
- <span id="page-24-9"></span>[12] F. Maxwell Harper and Joseph A. Konstan. The movielens datasets: History and context. *ACM Trans. Interact. Intell. Syst.*, 5(4):19:1–19:19, 2015. ISSN 2160-6455. doi: 10.1145/2827872. URL [https://grouplens.org/datasets/](https://grouplens.org/datasets/movielens/100k/) [movielens/100k/](https://grouplens.org/datasets/movielens/100k/). Last accessed 30 June 2025.
- <span id="page-24-7"></span>[13] Yoshinobu Kawahara, Kiyohito Nagano, Koji Tsuda, and Jeff A. Bilmes. Submodularity cuts and applications. In *Advances in Neural Information Processing Systems 22 - Proceedings of the 2009 Conference*, pages 916–924. Neural Information Processing Systems, 2009.

- <span id="page-25-4"></span>[14] David Kempe, Jon Kleinberg, and Éva Tardos. Maximizing the spread of influence through a social network. *Theory of Computing*, 11(4):105–147, 2015. doi: 10.4086/ toc.2015.v011a004.
- <span id="page-25-2"></span>[15] Andreas Krause and Carlos Guestrin. Near-optimal observation selection using submodular functions. In *Proceedings of the 22nd National Conference on Artificial Intelligence - Volume 2*, AAAI'07, page 1650–1654. AAAI Press, 2007.
- <span id="page-25-3"></span>[16] Andreas Krause, H. Brendan McMahan, Carlos Guestrin, and Anupam Gupta. Robust submodular observation selection. *Journal of Machine Learning Research*, 9(12):2761–2801, 2008.
- <span id="page-25-5"></span>[17] Hui Lin and Jeff Bilmes. A class of submodular functions for document summarization. In *Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1*, HLT '11, page 510–520. Association for Computational Linguistics, 2011.
- <span id="page-25-9"></span>[18] Michel Minoux. Accelerated greedy algorithms for maximizing submodular set functions. In *Optimization Techniques. Lecture Notes in Control and Information Sciences*, pages 234–243, 1978. doi: https://doi.org/10.1007/BFb0006528.
- <span id="page-25-1"></span>[19] Baharan Mirzasoleiman, Amin Karbasi, Rik Sarkar, and Andreas Krause. Distributed submodular maximization. *J. Mach. Learn. Res.*, 17(1):8330–8373, January 2016. ISSN 1532-4435.
- <span id="page-25-8"></span>[20] G.L. Nemhauser and L.A. Wolsey. Maximizing submodular set functions: Formulations and analysis of algorithms. In *Annals of Discrete Mathematics (11)*, volume 59 of *North-Holland Mathematics Studies*, pages 279–301. North-Holland, 1981. doi: https://doi.org/10.1016/S0304-0208(08)73471-6.
- <span id="page-25-10"></span>[21] Tore Opsahl. Triadic closure in two-mode networks: Redefining the global and local clustering coefficients. *Social Networks*, 35(2):159–167, 2013. doi: 0.1016/j.socnet.2011.07.001. URL [https://toreopsahl.com/datasets/#online%](https://toreopsahl.com/datasets/#online%20forum%20network.) [20forum%20network.](https://toreopsahl.com/datasets/#online%20forum%20network.) Last accessed 30 June 2025.
- <span id="page-25-0"></span>[22] Shinsaku Sakaue and Masakazu Ishihata. Accelerated best-first search with upperbound computation for submodular function maximization. In *Proceedings of the AAAI Conference on Artificial Intelligence*, volume 32, 2018. doi: https://doi.org/ 10.1609/aaai.v32i1.11521.
- <span id="page-25-6"></span>[23] Maxim Sviridenko. A note on maximizing a submodular set function subject to a knapsack constraint. *Operations Research Letters*, 32(1):41–43, 2004. doi: https: //doi.org/10.1016/S0167-6377(03)00062-2.
- <span id="page-25-7"></span>[24] Jing Tang, Xueyan Tang, Andrew Lim, Kai Han, Chongshou Li, and Junsong Yuan. Revisiting modified greedy algorithm for monotone submodular maximization with a knapsack constraint. *Proceedings of the ACM on Measurement and Analysis of Computing Systems*, 5(1):1–22, 2021. doi: 10.1145/3447386.

- <span id="page-26-1"></span>[25] Sebastian Tschiatschek, Rishabh Iyer, Haochen Wei, and Jeff Bilmes. Learning mixtures of submodular functions for image collection summarization. In *Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1*, NIPS'14, page 1413–1421, 2014. doi: 10.5555/2968826.2968984.
- <span id="page-26-4"></span>[26] Naoya Uematsu, Shunji Umetani, and Yoshinobu Kawahara. An efficient branchand-cut algorithm for submodular function maximization. *Journal of the Operations Research Society of Japan*, 63(2):41–59, 2020. doi: 10.15807/jorsj.63.41.
- <span id="page-26-0"></span>[27] Kai Wei, Rishabh Iyer, and Jeff Bilmes. Submodularity in data subset selection and active learning. In *Proceedings of the 32nd International Conference on Machine Learning*, volume 37 of *Proceedings of Machine Learning Research*, pages 1954–1963. PMLR, 2015.
- <span id="page-26-2"></span>[28] Laurence A. Wolsey. Maximising real-valued submodular functions: Primal and dual heuristics for location problems. *Mathematics of Operations Research*, 7(3): 410–425, 1982. doi: 10.1287/moor.7.3.410.
- <span id="page-26-3"></span>[29] Henning Martin Woydt, Christian Komusiewicz, and Frank Sommer. SubModST: A fast generic solver for submodular maximization with size constraints. In *32nd Annual European Symposium on Algorithms (ESA 2024)*, volume 308 of *Leibniz International Proceedings in Informatics (LIPIcs)*, pages 102:1–102:18. Schloss Dagstuhl – Leibniz-Zentrum für Informatik, 2024. doi: 10.4230/LIPIcs.ESA.2024.102.

# **A. Appendix: Detailed discussion of the algorithm Udom.**

For Submodular Knapsack-Constrained Maximization, Sakaue and Ishihata [\[22\]](#page-25-0) introduced the solver Udom. In the following, we discuss possible implementations of Udom and address contradictory descriptions of Udom by Sakaue and Ishihata [\[22\]](#page-25-0).

As mentioned, Umod and Udom are both best-first search algorithms that rely on heuristic functions to decide which node of a basic search tree should be considered next. Given an instance (*I, f, w, B*) ∈ I and a basic search tree *T* = (*V, A*), Sakaue and Ishihata [\[22\]](#page-25-0) assume that any *c* ∈ *C*(*S*) satisfies *w<sup>c</sup>* ≤ *B* − *w*(*S*), since otherwise *S* ∪ {*c*} is not a feasible solution. In the following discussion, we adopt this assumption. We now restate some definitions and algorithms by Sakaue and Ishihata [\[22\]](#page-25-0) to clarify how the heuristic function *u*dom used in Udom is defined and to highlight the issues associated with these definitions.

For any node *S* ∈ *V* and *Y* ⊆ *C*(*S*), Sakaue and Ishihata [\[22\]](#page-25-0) define

$$
u_{\text{mod}}(Y) := \max\{\sum_{x \in C(S) \backslash Y} p_x f(x | S \cup Y) : \sum_{x \in C(S) \backslash Y} p_x w(x) \le B - w(S),
$$
  
$$
p_x \in [0,1] \text{ for } c \in C(S) \backslash Y\},\
$$

which provides an upper bound on max*X*⊆*C*(*S*)\*Y,w*(*X*)≤*B*−*w*(*S*) *f*(*X*|*S* ∪ *Y* ). Notice that *u*mod implicitly depends on a given node *S* ∈ *V* , even though this is not reflected in its notation.

Furthermore, Sakaue and Ishihata [\[22\]](#page-25-0) claim that they use the following greedy algorithm to define the heuristic *u*dom.

<span id="page-27-0"></span>**Algorithm 2: Input:** (*I, f, w, B*) ∈ I and a node *S* in a basic search tree. **Output:** *Z* ⊆ *C*(*S*). **<sup>1</sup>** Choose *c*max ∈ arg max*c*∈*C*(*S*) *f*(*c*|*S*) **2** *X* ← ∅ **3 while** *C*(*S*) ̸= ∅ **do 4** Choose *c* <sup>∗</sup> ∈ arg max*c*∈*C*(*S*) n *f*(*c*|*S*∪*X*) *wc* o **5 if** *w*(*X* ∪ {*c* <sup>∗</sup>}) ≤ *B* − *w*(*S*) **then** *X* ← *X* ∪ {*c* ∗} **6** *C*(*S*) ← *C*(*S*) \ {*c* ∗} **<sup>7</sup>** *Z* ← arg max*r*∈{*c*max*,X*} *f*(*r*|*S*) **8 return** *Z*

<span id="page-27-2"></span><span id="page-27-1"></span>Assume that Algorithm [2](#page-27-0) is applied to an instance (*I, f, w, B*) ∈ I and a node *S* in a corresponding basic search tree. Then, Sakaue and Ishihata [\[22\]](#page-25-0) use *X*1:*<sup>k</sup>* to denote the set *X* constructed in the while loop in Algorithm [2.](#page-27-0) Further, they use *X*1:*<sup>i</sup>* with 1 ≤ *i* ≤ *k* to denote the set containing the first *i* elements that are added in Line [5](#page-27-1) of Algorithm [2](#page-27-0) to *X*. For *i <* 1, *X*1:*<sup>i</sup>* is defined as ∅.

For any *i* ≤ *k*, let *c<sup>i</sup>* be the *i*-th element added in Line [5](#page-27-1) of Algorithm [2](#page-27-0) to *X*. Then, for any *i* ≤ *k*, Sakaue and Ishihata [\[22\]](#page-25-0) define

$$
\beta_i := 1 - \frac{f(c_i | X_{1:i-1} \cup S)}{u_{\text{mod}}(X_{1:i-1})}, \quad \beta_{1:k} := \begin{cases} 0 & \text{if } u_{\text{mod}}(X_{1:i}) = 0 \text{ for some } i \leq k, \\ \prod_{i=1}^k \beta_i & \text{otherwise.} \end{cases}
$$

The heuristic function *u*dom in a node *S* is defined by Sakaue and Ishihata [\[22\]](#page-25-0) as

$$
u_{\text{dom}} := \frac{f(X_{1:k}|S)}{1 - \beta_{1:k}}.
$$

Note that *u*dom always implicitly depends on a node *S*, even though this dependency is not reflected in the notation.

Sakaue and Ishihata [\[22\]](#page-25-0) claim that, for a given node *S*, the value *u*dom can be computed in parallel with a single execution of Algorithm [2](#page-27-0) for (*I, f, w, B*) and *S*, since all sets *X*1:*i*−<sup>1</sup> and all marginal gains *f*(*c*|*S* ∪ *X*1:*i*−1) for *c* ∈ *C*(*S*) \ *X*1:*i*−<sup>1</sup> to compute *u*mod(*X*1:*i*−1), and thus *u*dom, are already computed during the execution of Algorithm [2.](#page-27-0)

However, to calculate *u*mod(*X*1:*i*−1) for some *i* ≤ *k*, and thus to compute *u*dom, it is generally necessary to compute the marginal gain *f*(*c*|*S* ∪ *X*1:*i*−1) of an element *c* that was not added to *X* in Line [5,](#page-27-1) but was removed from *C*(*S*) in Line [6](#page-27-2) of Algorithm [2,](#page-27-0) in some iteration *j < i* − 1 of the while loop.

This reveals a contradiction between the definitions given by Sakaue and Ishihata [\[22\]](#page-25-0) and the description provided to compute *u*dom for a node *S*. To resolve this contradiction and avoid additional calculations, we implemented Udom using the following variant of a greedy algorithm.

<span id="page-28-0"></span>**Algorithm 3: Input:** (*I, f, w, B*) ∈ I and a node *S* in a basic search tree. **Output:** *Z* ⊆ *C*(*S*). **<sup>1</sup>** Choose *c*max ∈ arg max*c*∈*C*(*S*) *f*(*c*|*S*) **2** *X* ← ∅ **3 while** *C*(*S*) ̸= ∅ **do 4** Choose *c* <sup>∗</sup> ∈ arg max*c*∈*C*(*S*)\*<sup>X</sup>* n *f*(*c*|*S*∪*X*) *wc* o **5 if** *w*(*X* ∪ {*c* <sup>∗</sup>}) ≤ *B* − *w*(*S*) **then** *X* ← *X* ∪ {*c* ∗} **6 else break <sup>7</sup>** *Z* ← arg max*r*∈{*c*max*,X*} *f*(*r*|*S*) **8 return** *Z*

By using Algorithm [3,](#page-28-0) we can compute *u*dom for a node *S* as described by Sakaue and Ishihata [\[22\]](#page-25-0) without additional function evaluations, since Algorithm [3](#page-28-0) terminates as soon as adding an element *c* ∗ to *X* would exceed the knapsack capacity *B* − *w*(*S*).

Although we cannot verify that our implementation of Udom via Algorithm [3](#page-28-0) matches the original, we observed that it runs faster than with Algorithm [2.](#page-27-0) For this reason, we used it to compare against the algorithms proposed by us.