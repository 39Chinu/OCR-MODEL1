## HydraOpt: Navigating the Efficiency-Performance Trade-off of Adapter Merging

Taha Ceritli<sup>1</sup> , Ondrej Bohdal<sup>1</sup> , Mete Ozay<sup>1</sup> , Jijoong Moon<sup>2</sup> , Kyeng-Hun Lee<sup>2</sup> , Hyeonmok Ko<sup>2</sup> , Umberto Michieli<sup>1</sup> <sup>1</sup>Samsung R&D Institute UK, United Kingdom, <sup>2</sup>Samsung Research, South Korea

Correspondence: [t.ceritli@samsung.com](mailto:o.bohdal.1@samsung.com)

## Abstract

Large language models (LLMs) often leverage adapters, such as low-rank-based adapters, to achieve strong performance on downstream tasks. However, storing a separate adapter for each task significantly increases memory requirements, posing a challenge for resourceconstrained environments such as mobile devices. Although model merging techniques can reduce storage costs, they typically result in substantial performance degradation. In this work, we introduce HydraOpt, a new model merging technique that capitalizes on the inherent similarities between the matrices of low-rank adapters. Unlike existing methods that produce a fixed trade-off between storage size and performance, HydraOpt allows us to navigate this spectrum of efficiency and performance. Our experiments show that HydraOpt significantly reduces storage size (48% reduction) compared to storing all adapters, while achieving competitive performance (0.2- 1.8% drop). Furthermore, it outperforms existing merging techniques in terms of performance at the same or slightly worse storage efficiency.

## 1 Introduction

Large language models (LLMs) have become a driving force behind many natural language processing tasks today, including text summarization [\(Liu et al.,](#page-9-0) [2024b\)](#page-9-0), smart-reply [\(Bastola et al.,](#page-7-0) [2023\)](#page-7-0) and question-answering [\(Sticha et al.,](#page-9-1) [2024\)](#page-9-1). While modern LLMs are pre-trained to perform a diverse set of tasks, their performance on specific tasks can be improved by updating its parameters on task-specific datasets. However, this finetuning process becomes computationally impractical due to the growing size of LLMs, especially for resource-constrained environments such as mobile devices.

One approach to reduce the computational complexity of the fine-tuning process is parameter-

<span id="page-0-0"></span>![](_page_0_Figure_8.jpeg)

Figure 1: Performance and storage efficiency tradeoff. Average performance over 5 applications and 8 languages. Existing merging techniques reduce storage costs at significant performance drops. Our method performs similarly at the same efficiency level and improves if more storage is available, achieving performance similar to LoRAs.

efficient fine-tuning (PEFT) [\(Hu et al.,](#page-8-0) [2022;](#page-8-0) [Xu](#page-9-2) [et al.,](#page-9-2) [2023;](#page-9-2) [Lialin et al.,](#page-8-1) [2023\)](#page-8-1), where only a small set of parameters is updated while keeping the parameters of the LLMs frozen. For example, lowrank-based adapters such as LoRA [\(Hu et al.,](#page-8-0) [2022\)](#page-8-0) and VeRA [\(Kopiczko et al.,](#page-8-2) [2024\)](#page-8-2) have facilitated the use of LLMs for on-device applications, as one can store separate adapters for different tasks and switch to the corresponding parameters when the user wishes to perform a specific task [\(Gunter et al.,](#page-8-3) [2024\)](#page-8-3). However, storing separate adapters becomes costly for on-device settings where the memory is limited. Model merging techniques [\(Wortsman](#page-9-3) [et al.,](#page-9-3) [2022;](#page-9-3) [Ilharco et al.,](#page-8-4) [2023;](#page-8-4) [Yadav et al.,](#page-9-4) [2024;](#page-9-4) [Yu et al.,](#page-9-5) [2024\)](#page-9-5) address this issue by combining multiple adapters into one adapter used for all tasks. However, such techniques significantly disrupt the performance with no control.

In this work, we propose a new model merging method (HydraOpt) that allows controllable efficiency-performance trade-off, unlike existing methods that result in a single storage size and

performance. HydraOpt achieves competitive performance compared to storing all adapters but with reduced storage size and improves over the performance of existing merging techniques at a slightly worse storage efficiency (Fig. [1\)](#page-0-0). Our contributions are three-fold:

- Building on the similarity between low-rankbased adapters, we introduce a new model merging strategy called HydraOpt that can navigate the efficiency-performance trade-off of model merging.
- We design a comprehensive evaluation framework that consists of 40 tasks derived from 5 applications and 8 languages. We conduct experiments to assess the impact of merging adapters across applications, languages, and tasks.
- Our experiments demonstrate that HydraOpt finds a better trade-off between efficiency and performance across different lowrank-based adapters and LLMs. While maintaining comparable performance to existing model merging methods at similar storage levels, HydraOpt consistently outperforms them when a modest increase in storage is permitted.

## 2 Related Work

Parameter-efficient Fine-tuning (PEFT) techniques adapt models efficiently via training relatively few parameters, making them especially suitable for fine-tuning large language models [\(Ding et al.,](#page-8-5) [2022;](#page-8-5) [Han et al.,](#page-8-6) [2024\)](#page-8-6). Low-rankbased adapters [\(Hu et al.,](#page-8-0) [2022;](#page-8-0) [Liu et al.,](#page-9-6) [2024a;](#page-9-6) [Kopiczko et al.,](#page-8-2) [2024;](#page-8-2) [Malinovsky et al.,](#page-9-7) [2024;](#page-9-7) [Ceritli et al.,](#page-8-7) [2024\)](#page-8-7), in particular, have become widely adopted, having small additional storage requirements thanks to their compact size, which makes them suitable for deployment to mobile devices [\(Gunter et al.,](#page-8-3) [2024\)](#page-8-3). LoRA [\(Hu et al.,](#page-8-0) [2022\)](#page-8-0) introduces two low-dimensional trainable parameters A ∈ R r×k and B ∈ R <sup>d</sup>×<sup>r</sup> which are used to approximate the weight updates ∆W, *i.e.*, ∆W = BA where rank r << min(d, k). Then, the LLM parameters can be updated such that W = W + ∆W. Performance of LoRA has been further improved in its many extensions, such as AdaLoRA [\(Zhang et al.,](#page-9-8) [2023\)](#page-9-8) and DoRA [\(Liu](#page-9-6) [et al.,](#page-9-6) [2024a\)](#page-9-6).

Various approaches to improve efficiency of LoRA have also been proposed [\(Kopiczko et al.,](#page-8-2) [2024;](#page-8-2) [Renduchintala et al.,](#page-9-9) [2024\)](#page-9-9). In particular, VeRA [\(Kopiczko et al.,](#page-8-2) [2024\)](#page-8-2) has become popular for improving storage and parameter efficiency of LoRA, while maintaining competitive performance. VeRA introduces the following model update: ∆W = ΛbBΛdA where the parameters B ∈ R d×r and A ∈ R r×k are shared across the layers while the parameters Λ<sup>b</sup> ∈ R d and Λ<sup>d</sup> ∈ R r are defined per each layer. The resulting method reduces the number of trainable parameters, as the layer-specific parameters are defined as vectors rather than matrices.

Model Merging: Multiple task-specific models can be combined into a single model capable of multi-tasking via a process called model merging. Task Arithmetic [\(Wortsman et al.,](#page-9-3) [2022;](#page-9-3) [Ilharco](#page-8-4) [et al.,](#page-8-4) [2023\)](#page-8-4) represents the simplest option, and it combines the weights of multiple models as a weighted average. Various more advanced techniques have been developed, including TIES [\(Ya](#page-9-4)[dav et al.,](#page-9-4) [2024\)](#page-9-4) and DARE [\(Yu et al.,](#page-9-5) [2024\)](#page-9-5). TIES first resets the values of parameters that changed little, then elects the sign in case of conflicts, and merges only sign-aligned parameters. DARE drops part of the weight changes and then rescales the remaining ones accordingly. Other methods [\(Xiao](#page-9-10) [et al.,](#page-9-10) [2024;](#page-9-10) [Huang et al.,](#page-8-8) [2024;](#page-8-8) [Hammoud et al.,](#page-8-9) [2024;](#page-8-9) [Shenaj et al.,](#page-9-11) [2025\)](#page-9-11) use data to improve merging, however, that is beyond the scope of the present work.

On-device LLMs: LLMs typically include billions of parameters, which requires significant resources, such as high-end GPUs, even for inference only [\(Borzunov et al.,](#page-8-10) [2024\)](#page-8-10). However, in many use cases, it is desirable to perform computations locally without transferring data to remote servers [\(Dhar et al.,](#page-8-11) [2021\)](#page-8-11), for example, when using sensitive data stored on resource-constrained devices. Real-world examples include generating personalized replies or summarizing private conversations, where maintaining data privacy is paramount. As a solution, smaller LLMs (*e.g.*, 1–3 billion parameters) have been developed for ondevice deployment. These models utilize model compression strategies paired with a smaller size to support efficient on-device inference. Prominent examples include Llama 3.2 1B [\(Dubey et al.,](#page-8-12) [2024\)](#page-8-12), StableLM2 1.6B [\(Bellagente et al.,](#page-7-1) [2024\)](#page-7-1) and Qwen2.5 1.5B [\(Yang et al.,](#page-9-12) [2024;](#page-9-12) [Qwen Team,](#page-9-13) [2024\)](#page-9-13). Due to their relatively small size, it is standard practice to include single-task adapters on the device to enable the small LLMs to perform the individual tasks, instead of relying on instruction following [\(Gunter et al.,](#page-8-3) [2024;](#page-8-3) [Dong et al.,](#page-8-13) [2024\)](#page-8-13).

## 3 Proposed Method

#### 3.1 Motivation

Our work stems from the analysis of the asymmetric behaviour of low-rank adaptation matrices. [Zhu](#page-9-14) [et al.](#page-9-14) [\(2024\)](#page-9-14) demonstrate that the B parameters in LoRA exhibit distinct values when fine-tuned across different tasks, while the A parameters remain relatively similar when initialized identically, despite being fine-tuned on diverse tasks. Similarly, [Tian et al.](#page-9-15) [\(2024\)](#page-9-15) observe that when multiple LoRA adapters are trained on separate datasets, the A parameters tend to converge to similar values, whereas the B parameters become more differentiated.

We observe similar patterns when fine-tuning Llama-3.2-3B-Instruct on five distinct text generation tasks in English. Fig. [2](#page-2-0) illustrates the similarity between these LoRA adapters computed via Mean Absolute Error. The plot indicates that the A parameters are more similar to each other compared to the B parameters. We report in Fig. [10](#page-14-0) an analysis using Canonical Correlation Analysis (CCA), as in [Zhu et al.](#page-9-14) [\(2024\)](#page-9-14). We further confirm these results with t-SNE visualizations in Fig. [11](#page-15-0) following the approach of [Tian et al.](#page-9-15) [\(2024\)](#page-9-15).

These findings suggest that the A parameters capture cross-domain commonalities, while the B parameters adapt to task-specific knowledge. This behavior may stem from the initialization schemes for low-rank-based adapters, where B is typically initialized as a zero matrix, while A is sampled from a Gaussian distribution. These behaviors can also be observed in VeRA as Λ<sup>b</sup> is initialized as zero vector and Λ<sup>d</sup> is sampled from a Gaussian distributions.

#### 3.2 Our Method: HydraOpt

We propose HydraOpt for merging a set of low-rank-based adapters parameters (*e.g.* LoRA) {B<sup>i</sup> , Ai} K <sup>i</sup>=1. As shown in Fig. [3,](#page-3-0) HydraOpt approximates the given set of parameters by learning a shared A′ parameter and a set of B′ parameters {B′ i }<sup>M</sup> <sup>i</sup>=1. The approximation to the original model updates is driven by the following loss function:

<span id="page-2-0"></span>![](_page_2_Figure_8.jpeg)

Figure 2: Similarity between A and B matrices of LoRAs measured using Mean Absolute Error on query matrices of Llama-3.2-3B-Instruct fine-tuned on 5 applications in English.

<span id="page-2-1"></span>
$$
\ell = \sum_{i=1}^{K} f\left(B_i A_i, \sum_{j=1}^{M} \sigma(\mathbf{C}'_i/T)(j) B'_j A'\right), \tag{1}
$$

where f is a distance function that measures the similarity between two model updates ∆W<sup>i</sup> := BiA<sup>i</sup> and ∆W′ j := B′ jA′ . Here, σ denotes the softmax function with the temperature term T, and C′ <sup>i</sup> <sup>∈</sup> <sup>R</sup><sup>M</sup> is a trainable vector of coefficients with the coefficient C ′ i,j representing how likely it is to use B′ j for the i th task. The softmax function approximates categorical one-hot encoded vectors for small values, hence guiding the model to use mostly one B′ j parameter for a given task.

Given the sparsity of adapter parameters, we choose Mean Absolute Error as the distance function f to induce sparsity [\(Bach et al.,](#page-7-2) [2012\)](#page-7-2). We then calculate the gradients of the objective function Eq. [\(1\)](#page-2-1) to update the parameters A′ , {B′ i }<sup>M</sup> <sup>i</sup>=1, {C′ i } K <sup>i</sup>=1 using an iterative optimization algorithm. For instance, the update rule for A′ using Gradient Descent becomes A′ = A′ − η∇ℓ where η is the learning rate and ℓ is the loss.

The coefficients C′ i are initialized using a Gaussian distribution and updated during training. We remark that this only brings a minimal increase in memory footprint during training, since the number of coefficients is much smaller than the number of LoRA parameters. Moreover, these coefficients are discarded once the training is over, after we associate each task with a B′ parameter. Therefore, the inference stage is unaltered.

HydraOpt allows us to walk the efficiency-

<span id="page-3-0"></span>![](_page_3_Figure_0.jpeg)

Figure 3: An overview of HydraOpt. We approximate K sets of LoRA parameters by learning a shared A′ parameter and a set of task-specific parameters {B′ i }<sup>M</sup> <sup>i</sup>=1.

performance trade-off of model merging. In the most aggressive parameter sharing scheme, HydraOpt constructs one set of LoRA parameters {B′ , A′}, which causes performance drops due to the reduced flexibility of the approximation similarly to existing model merging techniques. However, by adjusting the level of parameter sharing, we obtain both efficient and accurate model merging solutions.

In the special case of K = M, we omit the coefficients C′ i by learning a separate B′ parameter for each task. Specifically, we modify the loss function in Eq. [\(1\)](#page-2-1) to be:

<span id="page-3-1"></span>
$$
\ell = \sum_{i=1}^{K} f(B_i A_i, B'_i A').
$$
 (2)

The reduction in parameter size using HydraOpt depends on the number of LoRAs to merge and the size of LoRA parameters. For one layer of an LLM, the number of parameters required by LoRA becomes K × r × (d + k) for K tasks, whereas HydraOpt requires M × r × d + r × k parameters where M denotes the number of B′ parameters. Assuming that the A and B parameters are the same size, the total number of parameters reduces to 60% when merging 5 pairs of LoRA parameters (Fig. [12](#page-15-1) in Appendix [A.3\)](#page-10-0). The reduction rate asymptotically reaches 50% as the number of LoRAs increases, while it can be greater than 50% if the A is larger than B.

Notice that the objective functions in Eq. [\(1\)](#page-2-1)- [\(2\)](#page-3-1) do not utilize any external task-specific samples. Instead, they treat the given set of LoRA parameters {B<sup>i</sup> , Ai} K <sup>i</sup>=1 as the target pseudo-labels

#### <span id="page-3-2"></span>Algorithm 1 HydraOpt

| K<br>{Ai<br>, Bi}<br>Require: Adapter parameters<br>i=1,<br>tar<br>B′ parameters<br>get number of<br>M, number of<br>epochs E, temperature<br>T, optimizer<br>1: Initialize A′<br>{B′<br>}M<br>{C′<br>K<br>}<br>,<br>i=1,<br>i<br>i<br>i=1<br>2: for e<br>in E<br>do<br>if K<br≯=<br>M<br>then<br>3:<br>Calculate the loss ℓ<br>using Eq. (1)<br>4:<br>else<br>5:<br>Calculate the loss ℓ<br>using Eq. (2)<br>6:<br>Parameter update using the optimizer:<br>7:<br>A′ ←<br>arg min<br>ℓ<br>8:<br>A′<br>{B′<br>}M<br>i=1 ←<br>arg min<br>ℓ<br>9:<br>i<br>{B′<br>}M<br>i<br>i=1<br>{C′<br>K<br>}<br>i=1 ←<br>arg min<br>ℓ<br>10:<br>i<br>{C′<br>}K<br>i<br>i=1<br>11: Use A′<br>for all tasks<br>12: for i-th task in<br>1,<br>2, , K<br>do<br≯=<br>if K<br>M<br>then<br>13:<br>′<br>←<br>j<br>arg max<br>C<br>14:<br>i,j<br>j∈{1,2,,M}<br>Use B′<br>rather than Bi<br>15:<br>j<br>else<br>16:<br>Use B′<br>rather than Bi<br>17:<br>i |  |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--|
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |
|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |  |

and updates the trainable HydraOpt parameters A′ , {B′ i }<sup>M</sup> <sup>i</sup>=1, {C ′ i} K <sup>i</sup>=1 during the training. Therefore, our technique is classified as a data-free model merging method. Algorithm [1](#page-3-2) provides a brief description of HydraOpt.

## 4 Experiments

In this section, we describe our experimental setup (Sec. [4.1\)](#page-3-3) and discuss the main results (Sec. [4.2\)](#page-4-0) and the ablation studies (Sec. [4.3\)](#page-6-0).

#### <span id="page-3-3"></span>4.1 Setup

Tasks: We conduct experiments on 40 downstream tasks in total, each of which is a text generation application in a specific language. We tackle 5 applications. (i) Grammar Correction (GC): to generate the correct form of a given input containing grammar errors. (ii) Smart Reply (SR): to generate a response to a given textual message. (iii) Text Summarization (TS): to generate a shorter version of a given sentence. (iv) Tone Adjustment (TA): to re-write a given text in a specific style. (iv) Question Answering (QA): to answer a given question. Each application is considered in 8 different languages: EN, DE, ES, FR, IT, JA, KO, ZH[1](#page-4-1) .

Datasets: We use Cambridge English Write & Improve (W&I) [\(Bryant et al.,](#page-8-14) [2019\)](#page-8-14) for GC, Persona-Chat Synthetic [\(Jandaghi et al.,](#page-8-15) [2024\)](#page-8-15) for SR, SAM-Sum [\(Gliwa et al.,](#page-8-16) [2019\)](#page-8-16) for TS, Sound Natural [\(Einolghozati et al.,](#page-8-17) [2020\)](#page-8-17) rephrased using the finetuned RedPajama-INCITE-Base-3B-v1 model [\(Ut](#page-9-16)[sav,](#page-9-16) [2023\)](#page-9-16) for TA, and SQuAD [\(Rajpurkar et al.,](#page-9-17) [2016\)](#page-9-17) for QA. As these datasets are collected in English, we utilize machine-translation for the remaining languages. Specifically, we use OPUS-MT [\(Tiedemann and Thottingal,](#page-9-18) [2020\)](#page-9-18) for translation to French, German, Italian and Spanish, and M2M100 [\(Fan et al.,](#page-8-18) [2021\)](#page-8-18) for translation to Chinese, Japanese and Korean. However, the translation process fixes the grammar errors in the input text (as also mentioned in [Luhtaru et al.,](#page-9-19) [2024\)](#page-9-19). Therefore, we used datasets collected in the original languages for Grammar Correction, namely EC-Spell [\(Lv et al.,](#page-9-20) [2023\)](#page-9-20) for Chinese, Merlin [\(Boyd](#page-8-19) [et al.,](#page-8-19) [2014\)](#page-8-19) for Italian, and GitHub Typo Corpus [\(Hagiwara and Mita,](#page-8-20) [2020\)](#page-8-20) for the remaining languages. Table [6](#page-14-1) presents a summary of the employed datasets, including their links and number of samples. Table [7](#page-16-0) lists the prompts that we have used for each case.

Evaluation Metrics: Following the literature, we report F05 (↑) [\(Bryant et al.,](#page-8-21) [2017\)](#page-8-21) for GC[2](#page-4-2) , Weighted Rouge (↑) for SR, RougeL (↑) for TS and TA, and F1 (↑) for QA. Given the page limit, we report the average of these metrics as aggregated overview when needed, with individual results reported in Appendix [A.3](#page-10-0) for completeness. Additionally, we report the storage (S, %, ↓) as the percentage of the parameters compared to storing all individual adapters.

Models: We use Llama-3.2-1B-Instruct [\(Grattafiori et al.,](#page-8-22) [2024\)](#page-8-22) for our main experiments due to its size suitable for on-device deployment. However, we also present analyses with different model sizes (2B, 3B, and 3.5B) and architectures (Gemma2, [Gemma Team,](#page-8-23) [2024,](#page-8-23) and Phi-3, [Abdin et al.,](#page-7-3) [2024\)](#page-7-3) to prove the generalization of our method.

Baseline Methods: For fair comparison, we compare our method with existing data-free model merging techniques such as Task Arithmetic (TA, [Ilharco et al.](#page-8-4) [2023\)](#page-8-4), TIES [\(Yadav et al.,](#page-9-4) [2024\)](#page-9-4),

<span id="page-4-4"></span>Table 1: Performance on 5 English applications using Llama-3.2-1B-Instruct LoRA-finetuned. S represents the percentage of the parameters compared to storing 5 LoRAs.

| Method        | S (%) GC | SR | TS | TA |                               | QA Avg |
|---------------|----------|----|----|----|-------------------------------|--------|
| Zero-shot     | 0        |    |    |    | 13.1 5.1 23.4 27.6 15.8 17.0  |        |
| LoRA          | 100      |    |    |    | 35.1 23.0 38.2 58.1 61.5 43.2 |        |
| TA            | 20       |    |    |    | 25.9 11.4 32.3 51.7 28.7 30.0 |        |
| TIES          | 20       |    |    |    | 25.1 13.2 31.1 51.7 26.9 29.6 |        |
| DARE          | 20       |    |    |    | 21.6 7.4 27.1 39.0 19.7 23.0  |        |
| DARE-TIES     | 20       |    |    |    | 22.5 7.9 27.4 44.0 20.9 24.5  |        |
| HydraOpt(M=1) | 20       |    |    |    | 26.3 9.0 32.3 50.4 27.6 29.1  |        |
| HydraOpt(M=2) | 28       |    |    |    | 26.9 17.6 31.7 53.0 28.2 31.5 |        |
| HydraOpt(M=5) | 52       |    |    |    | 33.1 21.7 37.1 57.1 59.9 41.8 |        |

DARE [\(Yu et al.,](#page-9-5) [2024\)](#page-9-5), and DARE-TIES[3](#page-4-3)

Implementation Details: We set the LoRA rank to 32, α to 128 and dropout to 0.05 throughout the experiments. We utilize the AdamW optimizer with a learning rate of 5e-5 and a batch size of 3. Please see Appendix [A.1](#page-10-1) for further details.

.

#### <span id="page-4-0"></span>4.2 Main Results

Merging 5 LoRA adapters in a language: We first consider a typical model merging scenario where multiple LoRA adapters are obtained by finetuning the same model (Llama-3.2-1B-Instruct in this case) across different applications. Table [1](#page-4-4) presents a comparison of the methods in terms of storage efficiency and performance. The highestperforming state-of-the-art method is TA that reduces average performance by 13.2% at the storage occupancy of 20%.

HydraOpt exhibits similar performance at the same storage and starts outperforming TA as the extent of storage size reduction is sacrificed. Specifically, we obtain a 1.5% gain over TA in average performance when an additional 8% storage size is used. If more storage is available, we can approach the LoRA upper bound: namely, HydraOpt(M=5) is only 1.4% lower than LoRA in terms of average performance, while saving ∼50% storage.

We note that HydraOpt introduces additional runtime; however, the merging operation is still reasonably fast with relatively small GPU memory overhead (please see Table [17](#page-21-0) in Appendix [A.3](#page-10-0) for a comparison of the methods in terms of runtime and memory).

#### Merging 5 LoRA adapters (multiple languages):

<span id="page-4-1"></span><sup>1</sup>Abbreviated for English, German, Spanish, French, Italian, Japanese, Korean, Chinese, respectively

<span id="page-4-2"></span><sup>2</sup>We use ChERRANT [\(Zhang et al.,](#page-9-21) [2022\)](#page-9-21) for Chinese.

<span id="page-4-3"></span><sup>3</sup> See the dare ties function at [https://github.](https://github.com/huggingface/peft/blob/main/src/peft/utils/merge_utils.py) [com/huggingface/peft/blob/main/src/peft/](https://github.com/huggingface/peft/blob/main/src/peft/utils/merge_utils.py) [utils/merge\\_utils.py](https://github.com/huggingface/peft/blob/main/src/peft/utils/merge_utils.py) [Accessed on 17 May 2025]

<span id="page-5-0"></span>

| TA            |       | 70 69 64 68 69 77 79 60 |    |    |    |       |    |
|---------------|-------|-------------------------|----|----|----|-------|----|
| TIES          |       | 69 62 57 64 64 72 71 58 |    |    |    |       | 90 |
| DARE          |       | 53 45 47 51 54 69 60 55 |    |    |    |       |    |
| DARE-TIES     |       | 57 49 47 53 56 70 63 58 |    |    |    |       | 80 |
| HyperOpt(M=1) |       | 67 64 64 67 64 77 77 63 |    |    |    |       | 70 |
| HyperOpt(M=2) |       | 73 65 65 68 68 77 73 72 |    |    |    |       |    |
| HyperOpt(M=3) |       | 79 76 73 78 77 78 79 78 |    |    |    |       | 60 |
| HyperOpt(M=4) |       | 85 88 77 87 83 75 79 80 |    |    |    |       |    |
| HyperOpt(M=5) |       | 97 96 94 98 97 97 94 95 |    |    |    |       | 50 |
|               | EN DE | ES                      | FR | IT | JA | KO ZH |    |

Figure 4: Average performance on 5 applications in different languages using Llama-3.2-1B-Instruct. In this figure, we report the relative average score compared to LoRA.

We performed the same 5-way merging experiment in multiple languages and we observe similar improvements across the board as shown in Fig. [4.](#page-5-0)

Different LLMs: Next, we test the generalization of our approach across different LLM sizes and architectures (Llama 1B, Llama 3B, Gemma 2B, Phi3.5B). In Table [2,](#page-5-1) we observe a consistent trend across model types and sizes.

HydraOpt(M=5) consistently improves average performance over the baselines at a small storage size cost.

<span id="page-5-1"></span>Table 2: Average performance on 5 English applications for different LoRA-finetuned LLMs. We use Llama-3.2-1B-Instruct (L1B), Llama-3.2-3B-Instruct (L3B), Gemma-2-2B-it (G2B), and Phi-3.5 mini-instruct (P3.5B), and report the average of individual metrics for each model.

| Method        | S (%) | L1B  | L3B  | G2B  | P3.5 |
|---------------|-------|------|------|------|------|
| Zero-shot     | 0     | 17.0 | 20.1 | 20.8 | 14.9 |
| LoRA          | 100   | 43.2 | 47.8 | 47.9 | 45.4 |
| TA            | 20    | 30.0 | 37.4 | 37.7 | 33.3 |
| TIES          | 20    | 29.6 | 35.0 | 35.1 | 34.1 |
| DARE          | 20    | 23.0 | 38.6 | 24.6 | 20.1 |
| DARE-TIES     | 20    | 24.5 | 27.4 | 25.7 | 20.1 |
| HydraOpt(M=1) | 20    | 29.1 | 36.5 | 36.0 | 30.6 |
| HydraOpt(M=2) | 28    | 31.5 | 41.3 | 40.3 | 40.8 |
| HydraOpt(M=5) | 52    | 41.8 | 46.0 | 47.5 | 45.2 |

Different low-rank-based adapter types: In this experiment, we demonstrate how HydraOpt can be extended to other low-rank-based adapters. In particular, we consider VeRA [\(Kopiczko et al.,](#page-8-2) [2024\)](#page-8-2) for its efficiency and competitive performance compared to LoRA.

Similarly to the application of HydraOpt to a set of LoRA parameters, we merge a set of VeRA parameters by learning a new set of parameters Λ ′ b

<span id="page-5-2"></span>Table 3: Average performance on 5 English applications using Llama-3.2-1B-Instruct VeRA-finetuned. S represents the percentage of the parameters compared to storing 5 VeRAs.

| S (%) | Avg                                                                          |
|-------|------------------------------------------------------------------------------|
|       | 17.2                                                                         |
|       | 39.0                                                                         |
|       | 0.3                                                                          |
|       | 27.8                                                                         |
|       | 28.6                                                                         |
|       | 27.7                                                                         |
|       | 26.9                                                                         |
|       | 27.5                                                                         |
|       | 29.9                                                                         |
|       | 35.8                                                                         |
| 22.7  | 36.4                                                                         |
|       | 0.0<br>100.0<br>20.0<br>20.0<br>20.0<br>20.0<br>20.0<br>20.7<br>21.4<br>22.1 |

and Λ ′ <sup>d</sup> with the latter shared across multiple tasks. Note that for simplicity, we discard the merging of the parameters A and B as they are initialized similarly across the tasks and kept frozen during fine-tuning.

Table [3](#page-5-2) presents the results. The best state-ofthe-art approach is TIES in this case, while TA, which worked well on LoRA, achieves a significantly lower score here. Even though TIES performs better than our method at 20% storage efficiency, we remark once again that our approach allows us to achieve much higher performance at the minimal cost of 2.7% additional storage.

Evaluation across languages and merging setups: We extend our setup to multiple languages in Table [4.](#page-6-1) Firstly, we merge 5 LoRA adapters in each language and report the average performance across 8 languages (*application* block). Secondly, we apply merging across languages rather than applications, *i.e.*, merging 8 LoRA adapters for each application (*languages* block). Finally, we merge all 40 LoRA adapters, each of which corresponds to an application in a given language (*task* block). Detailed individual results are reported in Appendix [A.3.](#page-10-0)

The results highlight that our method is in line with existing state-of-the-art merging methods for the highest storage efficiency levels, however, it enables large accuracy gains when small additional storage is available.

Merging Across Applications: Our approach performs comparably to the best state-of-the-art method (TA), with only a 0.6% drop in performance. However, by utilizing 8% more storage, HydraOpt achieves a 1.4% performance gain over

<span id="page-6-1"></span>Table 4: Average performance on 40 tasks using Llama-3.2-1B-Instruct (L1B) and Llama-3.2-3B-Instruct (L3B) LoRA-finetuned. S represents the percentage of parameters compared to storing all 40 Lo-RAs.

|              | Method         | S (%) | L1B  | L3B  | Avg  |
|--------------|----------------|-------|------|------|------|
|              | Zero-shot      | 0.0   | 12.3 | 15.1 | 13.7 |
|              | LoRA           | 100.0 | 28.1 | 33.2 | 30.7 |
|              | TA             | 20.0  | 19.3 | 24.1 | 21.7 |
|              | TIES           | 20.0  | 17.9 | 20.5 | 19.2 |
|              | DARE           | 20.0  | 15.0 | 24.2 | 19.6 |
|              | DARE-TIES      | 20.0  | 15.6 | 18.4 | 17.0 |
| applications | HydraOpt(M=1)  | 20.0  | 18.9 | 23.3 | 21.1 |
|              | HydraOpt(M=2)  | 28.0  | 19.5 | 26.6 | 23.1 |
|              | HydraOpt(M=5)  | 52.0  | 26.9 | 32.4 | 29.6 |
|              | TA             | 12.5  | 24.6 | 29.1 | 26.9 |
|              | TIES           | 12.5  | 24.7 | 25.3 | 25.0 |
|              | DARE           | 12.5  | 15.8 | 19.0 | 17.4 |
| languages    | DARE-TIES      | 12.5  | 17.1 | 21.1 | 19.1 |
|              | HydraOpt(M=1)  | 12.5  | 23.9 | 27.4 | 25.6 |
|              | HydraOpt(M=3)  | 22.5  | 24.7 | 29.7 | 27.2 |
|              | HydraOpt(M=8)  | 47.5  | 26.6 | 32.1 | 29.4 |
| tasks        | TA             | 2.5   | 18.0 | 21.8 | 19.9 |
|              | TIES           | 2.5   | 17.4 | 18.7 | 18.0 |
|              | DARE           | 2.5   | 14.0 | 16.7 | 15.3 |
|              | DARE-TIES      | 2.5   | 14.2 | 16.6 | 15.4 |
|              | HydraOpt(M=1)  | 2.5   | 17.5 | 22.0 | 19.8 |
|              | HydraOpt(M=40) | 41.5  | 21.9 | 25.2 | 23.5 |
|              |                |       |      |      |      |

TA. Additionally, when a 48% reduction in storage size is acceptable, the average performance drop compared to the upper bound individual LoRA adapters can be reduced to 1.1%.

Merging Across Languages: In this setting, TA achieves the best performance at 12.5% storage efficiency, with an average performance drop of 3.8% compared to individual LoRA adapters. HydraOpt surpasses TA with just a 10% increase in storage, and the performance gap continues to widen as storage size increases. At 47.5% storage efficiency, HydraOpt incurs only a 1.3% drop compared to individual LoRA adapters.

Merging Across Tasks: In this most challenging setup, TA and HydraOpt exhibit similar performance at the most constrained storage efficiency of 2.5%. However, as storage size increases to 41.5%, our approach narrows the gap with individual LoRA adapters to as little as 7.2%.

## <span id="page-6-0"></span>4.3 Ablation Studies

We fine-tune Llama-3.2-1B-Instruct using the English data and perform several ablation studies when merging 5 LoRA adapters.

Impact of LoRA rank: First, we investigate whether the benefits of HydraOpt remain the same

<span id="page-6-2"></span>Table 5: Impact of LoRA rank on average performance for 5 English applications using Llama-3.2- 1B-Instruct LoRA-finetuned. We report the percentage of the parameters compared to storing all 5 LoRA parameters (denoted by S) and the average score.

| Method        | S (%) | r = 8 | r = 16 | r = 32 |
|---------------|-------|-------|--------|--------|
| Zero-shot     | 0     | 17.0  | 17.0   | 17.0   |
| LoRA          | 100   | 39.2  | 41.7   | 43.2   |
| TA            | 20    | 28.4  | 28.9   | 30.0   |
| TIES          | 20    | 28.1  | 29.1   | 29.6   |
| DARE          | 20    | 20.7  | 21.8   | 23.0   |
| DARE-TIES     | 20    | 22.4  | 23.8   | 24.5   |
| HydraOpt(M=1) | 20    | 27.1  | 28.3   | 29.1   |
| HydraOpt(M=2) | 28    | 30.0  | 31.0   | 31.5   |
| HydraOpt(M=5) | 52    | 38.5  | 40.0   | 41.8   |

<span id="page-6-3"></span>![](_page_6_Figure_10.jpeg)

Figure 5: Impact of distance function used during training. We report average performance on 5 English applications using Llama-3.2-1B-Instruct LoRAfinetuned.

across the LoRA rank r ∈ {8, 16, 32}. As shown in Table [5,](#page-6-2) HydraOpt begins to improve over the performance of the leading competitor method when the storage is increased by 8%. Moreover, a 48% reduction in storage size leads to competitive performance with storing all individual LoRA adapters.

Impact of the distance function: Next, we analyze the choice of distance function f used for calculating the loss during training. In particular, we compare mean absolute error (MAE) with three alternative loss functions based on cosine similarity (CS), Frobenius norm (FRO), and mean squared error (MSE). Fig. [5](#page-6-3) shows that MAE and FRO lead to better performance than CS and MSE. This result is not surprising as the optimization is done over the sparse LoRA parameters, which can be better learned using sparsity-inducing penalties [\(Bach](#page-7-2) [et al.,](#page-7-2) [2012\)](#page-7-2).

Analysis of existing merging methods at higher storage sizes: We apply existing merging methods only on the A parameters for comparison with our method at a reduced storage efficiency level. The existing merging methods lead to a performance drop as shown in Fig. [6,](#page-7-4) which can be explained by the lack of adaptation on the B parameters after obtaining the new shared A parameters. HydraOpt, on the other hand, iteratively adapts the B′ parameters to the shared A′ parameter to approximate the original model updates ∆W.

## 5 Conclusion

On-device applications of LLMs often leverage parameter-efficient fine-tuning methods, such as low-rank-based adapters, for downstream tasks. However, the need to deploy a separate adapter for each task results in substantial storage overhead, a critical challenge for resource-constrained environments such as mobile devices. While model merging techniques offer a potential solution by reducing the storage size, they often come at the cost of significant performance degradation on downstream tasks, making them impractical for realworld deployment.

In this work, we introduce HydraOpt, a new model merging technique that effectively addresses the trade-off. HydraOpt achieves competitive performance (0.2-1.8% drop) compared to storing all LoRA adapters, while significantly reducing parameter size (48% reduction). Furthermore, it consistently outperforms the performance of existing model merging methods at slightly worse efficiency levels. HydraOpt thus enables efficient storage utilization without compromising task-specific performance for deploying LLMs on-device.

<span id="page-7-4"></span>![](_page_7_Figure_4.jpeg)

Figure 6: Impact of storage efficiency level. We report average performance on 5 English applications using Llama-3.2-1B-Instruct LoRA-finetuned.

## Limitations

Despite the encouraging results obtained using HydraOpt, there are certain limitations in our current study that are worth acknowledging. For instance, this paper considers the generic case of data-free model merging where there is no assumption on the presence of data. Therefore, its performance is upper bounded by LoRA parameters. An interesting research direction may be considering data-driven merging scenarios, for which we expect similar gains in terms of efficiency and performance. Moreover, we tested HydraOpt with low-rank-based adapters such as LoRA and VeRA due to their popularity and efficiency-performance trade-offs. Exploring its applications to other types of adapters would be a valuable direction for future work. Finally, we believe that our proposed method can be used in more general cross-modal and multi-modal tasks, which are getting more and more attention in the literature.

## Potential Risks

This work investigates the efficiency-performance trade-off of serving LLMs for text generation applications on mass accessible devices. Even though our work can reduce the storage costs of LLMs, it does not change the inference complexity and its impact on the environment. Moreover, we did not evaluate how our method impacts LLMs in terms of fairness across different population subgroups, which needs to be verified using additional safeguarding tools.

## References

- <span id="page-7-3"></span>Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, and 1 others. 2024. Phi-3 technical report: A highly capable language model locally on your phone. *arXiv preprint arXiv:2404.14219*.
- <span id="page-7-2"></span>Francis Bach, Rodolphe Jenatton, Julien Mairal, Guillaume Obozinski, and 1 others. 2012. Optimization with sparsity-inducing penalties. *Foundations and Trends in Machine Learning*, 4(1):1–106.
- <span id="page-7-0"></span>Ashish Bastola, Hao Wang, Judsen Hembree, Pooja Yadav, Zihao Gong, Emma Dixon, Abolfazl Razi, and Nathan McNeese. 2023. LLM-based smartreply (LSR): Enhancing collaborative performance with ChatGPT-mediated smart reply system. *arXiv preprint arXiv:2306.11980*.
- <span id="page-7-1"></span>Marco Bellagente, Jonathan Tow, Dakota Mahan, Duy Phung, Maksym Zhuravinskyi, Reshinth Adithyan,

James Baicoianu, Ben Brooks, Nathan Cooper, Ashish Datta, and 1 others. 2024. Stable LM 2 1.6 B technical report. *arXiv preprint arXiv:2402.17834*.

- <span id="page-8-10"></span>Alexander Borzunov, Max Ryabinin, Artem Chumachenko, Dmitry Baranchuk, Tim Dettmers, Younes Belkada, Pavel Samygin, and Colin A Raffel. 2024. Distributed inference and fine-tuning of large language models over the internet. In *NeurIPS*.
- <span id="page-8-19"></span>Adriane Boyd, Jirka Hana, Lionel Nicolas, Detmar Meurers, Katrin Wisniewski, Andrea Abel, Karin Schone, Barbora Stindlov ¨ a, and Chiara Vettori. 2014. ´ The MERLIN corpus: Learner language and the CEFR. In *LREC*.
- <span id="page-8-14"></span>Christopher Bryant, Mariano Felice, Øistein E Andersen, and Ted Briscoe. 2019. The BEA-2019 shared task on grammatical error correction. In *Workshop on innovative use of NLP for building educational applications*.
- <span id="page-8-21"></span>CJ Bryant, Mariano Felice, and Edward Briscoe. 2017. Automatic annotation and evaluation of error types for grammatical error correction. In *ACL*.
- <span id="page-8-7"></span>Taha Ceritli, Savas Ozkan, Jeongwon Min, Eunchung Noh, Cho Jung Min, and Mete Ozay. 2024. A study of parameter efficient fine-tuning by learning to efficiently fine-tune. In *EMNLP Findings*, pages 15819– 15836.
- <span id="page-8-11"></span>Sauptik Dhar, Junyao Guo, Jiayi (Jason) Liu, Samarth Tripathi, Unmesh Kurup, and Mohak Shah. 2021. A survey of on-device machine learning: An algorithms and learning theory perspective. *ACM Trans. Internet Things*, 2(3).
- <span id="page-8-5"></span>Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, and 1 others. 2022. Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models. *arXiv preprint arXiv:2203.06904*.
- <span id="page-8-13"></span>Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan Ma, Rui Li, Heming Xia, Jingjing Xu, Zhiyong Wu, Baobao Chang, Xu Sun, Lei Li, and Zhifang Sui. 2024. A survey on in-context learning. In *EMNLP*.
- <span id="page-8-12"></span>Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, and 1 others. 2024. The llama 3 herd of models. *arXiv preprint arXiv:2407.21783*.
- <span id="page-8-17"></span>Arash Einolghozati, Anchit Gupta, Keith Diedrick, and Sonal Gupta. 2020. Sound natural: Content rephrasing in dialog systems. In *EMNLP*.
- <span id="page-8-18"></span>Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, and 1 others. 2021. Beyond englishcentric multilingual machine translation. *Journal of Machine Learning Research*, 22(107):1–48.

- <span id="page-8-23"></span>Gemma Gemma Team. 2024. Gemma 2: Improving open language models at a practical size. *arXiv preprint arXiv:2408.00118*.
- <span id="page-8-16"></span>Bogdan Gliwa, Iwona Mochol, Maciej Biesek, and Aleksander Wawer. 2019. SAMSum corpus: A humanannotated dialogue dataset for abstractive summarization. In *ACL*.
- <span id="page-8-22"></span>Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, and 1 others. 2024. The Llama 3 herd of models. *arXiv preprint arXiv:2407.21783*.
- <span id="page-8-3"></span>Tom Gunter, Zirui Wang, Chong Wang, Ruoming Pang, Andy Narayanan, Aonan Zhang, Bowen Zhang, Chen Chen, Chung-Cheng Chiu, David Qiu, and 1 others. 2024. Apple intelligence foundation language models. *arXiv preprint arXiv:2407.21075*.
- <span id="page-8-20"></span>Masato Hagiwara and Masato Mita. 2020. GitHub typo corpus: A large-scale multilingual dataset of misspellings and grammatical errors. In *LREC*.
- <span id="page-8-9"></span>Hasan Hammoud, Umberto Michieli, Fabio Pizzati, Philip Torr, Adel Bibi, Bernard Ghanem, and Mete Ozay. 2024. Model merging and safety alignment: One bad model spoils the bunch. In *EMNLP Findings*.
- <span id="page-8-6"></span>Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, and Sai Qian Zhang. 2024. Parameter-efficient finetuning for large models: A comprehensive survey. In *TMLR*.
- <span id="page-8-0"></span>Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. In *ICLR*.
- <span id="page-8-8"></span>Chengsong Huang, Qian Liu, Bill Yuchen Lin, Tianyu Pang, Chao Du, and Min Lin. 2024. Lorahub: Efficient cross-task generalization via dynamic lora composition. In *COLM*.
- <span id="page-8-4"></span>Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Suchin Gururangan, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi. 2023. Editing models with task arithmetic. In *ICLR*.
- <span id="page-8-15"></span>Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, and Hakim Sidahmed. 2024. Faithful persona-based conversational dataset generation with large language models. In *NLP4ConvAI*.
- <span id="page-8-2"></span>Dawid J Kopiczko, Tijmen Blankevoort, and Yuki M Asano. 2024. VeRA: Vector-based random matrix adaptation. *ICLR*.
- <span id="page-8-1"></span>Vladislav Lialin, Vijeta Deshpande, and Anna Rumshisky. 2023. Scaling down to scale up: A guide to parameter-efficient fine-tuning. *arXiv preprint arXiv:2303.15647*.

- <span id="page-9-6"></span>Shih-Yang Liu, Chien-Yi Wang, Hongxu Yin, Pavlo Molchanov, Yu-Chiang Frank Wang, Kwang-Ting Cheng, and Min-Hung Chen. 2024a. DoRA: Weightdecomposed low-rank adaptation. In *ICML*.
- <span id="page-9-0"></span>Yixin Liu, Kejian Shi, Katherine S He, Longtian Ye, Alexander R Fabbri, Pengfei Liu, Dragomir Radev, and Arman Cohan. 2024b. On learning to summarize with large language models as references. In *NAACL*.
- <span id="page-9-19"></span>Agnes Luhtaru, Elizaveta Korotkova, and Mark Fishel. 2024. No error left behind: Multilingual grammatical error correction with pre-trained translation models. In *EACL*.
- <span id="page-9-20"></span>Qi Lv, Ziqiang Cao, Lei Geng, Chunhui Ai, Xu Yan, and Guohong Fu. 2023. General and domain-adaptive chinese spelling check with error-consistent pretraining. *ACM Transactions on Asian and Low-Resource Language Information Processing*, 22(5):1–18.
- <span id="page-9-7"></span>Grigory Malinovsky, Umberto Michieli, Hasan Abed Al Kader Hammoud, Taha Ceritli, Hayder Elesedy, Mete Ozay, and Peter Richtarik. 2024. Randomized ´ asymmetric chain of LoRA: The first meaningful theoretical framework for low-rank adaptation. *arXiv preprint arXiv:2410.08305*.
- <span id="page-9-13"></span>Qwen Team. 2024. [Qwen2.5: A party of foundation](https://qwenlm.github.io/blog/qwen2.5/) [models.](https://qwenlm.github.io/blog/qwen2.5/)
- <span id="page-9-17"></span>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. In *EMNLP*.
- <span id="page-9-9"></span>Adithya Renduchintala, Tugrul Konuk, and Oleksii Kuchaiev. 2024. Tied-LoRA: Enhancing parameter efficiency of LoRA with weight tying. In *NAACL*.
- <span id="page-9-11"></span>Donald Shenaj, Ondrej Bohdal, Mete Ozay, Pietro Zanuttigh, and Umberto Michieli. 2025. Lora.rar: Learning to merge loras via hypernetworks for subject-style conditioned image generation. In *CVPR Workshop*.
- <span id="page-9-1"></span>Abigail Sticha, Norbert Braunschweiler, Rama Sanand Doddipatla, and Kate M Knill. 2024. Advancing faithfulness of large language models in goaloriented dialogue question answering. In *ACM Conference on Conversational User Interfaces*.
- <span id="page-9-15"></span>Chunlin Tian, Zhan Shi, Zhijiang Guo, Li Li, and Chengzhong Xu. 2024. HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning. In *NeurIPS*.
- <span id="page-9-18"></span>Jorg Tiedemann and Santhosh Thottingal. 2020. OPUS- ¨ MT — Building open translation services for the World. In *EAMT*.
- <span id="page-9-16"></span>Kumar Utsav. 2023. RedPajama-INCITE-Base-3Bv1 model finetuned for Paraphrasing and Changing the Tone. [https://huggingface.co/](https://huggingface.co/llm-toys) [llm-toys](https://huggingface.co/llm-toys).

- <span id="page-9-3"></span>Mitchell Wortsman, Gabriel Ilharco, Samir Ya Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari S Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, and 1 others. 2022. Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. In *ICML*.
- <span id="page-9-10"></span>Shitao Xiao, Zheng Liu, Peitian Zhang, and Xingrun Xing. 2024. LM-Cocktail: Resilient tuning of language models via model merging. In *ACL Findings*.
- <span id="page-9-2"></span>Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiaohui Tao, and Fu Lee Wang. 2023. Parameter-efficient fine-tuning methods for pretrained language models: A critical review and assessment. *arXiv preprint arXiv:2312.12148*.
- <span id="page-9-4"></span>Prateek Yadav, Derek Tam, Leshem Choshen, Colin A Raffel, and Mohit Bansal. 2024. TIES-merging: Resolving interference when merging models. In *NeurIPS*.
- <span id="page-9-12"></span>An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, and 40 others. 2024. Qwen2 technical report. *arXiv preprint arXiv:2407.10671*.
- <span id="page-9-5"></span>Le Yu, Bowen Yu, Haiyang Yu, Fei Huang, and Yongbin Li. 2024. Language models are super mario: Absorbing abilities from homologous models as a free lunch. In *ICML*.
- <span id="page-9-8"></span>Qingru Zhang, Minshuo Chen, Alexander Bukharin, Nikos Karampatziakis, Pengcheng He, Yu Cheng, Weizhu Chen, and Tuo Zhao. 2023. Adalora: Adaptive budget allocation for parameter-efficient finetuning. In *ICLR*.
- <span id="page-9-21"></span>Yue Zhang, Zhenghua Li, Zuyi Bao, Jiacheng Li, Bo Zhang, Chen Li, Fei Huang, and Min Zhang. 2022. MuCGEC: a multi-reference multi-source evaluation dataset for chinese grammatical error correction. In *NAACL*.
- <span id="page-9-14"></span>Jiacheng Zhu, Kristjan Greenewald, Kimia Nadjahi, Haitz Saez de Oc ´ ariz Borde, Rickard Br ´ uel Gabriels- ¨ son, Leshem Choshen, Marzyeh Ghassemi, Mikhail Yurochkin, and Justin Solomon. 2024. Asymmetry in low-rank adapters of foundation models. In *ICML*.

## A Appendix

We provide information about the datasets in Sec. [A.1,](#page-10-1) report analyses about the similarity between LoRA parameters in Sec. [A.2,](#page-10-2) and give more detailed results in Sec. [A.3.](#page-10-0)

## <span id="page-10-1"></span>A.1 Implementation Details

Table [6](#page-14-1) provides a summary of the datasets used in our experiments and additional information about our implementation. Table [7](#page-16-0) describes the prompts that we have used. For tone adjustment, we consider four tones, namely professional, casual, witty and (neutral) paraphrasing, which are combined to create a larger dataset. We utilize NVIDIA A40 for our experiments. Adapters are applied to the query, key, value, and output matrices for Llama-3.2-3B-Instruct, Llama-3.2-1B-Instruct, and Phi-3.5-mini-instruct, and to the query and value for Gemma-2-2B-it. Uniform merging coefficients are used for TA and DARE, whereas unary coefficients are used for TIES and DARE-TIES. We provide an implementation of our method in Figures [7,](#page-11-0) [8,](#page-12-0) [9.](#page-13-0)

## <span id="page-10-2"></span>A.2 Similarities Between LoRA Parameters

We perform Canonical Correlation Analysis (CCA) goodness of fit following [Zhu et al.](#page-9-14) [\(2024\)](#page-9-14) using LoRA matrices A and B obtained by fine-tuning Llama-3.2-3B-Instruct on English data. Fig. [10](#page-14-0) indicates that A parameters result in higher similarity scores than B parameters. Similarly, Fig. [11](#page-15-0) illustrates a similar trend using t-SNE plots where A parameters tend to converge to similar values.

# <span id="page-10-0"></span>A.3 Additional Results

Fig. [12](#page-15-1) illustrates how the number of parameters to store changes using HydraOpt. We also present detailed evaluations for Llama-3.2-3B-Instruct when merging across applications (Tables [8](#page-17-0)[-9\)](#page-17-1), languages (Tables [10-](#page-18-0)[11\)](#page-18-1) and tasks (Table [12\)](#page-19-0). Moreover, the average scores are reported in Table [13.](#page-20-0) Similarly, we present the detailed results under different ranks for Llama-3.2-3B-Instruct in Table [14,](#page-20-1) and the results for Gemma-2-2B-it LoRA-finetuned (Table [15\)](#page-20-2) and for Phi-3.5-mini-instruct LoRAfinetuned (Table [16\)](#page-20-3).Finally, Table [17](#page-21-0) compares the methods in terms of runtime and GPU memory, which show that HydraOpt introduces additional runtime; however, the merging operation is still reasonably fast with relatively small GPU memory overhead.

```
1 class HydraOpt(nn.Module):
2 def __init__(
3 self,
4 lora_parameters,
5 lora_names,
6 M,
7 T,
8 ) -> None:
9 super().__init__()
11 self.K = len(lora_names)
12 self.M = M
13 self.T = T
15 # trainable parameters
16 self.A_prime = nn.ModuleDict({})
17 self.B_primes = nn.ModuleDict({})
18 self.C_primes = None if self.K == self.M else nn.ParameterDict({})
20 keys = lora_parameters[lora_names[0]].keys()
21 for i in range(M):
22 peft_model_id = lora_names[i]
23 for key in keys:
24 # '.' can't be used in module_dict
25 key_ = key.replace(".", "_")
27 # initialize the shared A_prime
28 if i == 0 and "lora_A" in key:
29 r, in_features = lora_parameters[peft_model_id][key].shape
30 self.A_prime[key_] = nn.Linear(in_features, r, bias=False)
31 nn.init.kaiming_uniform_(
32 self.A_prime[key_].weight, a=math.sqrt(5)
33 )
35 # initialize the B_primes
36 if "lora_B" in key:
37 out_features, r = lora_parameters[peft_model_id][key].shape
38 self.B_primes[f"{key_}_{i}"] = nn.Linear(
39 r, out_features, bias=False
40 )
41 nn.init.zeros_(self.B_primes[f"{key_}_{i}"].weight)
43 # define coefficients if needed
44 if self.K != self.M:
45 for i in range(self.K):
46 for key in keys:
47 key_ = key.replace(".", "_")
49 if "lora_B" in key:
50 self.C_primes[f"{key_}_{i}"] = nn.Parameter(
51 nn.functional.softmax(
52 torch.randn(M) / T, dim=-1
53 )
54 )
56 def forward(self):
57 return self.A_prime, self.B_primes, self.C
```

![](_page_11_Figure_1.jpeg)

```
1 def hydra_loss(
2 A_prime, B_primes, C_primes, M, lora_parameters, lora_names, T
3 ):
4
5 keys = list(lora_parameters[lora_names[0]].keys())
6 K = len(lora_names)
7 J = len(keys)
8
9 for i, peft_model_id in enumerate(lora_names):
10 for j in range(J):
11 if j % 2 == 0:
12 A_key = keys[j]
13 B_key = keys[j + 1]
14 A_key_ = A_key.replace(".", "_")
15 B_key_ = B_key.replace(".", "_")
16
17 if "lora" not in A_key or "lora" not in B_key:
18 continue
19
20 # calculate the original model update
21 delta_W = lora_parameters[peft_model_id][B_key] @ lora_parameters[
               peft_model_id][A_key]
22
23 if K == M:
24 delta_W_prime = (
25 B_primes[f"{B_key_}_{i}"].weight @ A_prime[A_key_].weight
26 )
27 else:
28 delta_W_prime = torch.stack(
29 [
30 nn.functional.softmax(
31 C_primes[f"{B_key_}_{i}"] * T, dim=-1
32 )[l]
33 * B_primes[f"{B_key_}_{l}"].weight
34 @ A_prime[A_key_].weight
35 for l in range(M)
36 ]
37 ).sum(dim=0)
38 if i == 0 and j == 0:
39 total_loss = nn.functional.l1_loss(delta_W, delta_W_prime)
40 else:
41 total_loss += nn.functional.l1_loss(delta_W, delta_W_prime)
42
43 return total_loss / (K * J)
```

Figure 8: Implementation of HydraOpt loss function.

```
1 def hydraopt_merging(lora_parameters, lora_names, M, lr=0.01, epochs=1000, T=5.0):
3 hydraopt = HydraOpt(lora_parameters, lora_names, M=M, T=T)
4 hydraopt = hydraopt.to("cuda:0")
6 keys = list(lora_parameters[lora_names[0]].keys())
8 # move each pair of LoRA parameters to GPU
9 for i, peft_model_id in enumerate(lora_names):
10 for j in range(len(keys)):
11 if j % 2 == 0:
12 A_key = keys[j]
13 B_key = keys[j + 1]
14 if "lora" not in A_key or "lora" not in B_key:
15 continue
16 else:
17 lora_parameters[peft_model_id][B_key] = lora_parameters[
                     peft_model_id][B_key].to("cuda:0")
18 lora_parameters[peft_model_id][A_key] = lora_parameters[
                     peft_model_id][A_key].to("cuda:0")
21 optimizer = torch.optim.AdamW(hydraopt.parameters(), lr=lr)
22 for epoch in range(epochs):
23 optimizer.zero_grad()
25 # get the current parameters
26 A_prime, B_primes, C_primes = hydraopt()
28 # calculate the loss based on the distance to the original LoRA updates
29 loss = hydra_loss(
30 A_prime,
31 B_primes,
32 C_primes,
33 M,
34 lora_parameters,
35 lora_names
36 )
38 # backward pass
39 loss.backward()
41 # update weights
42 optimizer.step()
44 # obtain the mapping between the lora_Bs and B_primes parameters
45 B_mapping = {}
46 for task_index in range(len(lora_names)):
47 B_mapping[task_index] = {}
48 for key in keys:
49 key_ = key.replace(".", "_")
50 if "lora_B" in key:
51 if hydraopt.K == hydraopt.M:
52 selected_B_prime = task_index
53 else:
54 selected_B_prime = nn.functional.softmax(
55 hydraopt.C_primes[f"{key_}_{task_index}"] / T, dim=-1
56 ).argmax()
57 B_mapping[task_index][key] = selected_B_prime
59 return A_prime, B_primes, B_mapping
```

Figure 9: Implementation of HydraOpt merging.

<span id="page-14-1"></span>

| Task                     | Dataset                                 |          |         | Language # Training Samples # Validation Samples # Test Samples |        |
|--------------------------|-----------------------------------------|----------|---------|-----------------------------------------------------------------|--------|
|                          | ECSpell                                 | Chinese  | 6,680   | 750                                                             | 750    |
| Grammar Error Correction | Cambridge English Write & Improve (W&I) | English  | 23,523  | 2,526                                                           | 2,639  |
|                          | Merlin                                  | Italian  | 572     | 79                                                              | 81     |
|                          |                                         | French   | 616     | 240                                                             | 227    |
|                          |                                         | German   | 412     | 119                                                             | 132    |
|                          | GitHub Typo Corpus                      | Japanese | 1,043   | 325                                                             | 321    |
|                          |                                         | Korean   | 255     | 75                                                              | 93     |
|                          |                                         | Spanish  | 348     | 137                                                             | 116    |
| Smart Reply              | Persona-Chat Synthetic                  | English  | 225,061 | 25,847                                                          | 24,479 |
| Text Summarization       | SAMSum                                  | English  | 14,732  | 818                                                             | 819    |
| Tone Adjustment          | Sound Natural                           | All      | 2,245   | 321                                                             | 642    |
| Question Answering       | SQuAD                                   | English  | 65,699  | 21,900                                                          | 10,570 |

Table 6: Dataset statistics. Information about the datasets.

<span id="page-14-0"></span>![](_page_14_Figure_2.jpeg)

Figure 10: Similarity between A and B matrices of LoRAs measured using Canonical Correlation Analysis (CCA) goodness of fit as conducted by [Zhu et al.](#page-9-14) [\(2024\)](#page-9-14) on query matrices of Llama-3.2-3B-Instruct fine-tuned on English data.

<span id="page-15-0"></span>![](_page_15_Figure_0.jpeg)

Figure 11: t-SNE plots using LoRA parameters for query matrices of Llama-3.2-3B-Instruct fine-tuned across 5 applications in English. Numbers indicate which layer the parameter comes from. Shapes/colors indicate the application the model is fine-tuned for. The differences in the LoRA parameters for different tasks arise mainly from the B matrices.

<span id="page-15-1"></span>![](_page_15_Figure_2.jpeg)

Figure 12: The reduction in parameter size when using HydraOpt(M=K), assuming that the parameters A and B are the same size.

<span id="page-16-0"></span>

| Problem Type             | Language           | Prompt                                                                                                                                                    |
|--------------------------|--------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|
|                          | English            | Remove all grammatical errors from this text:                                                                                                             |
|                          | Spanish            | Quita todos los errores gramaticales de este texto:                                                                                                       |
|                          | French             | Supprimez tous les erreurs grammaticales de ce texte:                                                                                                     |
| Grammar Error Correction | German             | Verbessere alle grammatischen Fehler in diesem Text:                                                                                                      |
|                          | Italian            | Rimuovi tutti gli errori grammaticali da questo testo:                                                                                                    |
|                          | Chinese            | 除文本中的所有法:                                                                                                                                                 |
|                          | Korean             | 주어진 사용자의 입력에 오타나<br>문법 오류가 있으면 고친다:                                                                                                                       |
|                          | Japanese           | このテキストからすべての文法エラを削除する:                                                                                                                                    |
|                          | English            | Suggest a reply for the following text:                                                                                                                   |
|                          | Spanish            | Sugiera una respuesta para el texto siguiente:                                                                                                            |
|                          | French             | Propose une reponse pour le texte suivant:<br>´                                                                                                           |
| Smart Reply              | German             | Schlagen Sie eine Antwort fur den folgenden Text vor:<br>¨<br>Suggerisci una risposta per il seguente testo:                                              |
|                          | Italian<br>Chinese | 建以下文本行回:                                                                                                                                                  |
|                          | Korean             | 다음 텍스트에 대한<br>답변을 제안하시오:                                                                                                                                  |
|                          | Japanese           | 次のテキストにする返信を提案します:                                                                                                                                        |
|                          |                    | Summarize the following text:                                                                                                                             |
|                          | English<br>Spanish | Resume el siguiente texto:                                                                                                                                |
|                          | French             | Resume le texte suivant:<br>´                                                                                                                             |
|                          | German             | Zusammenfassen Sie den folgenden Text:                                                                                                                    |
| Text Summarization       | Italian            | Riassumi il seguente testo:                                                                                                                               |
|                          | Chinese            | 一下下面的文字:                                                                                                                                                  |
|                          | Korean             | 다음 텍스트를 요약하시오:                                                                                                                                            |
|                          | Japanese           | 次の文章を要約します:                                                                                                                                               |
|                          | English            | Changes a given user's input sentence or text to the Professional style:                                                                                  |
|                          | Spanish            | Cambia la oracion o el texto introducido por un usuario al estilo Profesional:<br>´                                                                       |
|                          | French             | Transforme la phrase ou le texte saisi par un utilisateur en style Professionnel:                                                                         |
| Tone Adj. (Professional) | German             | andert die Eingabe eines bestimmten Benutzers in einen Professionellen Stil:<br>¨                                                                         |
|                          | Italian            | Cambia la frase o il testo immesso da un utente in stile Professionale:                                                                                   |
|                          | Chinese            | 定用的入句子或文本更改格:                                                                                                                                             |
|                          | Korean             | 주어진 사용자의 입력을 전문적인 문체로 변경한다:<br>指定されたユザの入力文またはテキストを プロフェッショナル スタイルに更する:                                                                                    |
|                          | Japanese           |                                                                                                                                                           |
|                          | English            | Changes a given user's input sentence or text to the Casual style:                                                                                        |
|                          | Spanish            | Cambia la oracion o el texto introducido por un usuario al estilo Informal:<br>´                                                                          |
|                          | French             | Transforme la phrase ou le texte saisi par un utilisateur en style Informel:<br>andert die Eingabe eines bestimmten Benutzers in einen Freundlichen Stil: |
| Tone Adj. (Casual)       | German<br>Italian  | ¨<br>Cambia la frase o il testo immesso da un utente in stile Informal:                                                                                   |
|                          | Chinese            | 定用的入句子或文本更改日常格:                                                                                                                                           |
|                          | Korean             | 주어진 사용자의 입력을 평범한 문체로 변경한다:                                                                                                                                |
|                          | Japanese           | 指定されたユザの入力文またはテキストを カジュアル スタイルに更する:                                                                                                                       |
|                          | English            | Changes a given user's input sentence or text to the Witty style:                                                                                         |
|                          | Spanish            | Cambia la oracion o el texto introducido por un usuario al estilo Ingenioso:<br>´                                                                         |
|                          | French             | Transforme la phrase ou le texte saisi par un utilisateur en style Spirituel:                                                                             |
|                          | German             | andert die Eingabe eines bestimmten Benutzers in einen Witziger Stil:<br>¨                                                                                |
| Tone Adj. (Witty)        | Italian            | Cambia la frase o il testo immesso da un utente in stile Spiritoso:                                                                                       |
|                          | Chinese            | 定用的入句子或文本更改机智格:                                                                                                                                           |
|                          | Korean             | 주어진 사용자의 입력을 재치있는 문체로<br>변경한다:                                                                                                                            |
|                          | Japanese           | 指定されたユザの入力文またはテキストを ウィットに富んだ スタイルに更する:                                                                                                                    |
|                          | English            | Paraphrase the following text:                                                                                                                            |
|                          | Spanish            | Parafrasea el siguiente texto:                                                                                                                            |
|                          | French             | Paraphraser le texte suivant:                                                                                                                             |
| Tone Adj. (Paraphrase)   | German             | Fassen Sie den folgenden Text zusammen:                                                                                                                   |
|                          | Italian            | Parafrasare il testo seguente:                                                                                                                            |
|                          | Chinese            | 解以下文字:                                                                                                                                                    |
|                          | Korean<br>Japanese | 다음 텍스트를 의역하세요:<br>次のテキストを言い換えてください:                                                                                                                       |
|                          |                    |                                                                                                                                                           |
|                          | English            | Answer the following question:                                                                                                                            |
|                          | Spanish            | Responde a la siguiente pregunta:                                                                                                                         |
|                          | French             | Reponds ´ a la question suivante:<br>`                                                                                                                    |
| Question Answering       | German             | Beantworten Sie die folgende Frage:<br>Rispondi alla seguente domanda:                                                                                    |
|                          | Italian<br>Chinese | 回答以下:                                                                                                                                                     |
|                          | Korean             | 다음 질문에 답하시오:                                                                                                                                              |
|                          | Japanese           | 次の質問に答えましょう:                                                                                                                                              |
|                          |                    |                                                                                                                                                           |

Table 7: Prompts for each application and language. Details about the prompts we have used.

<span id="page-17-0"></span>Table 8: Performance when merging across 5 applications using Llama-3.2-3B-Instruct for En (English), De (German), Es (Spanish), and Fr (French). Results are reported per each language (L) and application separately.

<span id="page-17-1"></span>

| Table 9: Performance when merging across 5 appli         |
|----------------------------------------------------------|
| cations using Llama-3.2-3B-Instruct for It (Italian),    |
| Ja (Japanese), Ko (Korean), and Zh (Chinese). Re         |
| sults are reported per each language (L) and application |
| separately.                                              |

| Method        | L  | S (%) | GC   | SR   | TS   | TA   | QA   | Avg  | Method        | L  | S (%) | GC   | SR   | TS   | TA   | QA   | Avg  |
|---------------|----|-------|------|------|------|------|------|------|---------------|----|-------|------|------|------|------|------|------|
| Zero-shot     |    | 0     | 14.0 | 5.4  | 26.9 | 30.1 | 24.2 | 20.1 | Zero-shot     |    | 0     | 26.9 | 2.3  | 18.9 | 29.5 | 13.5 | 18.2 |
| LoRA          |    | 100   | 39.2 | 24.5 | 41.4 | 59.1 | 74.7 | 47.8 | LoRA          |    | 100   | 36.0 | 12.7 | 32.3 | 44.9 | 47.3 | 34.6 |
| TA            |    | 20    | 27.0 | 13.6 | 34.1 | 53.7 | 58.8 | 37.4 | TA            |    | 20    | 34.0 | 6.0  | 25.3 | 43.4 | 21.0 | 26.0 |
| TIES          |    | 20    | 26.2 | 14.9 | 32.4 | 53.3 | 48.2 | 35.0 | TIES          |    | 20    | 31.1 | 6.7  | 24.7 | 43.4 | 18.4 | 24.9 |
| DARE          |    | 20    | 27.4 | 14.9 | 34.5 | 54.2 | 61.9 | 38.6 | DARE          |    | 20    | 29.7 | 6.0  | 24.9 | 44.5 | 23.8 | 25.8 |
| DARE TIES     | En | 20    | 21.6 | 8.3  | 29.2 | 45.2 | 33.0 | 27.4 | DARE TIES     | It | 20    | 27.6 | 3.7  | 20.1 | 36.6 | 15.9 | 20.8 |
| HydraOpt(M=1) |    | 20    | 26.6 | 10.2 | 33.9 | 52.2 | 59.6 | 36.5 | HydraOpt(M=1) |    | 20    | 33.3 | 5.0  | 26.1 | 41.1 | 19.2 | 24.9 |
| HydraOpt(M=2) |    | 30    | 27.4 | 22.9 | 34.6 | 54.8 | 67.0 | 41.3 | HydraOpt(M=2) |    | 30    | 33.2 | 8.5  | 26.8 | 43.0 | 31.9 | 28.7 |
| HydraOpt(M=3) |    | 40    | 28.9 | 24.6 | 36.0 | 58.8 | 73.2 | 44.3 | HydraOpt(M=3) |    | 40    | 35.9 | 12.9 | 27.4 | 43.6 | 42.1 | 32.4 |
| HydraOpt(M=4) |    | 50    | 36.0 | 24.7 | 39.6 | 57.6 | 72.3 | 46.0 | HydraOpt(M=4) |    | 50    | 33.5 | 12.2 | 29.8 | 35.0 | 46.2 | 31.3 |
| HydraOpt(M=5) |    | 60    | 36.5 | 24.7 | 40.9 | 58.8 | 73.3 | 46.8 | HydraOpt(M=5) |    | 60    | 35.1 | 13.1 | 31.8 | 44.7 | 46.7 | 34.3 |
| Zero-shot     |    | 0     | 9.4  | 2.8  | 17.7 | 20.3 | 10.9 | 12.2 | Zero-shot     |    | 0     | 4.1  | 4.7  | 19.5 | 35.6 | 12.6 | 15.3 |
| LoRA          |    | 100   | 41.2 | 13.8 | 32.4 | 44.8 | 47.2 | 35.9 | LoRA          |    | 100   | 23.3 | 11.9 | 29.2 | 40.1 | 31.1 | 27.1 |
| TA            |    | 20    | 22.9 | 6.7  | 23.6 | 41.2 | 22.6 | 23.4 | TA            |    | 20    | 10.9 | 6.0  | 25.0 | 40.2 | 20.7 | 20.6 |
| TIES          |    | 20    | 19.5 | 6.8  | 22.9 | 40.9 | 18.7 | 21.8 | TIES          |    | 20    | 6.3  | 7.0  | 24.5 | 39.9 | 18.6 | 19.2 |
| DARE          |    | 20    | 26.4 | 6.6  | 20.5 | 42.7 | 29.4 | 25.1 | DARE          |    | 20    | 9.4  | 5.8  | 25.2 | 40.0 | 22.0 | 20.5 |
| DARE TIES     | De | 20    | 12.1 | 4.1  | 20.9 | 30.0 | 15.6 | 16.5 | DARE TIES     | Ja | 20    | 7.1  | 5.7  | 22.0 | 38.0 | 14.0 | 17.3 |
| HydraOpt(M=1) |    | 20    | 23.2 | 5.6  | 25.2 | 37.1 | 22.8 | 22.8 | HydraOpt(M=1) |    | 20    | 11.9 | 6.1  | 25.1 | 39.8 | 18.4 | 20.3 |
| HydraOpt(M=2) |    | 30    | 25.8 | 9.6  | 26.2 | 43.4 | 34.8 | 28.0 | HydraOpt(M=2) |    | 30    | 13.3 | 8.2  | 25.2 | 40.2 | 22.7 | 21.9 |
| HydraOpt(M=3) |    | 40    | 24.4 | 12.4 | 27.2 | 43.4 | 43.1 | 30.1 | HydraOpt(M=3) |    | 40    | 15.0 | 9.6  | 24.5 | 40.0 | 28.2 | 23.5 |
| HydraOpt(M=4) |    | 50    | 24.6 | 13.4 | 29.7 | 43.7 | 45.3 | 31.3 | HydraOpt(M=4) |    | 50    | 18.1 | 11.2 | 26.4 | 37.7 | 26.3 | 24.0 |
| HydraOpt(M=5) |    | 60    | 31.1 | 13.8 | 31.7 | 44.8 | 46.4 | 33.5 | HydraOpt(M=5) |    | 60    | 22.3 | 11.6 | 28.4 | 40.1 | 30.3 | 26.5 |
| Zero-shot     |    | 0     | 7.7  | 2.8  | 22.4 | 33.6 | 16.6 | 16.6 | Zero-shot     |    | 0     | 7.7  | 0.9  | 9.4  | 25.7 | 11.5 | 11.0 |
| LoRA          |    | 100   | 34.3 | 15.8 | 34.9 | 46.3 | 53.8 | 37.0 | LoRA          |    | 100   | 16.6 | 5.8  | 15.6 | 31.6 | 24.8 | 18.9 |
| TA            |    | 20    | 22.6 | 7.9  | 28.4 | 44.2 | 29.9 | 26.6 | TA            |    | 20    | 6.9  | 2.1  | 13.0 | 31.2 | 11.8 | 13.0 |
| TIES          |    | 20    | 16.9 | 8.7  | 27.0 | 44.3 | 23.7 | 24.1 | TIES          |    | 20    | 8.6  | 2.4  | 12.4 | 31.0 | 8.3  | 12.5 |
| DARE          |    | 20    | 23.3 | 7.9  | 28.5 | 45.2 | 30.0 | 27.0 | DARE          |    | 20    | 7.1  | 2.2  | 13.2 | 31.2 | 9.9  | 12.7 |
| DARE TIES     | Es | 20    | 8.4  | 4.8  | 24.1 | 37.9 | 21.2 | 19.3 | DARE TIES     | Ko | 20    | 7.9  | 1.7  | 10.7 | 28.0 | 12.3 | 12.1 |
| HydraOpt(M=1) |    | 20    | 20.8 | 6.3  | 29.2 | 42.5 | 28.6 | 25.5 | HydraOpt(M=1) |    | 20    | 7.8  | 1.9  | 12.4 | 30.6 | 12.3 | 13.0 |
| HydraOpt(M=2) |    | 30    | 24.7 | 11.7 | 30.3 | 44.2 | 35.2 | 29.2 | HydraOpt(M=2) |    | 30    | 9.0  | 3.0  | 12.4 | 31.2 | 15.7 | 14.2 |
| HydraOpt(M=3) |    | 40    | 25.3 | 15.1 | 31.5 | 45.4 | 46.8 | 32.8 | HydraOpt(M=3) |    | 40    | 8.8  | 4.2  | 13.2 | 25.9 | 22.5 | 14.9 |
| HydraOpt(M=4) |    | 50    | 22.9 | 13.6 | 32.8 | 40.8 | 52.4 | 32.5 | HydraOpt(M=4) |    | 50    | 9.4  | 5.1  | 13.2 | 29.7 | 22.2 | 15.9 |
| HydraOpt(M=5) |    | 60    | 31.2 | 15.1 | 34.5 | 46.1 | 53.1 | 36.0 | HydraOpt(M=5) |    | 60    | 15.4 | 5.7  | 15.7 | 31.4 | 24.5 | 18.5 |
| Zero-shot     |    | 0     | 10.2 | 3.6  | 20.8 | 28.5 | 11.3 | 14.9 | Zero-shot     |    | 0     | 3.7  | 1.6  | 20.2 | 24.8 | 12.1 | 12.5 |
| LoRA          |    | 100   | 30.2 | 15.0 | 34.0 | 47.8 | 42.8 | 34.0 | LoRA          |    | 100   | 48.6 | 7.9  | 27.6 | 37.3 | 30.1 | 30.3 |
| TA            |    | 20    | 20.8 | 7.6  | 28.1 | 46.0 | 29.0 | 26.3 | TA            |    | 20    | 10.6 | 3.7  | 24.1 | 37.8 | 19.9 | 19.2 |
| TIES          |    | 20    | 16.4 | 8.8  | 27.6 | 46.1 | 25.8 | 24.9 | TIES          |    | 20    | 10.3 | 3.9  | 23.6 | 37.0 | 18.4 | 18.6 |
| DARE          |    | 20    | 19.9 | 8.3  | 25.9 | 47.1 | 29.2 | 26.1 | DARE          |    | 20    | 6.3  | 3.7  | 23.4 | 37.9 | 19.3 | 18.1 |
| DARE TIES     | Fr | 20    | 13.1 | 5.5  | 23.5 | 36.9 | 14.5 | 18.7 | DARE TIES     | Zh | 20    | 6.2  | 2.4  | 21.0 | 30.2 | 14.6 | 14.9 |
| HydraOpt(M=1) |    | 20    | 19.3 | 6.8  | 28.7 | 43.3 | 27.4 | 25.1 | HydraOpt(M=1) |    | 20    | 11.7 | 3.4  | 24.2 | 36.2 | 18.0 | 18.7 |
| HydraOpt(M=2) |    | 30    | 20.4 | 11.3 | 30.2 | 45.9 | 32.7 | 28.1 | HydraOpt(M=2) |    | 30    | 17.0 | 4.9  | 24.9 | 38.0 | 23.2 | 21.6 |
| HydraOpt(M=3) |    | 40    | 22.4 | 13.9 | 30.6 | 46.8 | 37.7 | 30.3 | HydraOpt(M=3) |    | 40    | 38.1 | 7.0  | 24.7 | 37.9 | 27.8 | 27.1 |
|               |    | 50    | 24.9 | 14.1 | 31.6 | 29.9 | 41.3 | 28.4 |               |    | 50    | 44.0 | 6.4  | 24.9 | 35.7 | 28.3 | 27.8 |
| HydraOpt(M=4) |    | 60    | 30.8 | 14.9 | 33.8 | 47.8 | 42.4 | 34.0 | HydraOpt(M=4) |    | 60    | 46.4 | 7.3  | 27.1 | 37.1 | 29.6 | 29.5 |
| HydraOpt(M=5) |    |       |      |      |      |      |      |      | HydraOpt(M=5) |    |       |      |      |      |      |      |      |

<span id="page-18-0"></span>Table 10: Performance when merging across 8 languages using Llama-3.2-3B-Instruct. Results are reported per each language (L) and application separately.

<span id="page-18-1"></span>Table 11: Performance when merging across 8 languages using Llama-3.2-3B-Instruct. Results are reported per each language (L) and application separately.

| Method        | L  | S (%) | GC   | SR   | TS   | TA   | QA   | Avg  | Method        | L         | S (%) | GC   | SR   | TS   | TA   | QA   | Avg  |      |
|---------------|----|-------|------|------|------|------|------|------|---------------|-----------|-------|------|------|------|------|------|------|------|
| Zero-shot     |    | 0     | 14.0 | 5.4  | 26.9 | 30.1 | 24.2 | 20.1 | Zero-shot     |           | 0     | 26.9 | 2.3  | 18.9 | 29.5 | 13.5 | 18.2 |      |
| LoRA          |    | 100.0 | 39.2 | 24.5 | 41.4 | 59.1 | 74.7 | 47.8 | LoRA          |           | 100.0 | 36.0 | 12.7 | 32.3 | 44.9 | 47.3 | 34.6 |      |
| TA            |    | 12.5  | 27.6 | 15.3 | 35.8 | 49.6 | 75.5 | 40.8 | TA            |           | 12.5  | 34.0 | 6.3  | 32.4 | 42.8 | 45.3 | 32.2 |      |
| TIES          |    |       | 12.5 | 28.2 | 16.3 | 36.0 | 49.7 | 76.2 | 41.3          | TIES      |       | 12.5 | 34.2 | 6.1  | 32.6 | 42.4 | 46.3 | 32.3 |
| DARE          |    | 12.5  | 17.2 | 7.6  | 29.4 | 35.5 | 34.5 | 24.9 | DARE          |           | 12.5  | 28.6 | 3.6  | 21.6 | 35.9 | 18.9 | 21.7 |      |
| DARE TIES     |    |       | 12.5 | 19.4 | 8.6  | 30.5 | 40.0 | 41.6 | 28.1          | DARE TIES |       | 12.5 | 30.3 | 4.1  | 23.7 | 37.1 | 23.3 | 23.7 |
| HydraOpt(M=1) | En | 12.5  | 26.1 | 14.1 | 34.4 | 48.1 | 73.4 | 39.2 | HydraOpt(M=1) | It        | 12.5  | 33.1 | 5.9  | 31.1 | 41.8 | 43.1 | 31.0 |      |
| HydraOpt(M=2) |    | 17.5  | 27.1 | 16.7 | 35.3 | 50.3 | 72.6 | 40.4 | HydraOpt(M=2) |           | 17.5  | 33.8 | 6.6  | 30.9 | 42.1 | 45.0 | 31.7 |      |
| HydraOpt(M=3) |    | 22.5  | 29.5 | 17.9 | 36.9 | 51.6 | 71.2 | 41.4 | HydraOpt(M=3) |           | 22.5  | 35.0 | 6.3  | 32.1 | 42.6 | 44.3 | 32.1 |      |
| HydraOpt(M=4) |    | 27.5  | 29.3 | 19.4 | 37.1 | 53.4 | 69.8 | 41.8 | HydraOpt(M=4) |           | 27.5  | 35.3 | 7.4  | 31.0 | 43.1 | 45.5 | 32.4 |      |
| HydraOpt(M=5) |    | 32.5  | 36.2 | 21.2 | 41.2 | 57.0 | 63.0 | 43.7 | HydraOpt(M=5) |           | 32.5  | 35.5 | 7.7  | 31.0 | 43.4 | 46.1 | 32.7 |      |
| HydraOpt(M=6) |    | 37.5  | 38.9 | 23.4 | 40.5 | 58.2 | 67.0 | 45.6 | HydraOpt(M=6) |           | 37.5  | 34.7 | 9.7  | 31.8 | 43.8 | 45.5 | 33.1 |      |
| HydraOpt(M=7) |    | 42.5  | 39.1 | 24.1 | 41.0 | 57.9 | 72.4 | 46.9 | HydraOpt(M=7) |           | 42.5  | 35.8 | 6.8  | 31.5 | 42.6 | 45.6 | 32.5 |      |
| HydraOpt(M=8) |    | 47.5  | 36.9 | 23.9 | 41.1 | 58.5 | 73.3 | 46.7 | HydraOpt(M=8) |           | 47.5  | 35.0 | 11.4 | 31.7 | 44.5 | 46.3 | 33.8 |      |
| Zero-shot     |    | 0     | 9.4  | 2.8  | 17.7 | 20.3 | 10.9 | 12.2 | Zero-shot     |           | 0     | 4.1  | 4.7  | 19.5 | 35.6 | 12.6 | 15.3 |      |
| LoRA          |    | 100.0 | 41.2 | 13.8 | 32.4 | 44.8 | 47.2 | 35.9 | LoRA          |           | 100.0 | 23.3 | 11.9 | 29.2 | 40.1 | 31.1 | 27.1 |      |
| TA            |    | 12.5  | 30.5 | 7.7  | 31.5 | 41.2 | 46.2 | 31.4 | TA            |           | 12.5  | 18.8 | 6.1  | 27.3 | 40.4 | 29.6 | 24.5 |      |
| TIES          |    | 12.5  | 29.4 | 7.7  | 31.7 | 41.5 | 46.5 | 31.3 | TIES          |           | 12.5  | 21.5 | 5.9  | 27.5 | 39.7 | 30.4 | 25.0 |      |
| DARE          |    | 12.5  | 12.4 | 4.2  | 21.9 | 28.5 | 17.3 | 16.9 | DARE          |           | 12.5  | 8.9  | 5.4  | 22.5 | 37.9 | 17.6 | 18.5 |      |
| DARE TIES     |    | 12.5  | 14.1 | 4.9  | 24.2 | 31.3 | 21.8 | 19.2 | DARE TIES     |           | 12.5  | 11.1 | 5.9  | 23.6 | 38.5 | 22.3 | 20.3 |      |
| HydraOpt(M=1) | De | 12.5  | 25.8 | 7.2  | 29.9 | 39.7 | 47.1 | 30.0 | HydraOpt(M=1) | Ja        | 12.5  | 15.0 | 6.1  | 26.3 | 40.2 | 28.6 | 23.2 |      |
| HydraOpt(M=2) |    | 17.5  | 26.8 | 7.8  | 30.6 | 41.6 | 46.9 | 30.7 | HydraOpt(M=2) |           | 17.5  | 16.6 | 6.4  | 26.7 | 40.8 | 28.7 | 23.8 |      |
| HydraOpt(M=3) |    | 22.5  | 27.1 | 8.0  | 30.6 | 43.0 | 48.0 | 31.3 | HydraOpt(M=3) |           | 22.5  | 18.3 | 6.9  | 26.4 | 40.4 | 28.7 | 24.1 |      |
| HydraOpt(M=4) |    | 27.5  | 25.7 | 8.2  | 30.6 | 42.4 | 45.9 | 30.5 | HydraOpt(M=4) |           | 27.5  | 19.1 | 7.3  | 27.4 | 40.9 | 29.5 | 24.8 |      |
| HydraOpt(M=5) |    | 32.5  | 32.3 | 9.7  | 31.4 | 43.5 | 48.7 | 33.1 | HydraOpt(M=5) |           | 32.5  | 20.8 | 8.0  | 28.4 | 40.8 | 29.1 | 25.4 |      |
| HydraOpt(M=6) |    | 37.5  | 26.9 | 8.6  | 31.2 | 43.9 | 45.7 | 31.3 | HydraOpt(M=6) |           | 37.5  | 21.3 | 7.9  | 28.7 | 38.9 | 28.5 | 25.0 |      |
| HydraOpt(M=7) |    | 42.5  | 31.4 | 9.3  | 31.5 | 44.7 | 44.8 | 32.4 | HydraOpt(M=7) |           | 42.5  | 22.2 | 5.0  | 28.3 | 37.5 | 29.9 | 24.6 |      |
| HydraOpt(M=8) |    | 47.5  | 31.0 | 12.1 | 31.6 | 44.5 | 46.3 | 33.1 | HydraOpt(M=8) |           | 47.5  | 21.6 | 9.8  | 28.1 | 40.2 | 30.0 | 25.9 |      |
| Zero-shot     |    | 0     | 7.7  | 2.8  | 22.4 | 33.6 | 16.6 | 16.6 | Zero-shot     |           | 0     | 7.7  | 9.4  | 25.7 | 4.2  | 11.5 | 11.0 |      |
| LoRA          |    | 100.0 | 34.3 | 15.8 | 34.9 | 46.3 | 53.8 | 37.0 | LoRA          |           | 100.0 | 16.6 | 5.8  | 15.6 | 31.6 | 24.8 | 18.9 |      |
| TA            |    | 12.5  | 32.6 | 9.4  | 34.6 | 34.0 | 48.5 | 31.9 | TA            |           | 12.5  | 12.8 | 2.0  | 14.0 | 31.3 | 19.7 | 16.0 |      |
| TIES          |    | 12.5  | 33.1 | 9.0  | 34.8 | 29.7 | 49.3 | 31.2 | TIES          |           | 12.5  | 13.8 | 1.8  | 14.7 | 30.9 | 20.2 | 16.3 |      |
| DARE          |    | 12.5  | 9.8  | 4.9  | 26.8 | 37.8 | 24.9 | 20.8 | DARE          |           | 12.5  | 12.8 | 1.6  | 11.3 | 28.0 | 17.4 | 14.2 |      |
| DARE TIES     |    | 12.5  | 12.0 | 5.8  | 28.8 | 39.2 | 31.7 | 23.5 | DARE TIES     |           | 12.5  | 13.9 | 1.6  | 11.8 | 28.7 | 19.2 | 15.0 |      |
| HydraOpt(M=1) |    | 12.5  | 26.1 | 9.0  | 33.1 | 32.6 | 45.6 | 29.3 | HydraOpt(M=1) |           | 12.5  | 14.1 | 2.1  | 13.3 | 30.6 | 19.4 | 15.9 |      |
| HydraOpt(M=2) | Es | 17.5  | 28.6 | 9.4  | 33.5 | 43.6 | 48.0 | 32.6 | HydraOpt(M=2) | Ko        | 17.5  | 13.8 | 2.4  | 13.7 | 31.0 | 20.8 | 16.3 |      |
| HydraOpt(M=3) |    | 22.5  | 28.4 | 10.3 | 33.9 | 44.2 | 49.3 | 33.2 | HydraOpt(M=3) |           | 22.5  | 16.1 | 2.5  | 14.3 | 30.9 | 22.8 | 17.3 |      |
| HydraOpt(M=4) |    | 27.5  | 26.6 | 11.4 | 34.6 | 45.7 | 53.1 | 34.3 | HydraOpt(M=4) |           | 27.5  | 13.4 | 2.9  | 14.5 | 31.8 | 21.4 | 16.8 |      |
| HydraOpt(M=5) |    | 32.5  | 29.2 | 10.4 | 34.7 | 45.7 | 51.5 | 34.3 | HydraOpt(M=5) |           | 32.5  | 16.5 | 3.8  | 15.3 | 30.5 | 22.6 | 17.7 |      |
|               |    | 37.5  | 28.6 | 12.0 | 34.1 | 45.1 | 53.3 | 34.6 |               |           | 37.5  | 11.2 | 3.1  | 15.0 | 31.1 | 25.3 | 17.1 |      |
| HydraOpt(M=6) |    | 42.5  | 27.3 | 11.3 | 33.7 | 37.8 | 52.9 | 32.6 | HydraOpt(M=6) |           | 42.5  | 13.3 | 2.5  | 15.4 | 29.2 | 23.2 | 16.7 |      |
| HydraOpt(M=7) |    | 47.5  | 31.7 | 13.5 | 34.5 | 46.1 | 52.5 | 35.7 | HydraOpt(M=7) |           | 47.5  | 15.2 | 4.5  | 15.2 | 31.3 | 24.5 | 18.2 |      |
| HydraOpt(M=8) |    |       |      |      |      |      |      |      | HydraOpt(M=8) |           |       |      |      |      |      |      |      |      |
| Zero-shot     |    | 0     | 10.2 | 3.6  | 20.8 | 28.5 | 11.3 | 14.9 | Zero-shot     |           | 0     | 3.7  | 1.6  | 20.2 | 24.8 | 12.1 | 12.5 |      |
| LoRA          |    | 100.0 | 30.2 | 15.0 | 34.0 | 47.8 | 42.8 | 34.0 | LoRA          |           | 100.0 | 48.6 | 7.9  | 27.6 | 37.3 | 30.1 | 30.3 |      |
| TA            |    | 12.5  | 29.3 | 9.4  | 34.1 | 45.3 | 41.0 | 31.8 | TA            |           | 12.5  | 24.6 | 4.0  | 27.1 | 37.3 | 28.6 | 24.3 |      |
| TIES          |    | 12.5  | 30.4 | 9.6  | 34.4 | 45.0 | 42.2 | 32.3 | TIES          |           | 12.5  | 28.4 | 4.0  | 27.4 | 37.4 | 29.2 | 25.3 |      |
| DARE          |    | 12.5  | 13.5 | 5.5  | 24.8 | 35.7 | 18.0 | 19.5 | DARE          |           | 12.5  | 6.5  | 2.2  | 21.9 | 30.1 | 16.5 | 15.4 |      |
| DARE TIES     |    | 12.5  | 14.3 | 6.4  | 26.5 | 37.6 | 26.3 | 22.2 | DARE TIES     |           | 12.5  | 7.8  | 2.6  | 23.0 | 31.4 | 20.3 | 17.0 |      |
| HydraOpt(M=1) | Fr | 12.5  | 24.2 | 9.2  | 32.6 | 44.0 | 38.5 | 29.7 | HydraOpt(M=1) | Zh        | 12.5  | 12.6 | 3.6  | 26.1 | 36.4 | 26.5 | 21.0 |      |
| HydraOpt(M=2) |    | 17.5  | 29.8 | 9.1  | 33.5 | 45.2 | 39.1 | 31.3 | HydraOpt(M=2) |           | 17.5  | 19.6 | 3.9  | 26.7 | 36.8 | 28.0 | 23.0 |      |
| HydraOpt(M=3) |    | 22.5  | 26.7 | 9.7  | 33.8 | 45.9 | 40.8 | 31.4 | HydraOpt(M=3) |           | 22.5  | 38.3 | 4.4  | 26.6 | 38.2 | 28.2 | 27.2 |      |
| HydraOpt(M=4) |    | 27.5  | 29.5 | 9.4  | 33.6 | 46.9 | 41.9 | 32.3 | HydraOpt(M=4) |           | 27.5  | 41.9 | 5.0  | 27.0 | 37.5 | 29.2 | 28.1 |      |
| HydraOpt(M=5) |    | 32.5  | 31.6 | 9.6  | 33.7 | 47.4 | 40.2 | 32.5 | HydraOpt(M=5) |           | 32.5  | 43.1 | 5.2  | 27.1 | 37.6 | 27.7 | 28.1 |      |
| HydraOpt(M=6) |    | 37.5  | 31.1 | 10.3 | 33.8 | 47.8 | 41.8 | 32.9 | HydraOpt(M=6) |           | 37.5  | 43.8 | 4.9  | 27.3 | 35.1 | 29.2 | 28.1 |      |
| HydraOpt(M=7) |    | 42.5  | 30.3 | 10.2 | 33.0 | 46.8 | 39.0 | 31.9 | HydraOpt(M=7) |           | 42.5  | 43.4 | 4.7  | 24.3 | 36.1 | 26.2 | 26.9 |      |
| HydraOpt(M=8) |    | 47.5  | 31.4 | 13.6 | 33.9 | 47.6 | 41.9 | 33.7 | HydraOpt(M=8) |           | 47.5  | 46.2 | 6.9  | 27.0 | 37.3 | 29.6 | 29.4 |      |
|               |    |       |      |      |      |      |      |      |               |           |       |      |      |      |      |      |      |      |

<span id="page-19-0"></span>Table 12: Performance when merging across 40 tasks using Llama-3.2-3B-Instruct. Results are reported per each language (L) and application separately.

| Method                          | L  | S (%)        | GC           | SR          | TS           | TA           | QA           | Avg          |
|---------------------------------|----|--------------|--------------|-------------|--------------|--------------|--------------|--------------|
| Zero-shot                       |    | 0            | 14.0         | 5.4         | 26.9         | 30.1         | 24.2         | 20.1         |
| LoRA                            |    | 100.0        | 39.2         | 24.5        | 41.4         | 59.1         | 74.7         | 47.8         |
| TA                              |    | 2.5          | 23.9         | 8.7         | 30.6         | 49.0         | 40.5         | 30.5         |
| TIES                            | En | 2.5          | 23.3         | 8.7         | 30.3         | 48.2         | 35.9         | 29.3         |
| DARE                            |    | 2.5          | 15.7         | 6.6         | 28.2         | 33.7         | 25.9         | 22.0         |
| DARE-TIES                       |    | 2.5          | 15.6         | 6.6         | 28.2         | 33.7         | 25.8         | 22.0         |
| HydraOpt(M=1)<br>HydraOpt(M=40) |    | 2.5<br>41.5  | 24.2<br>28.9 | 7.8<br>22.1 | 30.3<br>35.6 | 49.1<br>57.0 | 42.3<br>71.3 | 30.8<br>43.0 |
| Zero-shot                       |    | 0            | 9.4          | 2.8         | 17.7         | 20.3         | 10.9         | 12.2         |
| LoRA                            |    | 100.0        | 41.2         | 13.8        | 32.4         | 44.8         | 47.2         | 35.9         |
| TA                              |    | 2.5          | 20.6         | 6.0         | 24.9         | 35.5         | 19.4         | 21.3         |
| TIES                            |    | 2.5          | 17.5         | 6.0         | 24.2         | 34.9         | 18.1         | 20.2         |
| DARE                            | De | 2.5          | 11.5         | 3.2         | 19.3         | 25.3         | 12.6         | 14.4         |
| DARE-TIES                       |    | 2.5          | 11.8         | 3.3         | 19.1         | 25.4         | 12.5         | 14.4         |
| HydraOpt(M=1)                   |    | 2.5          | 22.7         | 5.6         | 25.6         | 34.3         | 21.3         | 21.9         |
| HydraOpt(M=40)                  |    | 41.5         | 20.3         | 7.2         | 27.7         | 42.4         | 31.2         | 25.8         |
| Zero-shot                       |    | 0            | 7.7          | 2.8         | 22.4         | 33.6         | 16.6         | 16.6         |
| LoRA<br>TA                      |    | 100.0<br>2.5 | 34.3<br>19.2 | 15.8<br>6.8 | 34.9<br>28.9 | 46.3<br>41.5 | 53.8<br>25.4 | 37.0<br>24.4 |
| TIES                            |    | 2.5          | 15.5         | 6.5         | 28.3         | 40.0         | 22.8         | 22.6         |
| DARE                            | Es | 2.5          | 7.9          | 3.7         | 24.0         | 36.6         | 19.7         | 18.4         |
| DARE-TIES                       |    | 2.5          | 7.4          | 3.8         | 23.6         | 36.2         | 19.1         | 18.0         |
| HydraOpt(M=1)                   |    | 2.5          | 20.3         | 6.2         | 29.2         | 42.3         | 27.6         | 25.1         |
| HydraOpt(M=40)                  |    | 41.5         | 17.7         | 8.8         | 31.5         | 42.6         | 24.4         | 25.0         |
| Zero-shot                       |    | 0            | 10.2         | 3.6         | 20.8         | 28.5         | 11.3         | 14.9         |
| LoRA                            |    | 100.0        | 30.2         | 15.0        | 34.0         | 47.8         | 42.8         | 34.0         |
| TA                              |    | 2.5          | 17.5         | 7.2         | 27.5         | 43.2         | 23.3         | 23.8         |
| TIES                            | Fr | 2.5          | 15.8         | 7.2         | 26.7         | 42.1         | 20.4         | 22.4         |
| DARE                            |    | 2.5          | 12.4         | 4.5         | 22.1         | 33.5         | 12.1         | 16.9         |
| DARE-TIES<br>HydraOpt(M=1)      |    | 2.5<br>2.5   | 12.3<br>19.2 | 4.6<br>6.8  | 22.0<br>28.9 | 33.7<br>42.1 | 11.8<br>24.6 | 16.9<br>24.3 |
| HydraOpt(M=40)                  |    | 41.5         | 23.3         | 8.4         | 31.2         | 45.2         | 27.1         | 27.0         |
| Zero-shot                       |    | 0            | 26.9         | 2.3         | 18.9         | 29.5         | 13.5         | 18.2         |
| LoRA                            |    | 100.0        | 36.0         | 12.7        | 32.3         | 44.9         | 47.3         | 34.6         |
| TA                              |    | 2.5          | 33.0         | 4.9         | 26.7         | 41.7         | 19.7         | 25.2         |
| TIES                            | It | 2.5          | 30.5         | 4.8         | 26.0         | 40.6         | 18.1         | 24.0         |
| DARE                            |    | 2.5          | 26.7         | 2.7         | 19.7         | 34.6         | 15.2         | 19.8         |
| DARE-TIES                       |    | 2.5          | 26.6         | 2.7         | 19.6         | 34.7         | 14.9         | 19.7         |
| HydraOpt(M=1)                   |    | 2.5          | 33.5         | 5.1         | 27.2         | 41.2         | 19.1         | 25.2         |
| HydraOpt(M=40)                  |    | 41.5         | 33.2         | 5.9         | 29.2         | 41.4         | 20.7         | 26.1         |
| Zero-shot<br>LoRA               |    | 0<br>100.0   | 4.1<br>23.3  | 4.7<br>11.9 | 19.5<br>29.2 | 35.6<br>40.1 | 12.6<br>31.1 | 15.3<br>27.1 |
| TA                              |    | 2.5          | 9.8          | 6.2         | 22.5         | 39.3         | 18.9         | 19.3         |
| TIES                            |    | 2.5          | 9.4          | 6.0         | 22.3         | 39.2         | 18.0         | 19.0         |
| DARE                            | Ja | 2.5          | 6.3          | 4.9         | 20.7         | 37.2         | 13.0         | 16.4         |
| DARE-TIES                       |    | 2.5          | 6.1          | 5.0         | 20.8         | 37.3         | 12.9         | 16.4         |
| HydraOpt(M=1)                   |    | 2.5          | 11.6         | 6.2         | 23.3         | 39.3         | 17.7         | 19.6         |
| HydraOpt(M=40)                  |    | 41.5         | 13.8         | 6.4         | 23.3         | 39.1         | 24.5         | 21.4         |
| Zero-shot                       |    | 0            | 7.7          | 0.9         | 9.4          | 25.7         | 11.5         | 11.0         |
| LoRA                            |    | 100.0        | 16.6         | 5.8         | 15.6         | 31.6         | 24.8         | 18.9         |
| TA                              |    | 2.5          | 9.0          | 1.6         | 10.6         | 30.7         | 13.1         | 13.0         |
| TIES                            | Ko | 2.5          | 8.1          | 1.8         | 10.6         | 30.6         | 12.3         | 12.7         |
| DARE<br>DARE-TIES               |    | 2.5<br>2.5   | 9.1<br>8.9   | 1.3<br>1.4  | 10.1<br>10.0 | 27.4<br>27.5 | 12.1<br>11.9 | 12.0<br>11.9 |
| HydraOpt(M=1)                   |    | 2.5          | 8.4          | 1.6         | 11.2         | 30.3         | 13.5         | 13.0         |
| HydraOpt(M=40)                  |    | 41.5         | 13.8         | 1.8         | 10.7         | 30.8         | 15.5         | 14.5         |
| Zero-shot                       |    | 0            | 3.7          | 1.6         | 20.2         | 24.8         | 12.1         | 12.5         |
| LoRA                            |    | 100.0        | 48.6         | 7.9         | 27.6         | 37.3         | 30.1         | 30.3         |
| TA                              |    | 2.5          | 7.9          | 3.1         | 22.6         | 35.2         | 15.9         | 16.9         |
| TIES                            | Zh | 2.5          | 6.7          | 2.9         | 22.7         | 34.9         | 15.2         | 16.5         |
| DARE                            |    | 2.5          | 4.2          | 1.8         | 20.4         | 29.1         | 13.1         | 13.7         |
| DARE-TIES                       |    | 2.5          | 4.5          | 1.9         | 20.4         | 29.5         | 12.8         | 13.8         |
| HydraOpt(M=1)                   |    | 2.5          | 7.9          | 2.6         | 22.9         | 33.3         | 15.2         | 16.4         |
| HydraOpt(M=40)                  |    | 41.5         | 12.5         | 3.7         | 24.7         | 35.6         | 16.3         | 18.5         |

<span id="page-20-0"></span>Table 13: Performance on 40 tasks using Llama-3.2- 3B-Instruct LoRA-finetuned after merging LoRAs across applications, languages and tasks. S represents the percentage of parameters compared to storing all 40 LoRAs.

|              | Method         | S (%) | GC   | SR   | TS   | TA   | QA   | Avg  |
|--------------|----------------|-------|------|------|------|------|------|------|
|              | Zero-shot      | 0.0   | 10.5 | 3.0  | 19.5 | 28.5 | 14.1 | 15.1 |
|              | LoRA           | 100.0 | 33.7 | 13.4 | 30.9 | 44.0 | 44.0 | 33.2 |
|              | TA             | 20.0  | 19.5 | 6.7  | 25.2 | 42.2 | 26.7 | 24.1 |
|              | TIES           | 20.0  | 14.9 | 6.0  | 22.9 | 38.7 | 20.1 | 20.5 |
|              | DARE           | 20.0  | 18.7 | 6.9  | 24.5 | 42.9 | 28.2 | 24.2 |
| applications | DARE-TIES      | 20.0  | 13.0 | 4.5  | 21.5 | 35.3 | 17.6 | 18.4 |
|              | HydraOpt(M=1)  | 20.0  | 19.3 | 5.7  | 25.6 | 40.4 | 25.8 | 23.3 |
|              | HydraOpt(M=2)  | 28.0  | 21.3 | 10.0 | 26.3 | 42.6 | 32.9 | 26.6 |
|              | HydraOpt(M=3)  | 36.0  | 24.8 | 12.5 | 26.9 | 42.7 | 40.2 | 29.4 |
|              | HydraOpt(M=4)  | 44.0  | 26.7 | 12.6 | 28.5 | 38.8 | 41.8 | 29.7 |
|              | HydraOpt(M=5)  | 52.0  | 31.1 | 13.3 | 30.5 | 43.9 | 43.3 | 32.4 |
|              | TA             | 12.5  | 26.3 | 7.5  | 29.6 | 40.2 | 41.8 | 29.1 |
|              | TIES           | 12.5  | 21.4 | 6.3  | 26.9 | 37.5 | 34.2 | 25.3 |
|              | DARE           | 12.5  | 13.7 | 4.4  | 22.5 | 33.7 | 20.6 | 19.0 |
|              | DARE-TIES      | 12.5  | 15.4 | 5.0  | 24.0 | 35.5 | 25.8 | 21.1 |
|              | HydraOpt(M=1)  | 12.5  | 22.1 | 7.1  | 28.4 | 39.2 | 40.3 | 27.4 |
| languages    | HydraOpt(M=2)  | 17.5  | 24.5 | 7.8  | 28.8 | 41.4 | 41.1 | 28.7 |
|              | HydraOpt(M=3)  | 22.5  | 27.4 | 8.2  | 29.3 | 42.1 | 41.6 | 29.7 |
|              | HydraOpt(M=4)  | 27.5  | 27.6 | 8.9  | 29.5 | 42.7 | 42.0 | 30.1 |
|              | HydraOpt(M=5)  | 32.5  | 30.6 | 9.4  | 30.4 | 43.2 | 41.1 | 31.0 |
|              | HydraOpt(M=6)  | 37.5  | 29.6 | 10.0 | 30.3 | 43.0 | 42.0 | 31.0 |
|              | HydraOpt(M=7)  | 42.5  | 30.3 | 9.2  | 29.8 | 41.6 | 41.8 | 30.6 |
|              | HydraOpt(M=8)  | 47.5  | 31.1 | 12.0 | 30.4 | 43.7 | 43.1 | 32.1 |
| tasks        | TA             | 2.5   | 17.6 | 5.6  | 24.3 | 39.5 | 22.0 | 21.8 |
|              | TIES           | 2.5   | 13.7 | 4.6  | 22.2 | 35.5 | 17.7 | 18.7 |
|              | DARE           | 2.5   | 11.7 | 3.6  | 20.5 | 32.2 | 15.4 | 16.7 |
|              | DARE-TIES      | 2.5   | 11.6 | 3.6  | 20.4 | 32.3 | 15.2 | 16.6 |
|              | HydraOpt(M=1)  | 2.5   | 18.5 | 5.2  | 24.8 | 39.0 | 22.7 | 22.0 |
|              | HydraOpt(M=40) | 41.5  | 20.4 | 8.0  | 26.7 | 41.8 | 28.9 | 25.2 |

<span id="page-20-2"></span>Table 15: Performance on 5 English applications using Gemma-2-2B-it LoRA-finetuned. S represents the percentage of the parameters compared to storing 5 LoRAs. Results are reported per each application separately.

| Method        | S (%) | GC   | SR   | TS   | TA   | QA   | Avg  |
|---------------|-------|------|------|------|------|------|------|
| Zero-shot     | 0.0   | 19.4 | 4.3  | 27.4 | 31.0 | 21.7 | 20.8 |
| LoRA          | 100.0 | 40.0 | 24.4 | 41.1 | 58.0 | 75.8 | 47.9 |
| TA            | 20.0  | 29.5 | 14.9 | 34.9 | 51.4 | 57.9 | 37.7 |
| TIES          | 20.0  | 28.6 | 14.9 | 33.0 | 51.4 | 47.7 | 35.1 |
| DARE          | 20.0  | 23.1 | 4.5  | 28.9 | 38.6 | 27.8 | 24.6 |
| DARE TIES     | 20.0  | 24.0 | 5.0  | 29.0 | 41.1 | 29.5 | 25.7 |
| HydraOpt(M=1) | 20.0  | 29.3 | 12.2 | 35.9 | 49.4 | 53.5 | 36.0 |
| HydraOpt(M=2) | 28.0  | 28.7 | 20.7 | 36.1 | 53.6 | 62.5 | 40.3 |
| HydraOpt(M=3) | 36.0  | 28.5 | 23.1 | 37.2 | 57.1 | 67.3 | 42.6 |
| HydraOpt(M=4) | 44.0  | 26.5 | 23.2 | 39.2 | 56.5 | 72.8 | 43.7 |
| HydraOpt(M=5) | 52.0  | 39.2 | 23.7 | 40.8 | 58.1 | 75.8 | 47.5 |

<span id="page-20-1"></span>Table 14: Performance on 5 English applications using Llama-3.2-1B-Instruct LoRA-finetuned at variable rank. S represents the percentage of the parameters compared to storing 5 LoRAs. Results are reported per each application separately.

| Rank | Method        | S (%) | GC   | SR   | TS   | TA   | QA   | Avg  |
|------|---------------|-------|------|------|------|------|------|------|
|      | Zero-shot     | 0.0   | 13.1 | 5.1  | 23.4 | 27.6 | 15.8 | 17.0 |
|      | LoRA          | 100.0 | 26.9 | 20.4 | 35.4 | 56.3 | 57.2 | 39.2 |
|      | TA            | 20.0  | 25.4 | 10.6 | 30.1 | 51.1 | 24.6 | 28.4 |
|      | TIES          | 20.0  | 23.9 | 11.8 | 28.8 | 51.6 | 24.6 | 28.1 |
|      | DARE          | 20.0  | 17.8 | 6.7  | 25.2 | 35.0 | 18.9 | 20.7 |
|      | DARE TIES     | 20.0  | 19.9 | 7.5  | 26.0 | 38.6 | 19.8 | 22.4 |
| 8    | HydraOpt(M=1) | 20.0  | 25.1 | 8.5  | 29.9 | 48.0 | 23.8 | 27.1 |
|      | HydraOpt(M=2) | 28.0  | 24.6 | 15.5 | 30.0 | 50.6 | 29.5 | 30.0 |
|      | HydraOpt(M=3) | 36.0  | 25.5 | 18.7 | 30.4 | 53.5 | 41.4 | 33.9 |
|      | HydraOpt(M=4) | 44.0  | 26.3 | 19.1 | 30.1 | 55.9 | 40.2 | 34.3 |
|      | HydraOpt(M=5) | 52.0  | 26.5 | 20.0 | 32.8 | 56.7 | 56.4 | 38.5 |
|      | LoRA          | 100.0 | 32.6 | 21.6 | 36.9 | 57.2 | 60.4 | 41.7 |
|      | TA            | 20.0  | 25.6 | 10.6 | 31.2 | 50.7 | 26.5 | 28.9 |
|      | TIES          | 20.0  | 24.6 | 13.1 | 29.6 | 52.6 | 26.0 | 29.2 |
|      | DARE          | 20.0  | 18.7 | 7.0  | 26.1 | 37.8 | 19.6 | 21.8 |
|      | DARE TIES     | 20.0  | 20.8 | 7.7  | 27.0 | 42.6 | 20.9 | 23.8 |
| 16   | HydraOpt(M=1) | 20.0  | 26.1 | 8.9  | 31.6 | 49.6 | 25.2 | 28.3 |
|      | HydraOpt(M=2) | 28.0  | 25.6 | 18.4 | 31.3 | 51.9 | 28.0 | 31.0 |
|      | HydraOpt(M=3) | 36.0  | 26.7 | 20.7 | 31.1 | 56.1 | 43.5 | 35.6 |
|      | HydraOpt(M=4) | 44.0  | 26.4 | 20.1 | 34.0 | 56.0 | 57.1 | 38.7 |
|      | HydraOpt(M=5) | 52.0  | 29.1 | 20.3 | 36.2 | 56.3 | 58.0 | 40.0 |

<span id="page-20-3"></span>Table 16: Performance on 5 English applications using Phi-3.5-mini-instruct LoRA-finetuned. S represents the percentage of the parameters compared to storing 5 LoRAs. Results are reported per each application separately.

| Method        | S (%) | GC   | SR   | TS   | TA   | QA   | Avg  |
|---------------|-------|------|------|------|------|------|------|
| Zero-shot     | 0.0   | 19.1 | 2.6  | 23.6 | 21.5 | 7.5  | 14.9 |
| LoRA          | 100.0 | 33.3 | 25.1 | 39.9 | 58.0 | 71.0 | 45.4 |
| TA            | 20.0  | 26.8 | 10.3 | 33.1 | 49.4 | 47.0 | 33.3 |
| TIES          | 20.0  | 26.7 | 12.9 | 32.1 | 52.3 | 46.4 | 34.1 |
| DARE          | 20.0  | 22.3 | 3.7  | 25.9 | 38.1 | 10.8 | 20.1 |
| DARE TIES     | 20.0  | 22.3 | 3.7  | 25.9 | 38.1 | 10.8 | 20.1 |
| HydraOpt(M=1) | 20.0  | 26.7 | 7.4  | 33.7 | 45.6 | 39.5 | 30.6 |
| HydraOpt(M=2) | 28.0  | 27.4 | 18.4 | 34.7 | 52.2 | 71.1 | 40.8 |
| HydraOpt(M=3) | 36.0  | 28.0 | 23.3 | 36.7 | 57.5 | 71.0 | 43.3 |
| HydraOpt(M=4) | 44.0  | 29.7 | 21.0 | 36.8 | 56.8 | 67.7 | 42.4 |
| HydraOpt(M=5) | 52.0  | 32.7 | 25.0 | 40.0 | 57.7 | 70.7 | 45.2 |
|               |       |      |      |      |      |      |      |

<span id="page-21-0"></span>Table 17: Comparison of the methods in terms of runtime and GPU memory. The results indicate that HydraOpt introduces additional runtime; however, the merging operation is still reasonably fast with relatively small GPU memory overhead.

| Metric         |      |      |      |      |      |      |      | TA TIES DARE DARE-TIES HydraOpt(M=1) HydraOpt(M=2) HydraOpt(M=3) HydraOpt(M=4) HydraOpt(M=5) |      |
|----------------|------|------|------|------|------|------|------|----------------------------------------------------------------------------------------------|------|
| Runtime (mins) | 0.7  | 0.6  | 0.7  | 0.7  | 10.6 | 13.9 | 17.2 | 20.6                                                                                         | 8.6  |
| GPU (GB)       | 19.6 | 19.6 | 19.6 | 19.6 | 20.5 | 20.7 | 21.0 | 21.3                                                                                         | 20.7 |