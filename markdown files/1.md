# Design and Reliability of a User Space Write-Ahead Log in Rust

Vitor K. F. Pellegatti

Department of Computing at Sorocaba (DComp) Federal University of Sao Carlos ˜ Sorocaba, Sao Paulo, Brazil ˜ Email: vitor.pellegatti@estudante.ufscar.br

*Abstract*—Write-ahead logs (WALs) are a fundamental faulttolerance technique found in many areas of computer science. WALs must be reliable while maintaining high performance, because all operations will be written to the WAL to ensure their stability. Without reliability a WAL is useless, because its utility is tied to its ability to recover data after a failure. In this paper we describe our experience creating a prototype user space WAL in Rust. We observed that Rust is easy to use, compact and has a very rich set of libraries. More importantly, we have found that the overhead is minimal, with the WAL prototype operating at basically the expected performance of the stable memory device.

#### *Index Terms*—Fault tolerance, write-ahead log, Rust.

#### I. INTRODUCTION

Write-ahead logs (WALs) are a fundamental fault-tolerance technique found in many areas of computer science [\[1\]](#page-5-0), from database management systems [\[2\]](#page-5-1), [\[3\]](#page-5-2) to operating systems and distributed systems [\[4\]](#page-5-3). The idea behind a WAL is to commit to stable storage a log of operations that *will* be performed in the system, before the operations are even started. Usually, the operations logged are long and/or complex and can leave the system in an invalid state if interrupted by a fault during execution. By consulting the log during recovery after a crash, the system can ensure these operations are effectively applied and the system stays consistent.

As a central piece in the fault tolerance puzzle, WALs must be reliable while maintaining high performance, because all operations will be written to the WAL. Without reliability a WAL is useless, because its utility is tied to its ability to recover data after a failure. Moreover, recovery performance is also very important, because a system under recovery is an unavailable system. To muddle the waters further, with the rising use of solid state stable memory such as SSDs, reliability of the storage device must also be managed [\[5\]](#page-5-4).

We see as an important research subject the construction of safe and reliable system-level infrastructure. In this context, the widely loved Rust language [\[6\]](#page-5-5) offers safer code and Clevel performance. Safety in this case usually refers to correct memory access, but Rust provides more with a type system that allows safe concurrent programming [\[7\]](#page-5-6) and advanced program analysis [\[8\]](#page-5-7).

In this paper we describe our experience creating a *prototype* user space WAL in Rust. Our motivation was to assess if this

Gustavo M. D. Vieira Department of Computing at Sorocaba (DComp) Federal University of Sao Carlos ˜ Sorocaba, Sao Paulo, Brazil ˜ Email: gdvieira@ufscar.br

language has: 1) the abstractions to create a productive application level API, 2) the infrastructure to handle serialization and low level file I/O, 3) actual reliability regarding crashes and file corruption and 4) low overhead leading to good performance. To assess these points, we subjected our prototype to a series of reliability and performance experiments.

We have observed that programming interfaces and ergonomics of the language are excellent, producing very readable code. Serialization and file I/O are well supported and mature, with a good number of ready made solutions and proper interfaces for creating our own. Reliability at the code level is excellent, but overall reliability is limited by the ondisk serialization format. Finally, our experiments have shown that overhead is minimal, operating at basically the expected performance of the stable memory device.

This paper is organized as follows. Sections [II](#page-0-0) and [III](#page-1-0) give a background in WALs and the Rust programming language. Section [IV](#page-1-1) describes the design requirements and decisions of our WAL prototype. Section [V](#page-3-0) shows our experimental results and Section [VI](#page-5-8) closes the paper with our conclusions.

## II. WRITE-AHEAD LOGS

<span id="page-0-0"></span>*Write-ahead log* (WAL) is a recovery technique first used in database managements systems [\[1\]](#page-5-0). It consists in writing to stable storage a log of changes to be performed in the application state before effectively applying them. By forcing the log write to be stable before performing the state change, it is possible to recover the application state afterwards with an appropriate recovery algorithm [\[9\]](#page-5-9). This is particularly relevant if the state change to be performed in composed of many writes to stable memory that must be atomic to maintain state consistency [\[2\]](#page-5-1). A *checkpoint* is a record in the log where the application state itself is completely written to stable storage and is used by many recovery algorithms as their starting point [\[3\]](#page-5-2).

Another simpler, perhaps more interesting, way that writeahead logs can be used is when *no writes* are done to stable memory as part of a state change [\[10\]](#page-5-10). The application state is kept in main-memory and the write-ahead log becomes the sole registry of the state change in stable memory, while the change happens in volatile memory only. If a crash occurs, the recovery algorithm consists in replaying all state changes recorded in the log. We call such WAL an *operation replay log*. This approach streamlines all writes to stable memory in sequential units that extract the most performance out of the stable memory subsystem [\[11\]](#page-5-11). Recovery, however, becomes very expensive, requiring reading all the log records and reapplying them sequentially. In this context, checkpoints in the log are very important to speed up recovery and must be paired with dumps of the application state to stable memory [\[10\]](#page-5-10).

Write-ahead logs are a very important technique, used in several contexts from databases to file systems. Research in WALs followed its applications, focused in their performance. For example, the most critical step for performance in a WAL scheme is the writing of the individual records. The write performance can be improved by using parallel processing [\[4\]](#page-5-3), [\[12\]](#page-5-12), by writing to novel types of stable memory [\[13\]](#page-5-13) or by storing the WAL in a distinct device [\[14\]](#page-5-14), among many other strategies. Another important approach to improve WAL performance are *log-structured* data structures, where the application state is kept in persistent memory *inside* the WAL [\[15\]](#page-5-15). This way, stable writes are minimized and recovery speed can be greatly increased.

Another research concern about WALs is their reliability, as they are central to recovery of applications in the presence of serious faults. Some research went into securing the WAL from an attack, to avoid leaking sensitive information [\[16\]](#page-5-16). However, one overlooked area is the integrity of data once it is written to stable storage. By definition, one never expects data written to stable storage to change or otherwise be corrupted, but unfortunately this can happen, specially in the event of a power loss [\[5\]](#page-5-4). One change in a record in the WAL can hinder recovery, or make it outright impossible.

#### III. RUST

<span id="page-1-0"></span>The Rust programming language [\[6\]](#page-5-5) is a modern alternative for building systems software, with a primary focus on safe programming. This language, through its unique memory model, allows for the compilation of safe code into binaries that execute with minimal overhead. These programs combine performance on par with C/C++ with the memory safety of application languages. Additionally, Rust is a modern language, with tools and libraries that allow for the same level of productivity achieved with application programming languages.

Rust memory consistency mechanism makes it an extremely safe language in terms of memory access, without significant overhead at runtime and without a garbage collector. Some research also shows interesting properties in Rust code, such as software fault isolation, static information flow analysis control, and easily saving the program's execution state [\[8\]](#page-5-7).

The main mechanism that allows the language to be safe and fast is called *ownership*. In Rust, variable declarations are made at compile time, and each variable is intrinsically tied to a piece of memory allocated to it. These two assumptions ensure that the program knows at all times which variable is responsible for which piece of memory, preventing undefined behavior in the code. Additionally, the language allows references to be created, and there is strict control over which variable can alter which piece of memory at all times during code execution.

Besides its memory safety mechanisms of ownership and references, Rust also has many of the features found in modern languages. Among them, we can mention *traits* and *derive*, two essential aspects for a modern WAL implementation. Traits are similar to interfaces found in other programming languages, allowing for easy replication of behavior across different structures, albeit with some differences. Derive is a call to the compiler that enables metaprogramming and code addition during compilation. Through derive, we can ask the compiler to provide us with basic implementations of certain traits for any classes in the language.

A WAL implementation written in Rust can be extremely generic as a consequence of these two important language features. Anyone wishing to store a record in the WAL, could use the derive macro on the struct that defines the record. This will allow automatic serialization e deserialization of the struct. Combining this with the definition of a trait that defines minimum functionality of a record, it is straightforward to create an API to write and retrieve records from stable memory.

## IV. DESIGN OF A WRITE-AHEAD LOG IN RUST

<span id="page-1-1"></span>We created an operation replay log that can be used to store application state changes, and later replay them if necessary for recovery. In this section we describe our requirements for this WAL, design decisions and its implementation.

## *A. Requirements and Assumptions*

The initial requirement for the WAL created is that it is to be general purpose, in the sense that a record stored isn't tied to a specific format from the point of view of the WAL. Put in another way, the WAL treats records as opaque data structures and does not care about their contents. Moreover, we want a system with a high degree of generality, capable of accepting any Rust data structure and then translating it into the desired serialization formats. As the records are opaque, the system relies in the serialization infrastructure of the Rust language. This allows for the actual log file to be written in several formats, as discussed later.

The system offers several key operations. It creates WAL files whenever requested by the application, and makes them available for use. It efficiently writes records to the appropriate files *synchronously*, ensuring stability of written records. It also efficiently recovers written records, with minimal overhead. The recovery process provides the application with an ordered list of all records in the log, that it can process to recover its state. Furthermore, it ensures the integrity of records if the writing format allows for such verification.

We've designed the WAL to always be available while in use, much like an open file. This behavior is maintained even in the presence of failures. For writes, this means alerting the client application that the record wasn't written and therefore isn't stable. The application can then rewrite the record until it succeeds. For reads, the systems interrupts the recovery process as soon as an error is encountered and the client is alerted of issues when recovering records. This means that once it's started, the recovery process will provide the client application with all stored records, either until the end of the file or until a corrupted record is found.

This recovery behavior is driven by the fact that the WAL would primarily function as a replay mechanism. The records in the WAL are written in order and reflect the succession of state changes. Thus, to precisely recreate the system's conditions before a failure, more recent events intrinsically rely on previous ones. It wouldn't make sense to recover objects that came after a corrupted object, as the entire recovery would already be compromised.

#### *B. Application Programming Interface*

The first step in implementing the design shown in the last section is the definition of a suitable API (application program interface). We decided to design the simplest API that would satisfy the requirements to avoid adding confounding factors to the experimental evaluation. In brief, the WAL API is defined with these three simple abstract operations:

- **new(file) -> wal:** Creates a new WAL instance for logging data to the specified file.
- **write(record):** Writes a single record to the WAL.
- **retrieve() -> iterator:** Retrieves an iterator over the records present in the WAL, in the order they were written.

The type of the records are defined as generic types, constrained by the traits Serialize for writing and Deserialize for reading. These traits are defined in the popular Rust serialization framework Serde[1](#page-2-0) , that also provides the backend implementation of the reading and writing process. Concerning the client application, the programmer must annotate the type of the record with the #[derive(Deserialize, Serialize)] tag, easily obtaining default implementations of both traits if using regular Rust types. Moreover, because it uses statically defined generic types, the WAL will only write and read a single type of record per file.

Using the Serde framework we actually defined two implementations of the WAL, each based upon an in disk format: JSONLogger and BinLogger. The JSONLogger implementation stores the records in the JSON format, while the BinLogger implementation stores the records in MessagePack format[2](#page-2-1) . Each implementation provides the API with methods of the structs JSONLogger and BinLogger. The new() method is static and returns an implementation of WAL with the desired disk format. Both write() and retrieve() are instance methods, and must be called from the returned WAL instance returned.

```
1 use logging_system::BinLogger;
2 use serde::{Deserialize, Serialize};
4 #[derive(Deserialize, Serialize)]
5 struct Record {
6 id: u32,
7 }
9 fn main() {
10 let logger: BinLogger<Record> =
11 BinLogger::new("records.wal");
13 let record = Record {
14 id: 42,
15 };
17 if let Err(e) = logger.write_data(&record) {
18 println!("Something went wrong: {e}");
19 };
21 let records =
22 logger.retrieve_iterator().unwrap();
23 for record in records {
24 // Restore record
25 }
26 }
```

![](_page_2_Figure_12.jpeg)

<span id="page-2-2"></span>Listing [1](#page-2-2) shows a brief example with the main components of the WAL API using BinLogger. After the necessary imports, we define the record data structure in Lines 4 to 7, using Serde's Deserialize and Serialize traits for derive. The WAL is instantiated in Lines 10 and 11, and a sample record is written in Line 17. Lines 21 to 25 show how the records can be recovered through an iterator.

#### *C. Internals*

3

8

12

16

20

The WAL system implementation is quite straightforward, but some design decisions have implications to the reliability and performance of the system. The main struct of each implementation (JSONLogger and BinLogger) are created with the new() method. In this function, we either create the file if it doesn't exist or link the structure to an existing file and keep it open as long as the structure is in use. This approach boosts system performance by eliminating the need to open and close the file for every record written.

The two main API primitives are write() and read(). The implementation of write() is mostly delegated to Serde, thus the system design consisted basically on selecting the disk format and adding reliability. The implementation of read() bridges the stream of data produced by Serde in the form of an iterator of records that can be used for recovery.

*1)* write()*:* The Serde framework provides many serialization formats, many of these are well-known text formats, like JSON, YAML, TOML, and CSV, while others are more specific to Rust, such as RON (Rust Object Notation). Serde also supports binary formats like CBOR, BSON, and MessagePack, among many others. For this work, we selected two of these formats: JSON and MessagePack.

JSON (JavaScript Object Notation) is particularly appealing because it's a widely recognized text format used in many other contexts. Moreover, its objects are extremely generic,

<span id="page-2-0"></span><sup>1</sup><https://serde.rs/>

<span id="page-2-1"></span><sup>2</sup><https://msgpack.org/>

which was highly desirable considering our design requirement of generality. This provides a degree of interoperability with other systems and, as a human readable format, makes development and testing easier.

MessagePack is relatively newer than JSON. Its core idea is to be a more concise version of JSON, yet just as efficient or even more so. The central characteristic of this format is that it's a binary serialization format, meaning data gets converted into raw bytes, which makes serialized data very compact. However, reading objects from a log file is a challenge and data corruption can be a greater problem than with JSON.

```
JSON 27 bytes
{"compact":true,"schema":0}
MessagePack 18 bytes
82a7 636f 6d70 6163 74c3 a673 6368 656d 6100
```

#### Fig. 1. JSON and MessagePack

<span id="page-3-1"></span>In Figure [1,](#page-3-1) you can see a small example of a JSON object with two fields and its equivalent MessagePack representation. The format uses bytes to identify upcoming fields and their respective sizes. The MessagePack format proved interesting to our research because of its space efficiency and potential performance gains related to having to write less data. Also, this format is good for assessing the reliability of the WAL, because the format is more sensitive to data corruption. After selecting the disk formats, we used the appropriate Serde data formats implemented in the Rust crates (libraries) serde json[3](#page-3-2) and rmp-serde[4](#page-3-3) .

Both serialization formats possess distinct characteristics concerning reliability and size. To improve the reliability of the MessagePack format we decided to add a simple checksum to the serialized record. Neither Serde or the MessagePack format have support for checksumming, so we added it with a simple strategy. First we use Serde to serialize the record in a byte array, then we checksum the array and serialize the checksum in a second byte array. We then write to the WAL file the pair of serialized record and serialized checksum. As checksum algorithm we selected the simple and fast CRC32 algorithm, implemented by the crc32fast crate[5](#page-3-4) .

*2)* read()*:* The implementation of read() must perform the deserialization process, reverting the serialization. From our requirements, we don't need to read an arbitrary position in the WAL, but only to stream the records in order since the last checkpoint, to feed the application recovery process. Thus, considering the Rust language usual idioms, the perfect fit for reading the records in an iterator. Rust iterators provide an idiomatic way of processing a list of data *efficiently*, by only realizing each list elements lazily as they are required. This is desirable as it won't be necessary to read the entire WAL file to begin processing it, saving time and memory.

The actual implementation of the reading takes the reading iterator provided by Serde and transforms it in a checksum validated iterator of records. This is done by reading the pairs (record, checksum) previously written to the WAL file, validating the checksum against the restored record, and returning the record only if it matches the expected checksum. We must note that the WAL files created are bound to the record type written within them. Reading something of a different type, by providing the wrong file name for example, will cause deserialization errors. This is done using the generic types of Rust and effectively means WAL files have their type enforced at compile time.

### V. EVALUATION

<span id="page-3-0"></span>We created a testing environment to asses both the reliability and performance of our WAL system. First we have a simple application that writes a set of records in the WAL and later recovers the written records. Each record is a small but complex Rust struct, composed by some primitives fields and a vector of another struct of primitive fields.

```
1 #[derive(Deserialize, Serialize, Debug)]
2 struct Data {
3 a: u32,
4 b: u32
5 }
6
7 #[derive(Deserialize, Serialize, Debug)]
8 struct Record {
9 id: u32,
10 comment: String,
11 objects: Vec<Data>,
12 }
```

## Listing 2: Record Struct

The application was run with both implementations of the WAL: JSONLogger and BinLogger. The chosen record type is directly mapped to the two formats without further intervention. The reliability experiment was made by manually corrupting the WAL file on disk, before it was recovered. The performance experiment consisted in a micro-benchmark where a set of records were written and later recovered from the WAL.

## *A. Reliability*

We present the reliability experiments by serialization format. For the JSON format, we corrupted the WAL file considering the way the JSON format is structured. We now list each failure introduced and the consequence of each:

Adding or removing spaces, newlines, or tabs: This

change doesn't affect the object's content at all, only the file's formatting, which has no effect on the object deserialization process.

- Adding or removing structural symbols: Inserting any loose structural symbols of a JSON object ({,},[,]) will cause deserialization to fail at that specific point.
- Altering, removing, or adding valid fields: Adding new fields didn't alter the object recovery process in any way. However, removing or changing field identifiers caused deserialization failures for the altered object.

<span id="page-3-2"></span><sup>3</sup>https://crates.io/crates/serde json

<span id="page-3-3"></span><sup>4</sup>https://crates.io/crates/rmp-serde

<span id="page-3-4"></span><sup>5</sup><https://crates.io/crates/crc32fast/1.4.0>

- Changing the order of fields: This change didn't affect the object recovery process. The deserialization process is robust enough to handle both unnecessary additional fields and changes in their order.
- Introducing an empty object: Introducing a completely empty object led to deserialization problems where the object was inserted. As an empty object doesn't possess the necessary fields for deserialization, this could be considered a subcase of removing fields.
- Changing values of valid fields: This change represents a corruption that the system cannot clearly detect in the JSON format. If the altered value is still consistent with the field's type, the change won't be detected as an error, and the record will be recovered normally, which is, in fact, an error. However, if the value is changed to a different type than expected, the error is detected.

In our evaluation the flexible nature of the text based format such as JSON is both a blessing and a curse. The WAL file in this format isn't vulnerable to some of the corruptions performed, allowing the records to be recovered. Some corruptions in key areas of the file will still render it unreadable, but that's expected. More troubling is the observation that some types of corruption will actually change the records stored, but these changes won't be noticed.

Considering this limitation of the JSON format, and the inherent fragility of a binary only format, we have added checksumming to the MessagePack serialization format. This changes the failure dynamic completely, because now any and all changes will violate the checksum. To assess this, we once again corrupted the WAL file, now considering the way the MessagePack format is structured:

- Changes to an object's identifier;
- Changes to a field's identifier;
- Changes to a field's value;
- Changes to the checksum identifier;
- Changes to the checksum value.

For all five items, as expected, our checksumming procedure proved robust enough to detect the mentioned errors. It's important to note that this detection is performed individually for each object. If an error is found, the deserialization process is interrupted at the correct point.

Finally, it's worth mentioning that it's not always possible to specifically identify which change occurred. For instance, a change to the checksum value or an object field's value triggered the same type of error. However, with more robust error detection and correction codes, it might be possible to detect the specific error introduced into a record.

#### *B. Performance*

To assess the WAL performance, we ran an experiment focused on record sizes. As we described in Section [IV,](#page-1-1) each record written to the WAL must be stable in secondary memory before the write() call returns. This implies an expensive sync operation after each write. Thus, it is more efficient if the application can coalesce many records in a single write. This isn't always the case, so we created some scenarios reflecting changing application demands. This also characterizes the performance expectation of the WAL over different record sizes.

The experiment consists in writing a group of 2,000,000 records, and later reading the records back. We created three configurations:

- A: 2,000,000 sets of 1 record;
- B: 1,000,000 sets of 2 records;
- C: 500,000 sets of 4 records.

The experiment was run in a host with a AMD Ryzen 5 PRO 6650U CPU, 16 GB RAM, and a Kigston NV2 1TB NVMe SSD. The SSD has a benchmarked sequential performance of about 5,600 MB/s reading and 2,800 MB/s writing, and a random access of 350 kIOPS reading and 300 kIOPS writing. During the experiment, CPU and random access IOPS were the resources driving the results, SSD throughput was largely unused.

Each configuration was run 5 times for each implementation of the WAL: JSONLogger and BinLogger. The results were averaged by configuration, separating reads from writes, using three metrics: elapsed time to write all 2,000,000 records in seconds, throughput in MB/s, throughput in records/s. Elapsed time is an absolute metric and summarizes well the overall performance of the WAL, and the relative performance of each serialization format. Throughput in bytes shows how efficiently each serialization format uses the available disk throughput. Records per second shows the disk IOPS utilization of each serialization format.

TABLE I WRITE PERFORMANCE DATA

<span id="page-4-0"></span>

|                      | Configurations |           |           |
|----------------------|----------------|-----------|-----------|
| Metric               | A              | B         | C         |
| JSON time (s)        | 8.461          | 4.982     | 3.154     |
| JSON throu. (MB/s)   | 70.187         | 110.953   | 168.924   |
| JSON throu. (rec./s) | 236389.85      | 401412.97 | 634115.41 |
| MP time (s)          | 7.179          | 3.858     | 2.171     |
| MP throu. (MB/s)     | 32.359         | 57.743    | 99.561    |
| MP throu. (rec./s)   | 278574.81      | 518376.44 | 921404.22 |

Table [I](#page-4-0) shows the results for write operations. The write performance of the WAL is excellent, mostly bound by the maximum IOPS of the device, at about 250 k records per second for both serialization formats. Remember that every write must be synced to stable storage, thus the latency of individual writes dominates here. The performance increases as we bunch more records together, and this gives an advantage to the more compact MessagePack format over JSON, by using less CPU and writing roughly 2/3 of the data. This efficiency makes the BinLogger score an impressive 920 k records/s in writes over about 630 k records/s for JSONLogger. Both numbers are rather good in general, and it is interesting to note that even the less efficient JSON format leaves most of the SSD bandwidth unused.

Table [II](#page-5-17) shows the results for read operations. The read performance is mostly CPU bound, because there is no need

TABLE II READ PERFORMANCE DATA

<span id="page-5-17"></span>

|                      | Configurations |            |            |
|----------------------|----------------|------------|------------|
| Metric               | A              | B          | C          |
| JSON time (s)        | 5.938          | 5.714      | 5.423      |
| JSON throu. (MB/s)   | 99.997         | 96.740     | 98.242     |
| JSON throu. (rec./s) | 336791.05      | 349993     | 368785.96  |
| MP time (s)          | 0.709          | 0.561      | 0.526      |
| MP throu. (MB/s)     | 327.858        | 396.977    | 410.695    |
| MP throu. (rec./s)   | 2822466.84     | 3563791.87 | 3800836.18 |

to sync data to and from stable storage and, most importantly, OS caches are primed with the data just written in the previous step. We considered to bypass the OS disk cache, but decided against it because this way we could assess the CPU cost of each serialization format. This allowed us to observe that MessagePack is about 10 times more efficient than JSON to deserialize data. Both formats barely use any disk bandwidth, and the impressive number of 2,8 M records/s achieved by the BinLogger, while reading a record at a time, clearly shows we are not operating bound by the SSD device performance. Both formats improve their reading performance as the number of records in each set increases, but only by a small margin that we hypothesize is related to a smaller number of system calls.

#### VI. CONCLUSION

<span id="page-5-8"></span>We've built a reliable WAL implementation in Rust using two distinct formats, each offering different guarantees. The first format, JSON, is human-readable is robust against various file corruptions. However, this format allows the data to be corrupted in a way that is imperceptible to the client application. The second format, MessagePack, is a very fast binary format and combined with a checksum mechanism is able to detect and flag all file corruptions. Performance of both implementations were quite good, with the most overhead found in the JSON format. MessagePack encoded logs showed a very small overhead, with performance very close to the maximum supported by the device.

The Rust programming language proved why it is such a sensation among system programmers. It is easy to use, compact and has a very rich set of libraries. We were able to realize our design with almost no changes and used many prepackaged components. Our reliability testing found a very safe implementation, able to detect all inserted corruptions with the aid of a checksum.

Moving forward, we want to perform a more thorough set of reliability tests, and develop ways to recover a damaged WAL file. If the checksum is replaced by an error correcting code, some level of corruption could be withstood. We could also pursue an approach that incorporates even more security into our system, by use of encryption for example.

#### REFERENCES

<span id="page-5-0"></span>[1] R. Peterson and J. P. Strickland, "Log write-ahead protocols and IMS/VS logging," in *Proceedings of the 2nd ACM SIGACT-SIGMOD Symposium on Principles of Database Systems*, 1983, pp. 216–243.

- <span id="page-5-1"></span>[2] A. Jhingran and P. Khedkar, "Analysis of recovery in a database system using a write-ahead log protocol," *Acm Sigmod Record*, vol. 21, no. 2, pp. 175–184, 1992.
- <span id="page-5-2"></span>[3] M. Haubenschild, C. Sauer, T. Neumann, and V. Leis, "Rethinking logging, checkpoints, and recovery for high-performance storage engines," in *Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data*, 2020, pp. 877–892.
- <span id="page-5-3"></span>[4] Y. Nakamura, H. Kawashima, and O. Tatebe, "Integration of TicToc concurrency control protocol with parallel write ahead logging protocol," *International Journal of Networking and Computing*, vol. 9, no. 2, pp. 339–353, 2019.
- <span id="page-5-4"></span>[5] M. Zheng, J. Tucek, F. Qin, M. Lillibridge, B. W. Zhao, and E. S. Yang, "Reliability analysis of SSDs under power fault," *ACM Transactions on Computer Systems (TOCS)*, vol. 34, no. 4, pp. 1–28, 2016.
- <span id="page-5-5"></span>[6] S. Klabnik and C. Nichols, *The Rust programming language*. No Starch Press, 2023.
- <span id="page-5-6"></span>[7] R. Jung, J.-H. Jourdan, R. Krebbers, and D. Dreyer, "Safe systems programming in Rust," *Communications of the ACM*, vol. 64, no. 4, pp. 144–152, 2021.
- <span id="page-5-7"></span>[8] A. Balasubramanian, M. S. Baranowski, A. Burtsev, A. Panda, Z. Rakamaric, and L. Ryzhyk, "System programming in Rust: Beyond safety," ´ in *Proceedings of the 16th workshop on hot topics in operating systems*, 2017, pp. 156–161.
- <span id="page-5-9"></span>[9] C. Mohan and F. Levine, "ARIES/IM: an efficient and high concurrency index management method using write-ahead logging," *ACM Sigmod Record*, vol. 21, no. 2, pp. 371–380, 1992.
- <span id="page-5-10"></span>[10] G. M. D. Vieira and L. E. Buzato, "Treplica: Ubiquitous replication," in *SBRC '08: Proc. of the 26th Brazilian Symposium on Computer Networks and Distributed Systems*, Rio de Janeiro, Brasil, May 2008. [Online]. Available: [http://www.lbd.dcc.ufmg.br/bdbcomp/servlet/](http://www.lbd.dcc.ufmg.br/bdbcomp/servlet/Trabalho?id=7450) [Trabalho?id=7450](http://www.lbd.dcc.ufmg.br/bdbcomp/servlet/Trabalho?id=7450)
- <span id="page-5-11"></span>[11] W. Mingardi and G. Vieira, "Characterizing synchronous writes in stable memory devices," in *Anais do XVIII Workshop em Desempenho de Sistemas Computacionais e de Comunicac¸ao˜* . Porto Alegre, RS, Brasil: SBC, 2019. [Online]. Available: [https://sol.sbc.org.br/index.php/](https://sol.sbc.org.br/index.php/wperformance/article/view/6458) [wperformance/article/view/6458](https://sol.sbc.org.br/index.php/wperformance/article/view/6458)
- <span id="page-5-12"></span>[12] R. Johnson, I. Pandis, R. Stoica, M. Athanassoulis, and A. Ailamaki, "Scalability of write-ahead logging on multicore and multisocket hardware," *The VLDB Journal*, vol. 21, pp. 239–263, 2012.
- <span id="page-5-13"></span>[13] W.-H. Kim, J. Kim, W. Baek, B. Nam, and Y. Won, "NVWAL: Exploiting NVRAM in write-ahead logging," *ACM SIGPLAN Notices*, vol. 51, no. 4, pp. 385–398, 2016.
- <span id="page-5-14"></span>[14] P. E. Rocha and L. C. Bona, "Analyzing the performance of an externally journaled filesystem," in *2012 Brazilian Symposium on Computing System Engineering*. IEEE, 2012, pp. 93–98.
- <span id="page-5-15"></span>[15] C. Sauer, G. Graefe, and T. Harder, "FineLine: log-structured trans- ¨ actional storage and recovery," *Proceedings of the VLDB Endowment*, vol. 11, no. 13, pp. 2249–2262, 2018.
- <span id="page-5-16"></span>[16] J. Pei and V. Shmatikov, "BigFoot: Exploiting and mitigating leakage in encrypted write-ahead logs," *arXiv preprint arXiv:2111.09374*, 2021.