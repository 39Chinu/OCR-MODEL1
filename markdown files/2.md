# <span id="page-0-0"></span>Pseudorandomness of Expander Walks via Fourier Analysis on Groups

Fernando Granha Jeronimo\* Tushant Mittal† Sourya Roy‡

A long line of work has studied the pseudorandomness properties of walks on expander graphs. A central goal is to measure how closely the distribution over n-length walks on an expander approximates the uniform distribution of n-independent elements. One approach to do so is to label the vertices of an expander with elements from an alphabet Σ, and study closeness of the mean of functions over Σ <sup>n</sup>, under these two distributions. We say expander walks ε-fool a function if the expander walk mean is ε-close to the true mean. There has been a sequence of works studying this question for various functions, such as the XOR function, the AND function, etc. We show that:

- The class of symmetric functions is O(|Σ|λ)-fooled by expander walks over any generic λ-expander, and any alphabet Σ . This generalizes the result of Cohen, Peri, Ta-Shma [STOC'21] which analyzes it for |Σ| = 2, and exponentially improves the previous bound of O(|Σ| <sup>O</sup>(|Σ|)λ), by Golowich and Vadhan [CCC'22]. Moreover, if the expander is a Cayley graph over Z<sup>|</sup>Σ<sup>|</sup> , we get a further improved bound of O( p |Σ|λ).

Morever, when Σ is a finite group G, we show the following for functions over Gn:

- The class of symmetric class functions is O √ |G| <sup>D</sup> λ -fooled by expander walks over "structured" λ-expanders, if G is D-quasirandom.
- We show a lower bound of Ω(λ) for symmetric functions for any finite group G (even for "structured" λ-expanders).
- We study the Fourier spectrum of a class of non-symmetric functions arising from *word maps*, and show that they are exponentially fooled by expander walks.

Our proof employs Fourier analysis over general groups, which contrasts with earlier works that have studied either the case of Z<sup>2</sup> or Z. This enables us to get quantitatively better bounds even for unstructured sets.

<sup>\*</sup>University of Illinois Urbana-Champaign, granha@illinois.edu.

<sup>†</sup>Stanford University, tushant@stanford.edu. TM is a postdoctoral fellow supported by the NSF grants CCF-2143246 and CCF-2133154.

<sup>‡</sup>The University of Iowa, sourya-roy@uiowa.edu. SR was partially supported by the Old Gold Summer Fellowship from The University of Iowa.

# <span id="page-1-0"></span>**Contents**

| 1 | Introduction                                        |                                                              | 1  |
|---|-----------------------------------------------------|--------------------------------------------------------------|----|
|   | 1.1                                                 | Our Results<br>.                                             | 2  |
|   |                                                     | 1.1.1<br>Pseudorandomness of generic expanders<br>.          | 2  |
|   |                                                     | 1.1.2<br>Fooling symmetric functions and word functions<br>. | 4  |
|   |                                                     | 1.1.3<br>Pseudorandomness of structured expanders<br>.       | 5  |
|   |                                                     | 1.1.4<br>Lower Bounds                                        | 6  |
|   | 1.2                                                 | Proof techniques                                             | 6  |
| 2 | Preliminaries                                       |                                                              |    |
|   | 2.1                                                 | Random walks on expander graphs<br>.                         | 8  |
|   | 2.2                                                 | The main quantity                                            | 9  |
|   | 2.3                                                 | Inner products and norms<br>.                                | 9  |
|   | 2.4                                                 | Fourier Analysis on Finite Groups<br>.                       | 10 |
|   | 2.5                                                 | Complex valued functions on groups                           | 10 |
| 3 | Expander Walks and Product functions                |                                                              | 11 |
|   | 3.1                                                 | Walks on "structured" Cayley graphs<br>.                     | 14 |
|   |                                                     | 3.1.1<br>Decay for walks on Pseudo Cayley graphs<br>.        | 15 |
| 4 | Fooling Symmetric Functions and Word Functions      |                                                              | 18 |
|   | 4.1                                                 | A general reduction to fooling irreps<br>.                   | 18 |
|   | 4.2                                                 | Fooling symmetric functions                                  | 19 |
|   | 4.3                                                 | Word functions<br>.                                          | 21 |
|   |                                                     | 4.3.1<br>Fourier Spectrum of Word functions                  | 22 |
|   |                                                     | 4.3.2<br>Fooling Word Functions<br>.                         | 23 |
| 5 | Function Classes with Group Symmetry                |                                                              | 24 |
|   | 5.1                                                 | Symmetric Class Functions<br>.                               | 24 |
|   | 5.2                                                 | Diagonal action and G-invariant functions<br>.               | 27 |
| 6 | Lower Bounds for decay of Symmetric functions<br>28 |                                                              |    |
|   | 6.1                                                 | Fourier Coefficient of Threshold Function<br>.               | 28 |

# <span id="page-2-0"></span>**1 Introduction**

Expander graphs are fundamental pseudorandom objects with a vast range of applications in computer science and mathematics [\[HLW06,](#page-33-0) [Vad12,](#page-34-0) [Lub94\]](#page-33-1). These graphs combine two opposing properties of being well-connected yet sparse. In many ways, they exhibit behavior that is surprisingly close to truly random, thereby being used to replace randomness and yield several explicit constructions. For instance, explicit codes approaching the random guarantees of the Gilbert–Varshamov [\[Gil52,](#page-32-0) [Var57\]](#page-34-1) bound [\[TS17\]](#page-34-2) or the generalized Singleton [\[ST20,](#page-34-3) [Rot22\]](#page-33-2) bound can be constructed using expanders [\[JMST25\]](#page-33-3). Moreover, expanders can be used to construct a variety of pseudorandom generators [\[INW94,](#page-33-4) [HH24\]](#page-33-5).

Walks on expander graphs not only mix fast, but they are an important derandomization tool for the Chernoff bound [\[Gil93,](#page-32-1) [GLSS18\]](#page-32-2), the hitting set property [\[AKS87,](#page-32-3) [TSZ24\]](#page-34-4), etc. These tasks can be phrased in a more general and unified way as how well expander walks fool a Boolean function f : {0, 1} <sup>n</sup> → {0, 1}. In this setting, the vertices, VX, of an expander graph X, are labelled with bits {0, 1} and instead of evaluating f under the uniform distribution on n bits, we evaluate it under the distribution on {0, 1} n induced by taking a random walk on X of length n. To quantify the error incurred in this process of replacing true randomness by expander walks, it is convenient to define EX(f) as:

$$
\mathcal{E}_X(f) = \left| \mathbb{E}_{s \sim V_X^n} \left[ f(s) \right] - \mathbb{E}_{s \sim RW_n} \left[ f(s) \right] \right|.
$$

In this language, by choosing f to be the AND function on n bits, we recover the expander hitting set property application. The choice of f as a (suitable) threshold function on n bits leads to the expander Chernoff bound. The choice of f as the XOR function on n bits (and a carefully constructed X) leads to the breakthrough code construction of Ta-Shma [\[TS17\]](#page-34-2).

Using this unified perspective, Cohen, Peri, and Ta-Shma [\[CPTS21\]](#page-32-4) developed a systematic framework to analyze expander random walks and obtain bounds on EX(f). Their framework is based on Fourier analysis and exploits the fact that any Boolean function f : {0, 1} <sup>n</sup> → {0, 1} can be expressed in the Fourier basis as a linear combination of characters, which are XOR functions in this case. They obtained bounds on EX(f) in terms of the spectral expansion λ of the (normalized) adjacency matrix of X.

A series of works [\[GV22,](#page-33-6) [CMP](#page-32-5)+22, [Gol23\]](#page-32-6) have since extended the [\[CPTS21\]](#page-32-4) framework to functions of the form f : Σ <sup>n</sup> → C, where Σ is a finite alphabet. These works study *symmetric functions*—functions that are invariant under any permutation of the input coordinates—and functions computed by restricted circuit classes such as AC<sup>0</sup> . Golowich and Vadhan [\[GV22\]](#page-33-6) get the following bound for symmetric functions:

$$
|\mathcal{E}_X(f)| \ \leqslant \ (|\Sigma|^{O(|\Sigma|)} \cdot \lambda).
$$

They asked whether such an exponential dependence on |Σ| is optimal. In this work, we improve this bound to O(|Σ| · λ) by viewing a function f : Σ <sup>n</sup> → C as a function f : Z n <sup>|</sup>Σ<sup>|</sup> <sup>→</sup> <sup>C</sup> which enables us to use a Fourier basis. More interestingly, this change of perspective motivates us to consider graphs that can utilize this algebraic structure, such as Cayley graphs over Z<sup>|</sup>Σ<sup>|</sup> . This idea helps us get a bound of O( p |Σ| · λ) for Cayley expanders, further improving upon our bound of O(|Σ| · λ) for arbitrary expanders.

**Functions over Groups** More broadly, the above suggests investigating functions over general finite groups (instead of just Z<sup>|</sup>Σ<sup>|</sup> ) and considering expanders with a compatible algebraic structure. This opens up interesting directions to study:

- 1. What novel classes of functions f : G<sup>n</sup> → C can we study that utilize the group operation, or have richer symmetries coming from the group? For instance, *class functions*, i.e., functions that satisfy f(x) = f(gxg−<sup>1</sup> ) for every x, g ∈ G.
- 2. Can one obtain stronger bounds on EX(f) for such function classes when the expander X has algebraic structure?
- 3. How can one utilize the pseudorandomness properties of the group itself, such as *quasirandomness*?

While these questions are very natural in their own right, studying functions over general groups has been fruitful in the context of complexity theory. For instance, the famed Barrington's theorem [\[Bar89\]](#page-32-7) effectively reinterprets a Boolean function as a function over the permutation group. More recently, [\[JMRW22\]](#page-33-7) showed that one can obtain improved expanders by studying pseudorandomness for functions over the permutation group.

# <span id="page-3-0"></span>**1.1 Our Results**

We initiate a study of this general setup and make progress in answering these questions. We (i) give a general lemma about the pseudorandomness for matrix-valued functions (over arbitrary expanders), which is needed to work with Fourier decompositions of non-abelian groups, (ii) analyze specific function classes of symmetric functions and *word functions* over a group G, and (iii) we study symmetric *class functions* over structured expanders, and show that the quasirandomness of the group G synergizes with the randomness of the expander X to yield improved bounds, and finally, (iv) we prove a lower bound for the fooling of symmetric functions even over such structured expanders.

# <span id="page-3-1"></span>**1.1.1 Pseudorandomness of generic expanders**

We begin by considering an abstract problem about expander walks. Let X be an expander and consider a set of k matrix-valued mean-zero functions:

$$
\big\{f_j:X\to\mathbb{C}^{d_j\times d_j}\mid j\in[k]\big\},\quad \, \max_x\|f_j(x)\|_{op}\leqslant 1.
$$

Given an ordered subset S = {i<sup>1</sup> < i<sup>2</sup> < · · · < ik−<sup>1</sup> < ik} of indices, we wish to study the expression,

$$
\mathcal{E}_{X,\mathcal{S}}\left(f_1\otimes\cdots\otimes f_k\right)\;:=\;\left\|\mathbb{E}_{\vec{x}\sim\mathsf{RW}_n}\big[f_1(x_{i_1})\otimes\cdots\otimes f_k(x_{i_k})\big]\right\|_{op}
$$

Note that the above expression is identically 0 if X is a complete graph (with self-loops) as the functions, fi, have zero mean. The goal is to show that above quantity is small when we have a λ-expander. Analyzing special cases of such quantity is at the heart of several past works [\[CPTS21,](#page-32-4) [JMRW22,](#page-33-7) [RR24\]](#page-33-8) that studied pseudorandomness of expander walks. For <span id="page-4-4"></span>the setting of matrix-valued functions, the result of [\[JMRW22\]](#page-33-7) gives the following bound on the expression:

<span id="page-4-0"></span>**Theorem 1.1** ( [\[JMRW22\]](#page-33-7))**.** *Let* X *be any* λ*-expander and* {f1, . . . , fk} *be a collection of mean-zero normalized matrix-valued functions for* k ⩾ 2*. Then for any* k*-sized subset of indices,* S*,*

$$
\mathcal{E}_{X,S}\left(f_1\otimes\cdots\otimes f_k\right)\,\leqslant\,(2\lambda)^{\lfloor\frac{k}{2}\rfloor}.
$$

The above result is agnostic to the set S and gives a general worst-case bound. But this is too pessimistic when S has large gaps. For instance, if S = {1, 4, 9}, the above result gives a bound of λ which is far from the optimal (could be as small as λ 8 ). We prove a result that takes the structure of S into account and gives an improved guarantee when S has large gaps.

<span id="page-4-1"></span>**Theorem 1.2** (Matrix-Valued Fooling, [Theorem 3.1\)](#page-12-1)**.** *Let* X *be any* λ*-expander and* {f1, . . . , fk} *be a collection of mean-zero matrix-valued functions for* k ⩾ 2*. Then for any* k*-sized subset of indices,* S*,*

$$
\mathcal{E}_{X,\mathcal{S}}\left(f_1\otimes\cdots\otimes f_k\right)\,\leqslant\, \lambda^{\eta(\mathcal{S})}\,\leqslant\, (4\lambda)^{\lfloor\frac{k}{2}\rfloor}\,.
$$

*where* η(S) *is an explicit function.*

The above bound is an improvement (over [Theorem 1.1\)](#page-4-0) when S has large gaps. [Theo](#page-4-1)[rem 1.2](#page-4-1) generalizes the result of [\[CPTS21\]](#page-32-4), who achieved the same improvement over the result of Ta-Shma [\[TS17\]](#page-34-2) for {±1}-valued functions. This quantitative improvement was crucially used by [\[CPTS21\]](#page-32-4) to prove their result about fooling functions over {0, 1} <sup>n</sup>, and we use it similarly to prove it for functions over an arbitrary alphabet, Σ n.

The above theorem connects with fooling functions via Fourier analysis. Let G be a group, and f : G<sup>n</sup> → C be any function. Consider a labeling[1](#page-4-2) map, φ : X → G. Then, f ◦ φ : X <sup>n</sup> → C, and the term we wish to bound is:

$$
\mathcal{E}_X(f) := \Big| \underset{\vec{x} \sim \text{RW}_n}{\mathbb{E}} \Big[ f(\varphi(x_1), \ldots, \varphi(x_n)) \Big] - \underset{\vec{x} \sim \text{Unif}_n}{\mathbb{E}} \Big[ f(\varphi(x_1), \ldots, \varphi(x_n)) \Big] \Big|.
$$

Furthermore, since f is a function on a product group, Gn, we can apply the general Fourier transform to express f as a linear combination of matrix-valued tensor functions[2](#page-4-3) . These tensor functions (when composed with φ) can be analyzed using [Theorem 1.2.](#page-4-1) This can be seen as a generalization of the Fourier analytic approach of [\[CPTS21\]](#page-32-4), who study symmetric functions over Z n 2 . As a first application, we use our generalization from Z n 2 to Z n |Σ| , to prove [Theorem 1.3.](#page-5-1) Additionally, the ability to work with a general Fourier basis is utilized for other results where the function uses group structure for a given (potentially non-Abelian) group G, such as for *group products* [\(Theorem 1.5\)](#page-5-2), and our general lower bound [\(Theorem 1.9\)](#page-7-2).

<span id="page-4-3"></span><span id="page-4-2"></span><sup>1</sup>We only work with unbiased labelings, i.e., those that induce the uniform distribution on G.

<sup>2</sup>[Theorem 1.2](#page-4-1) enables the possibility of working with orthonormal bases other than the Fourier basis. Any reasonably "flat" orthonormal basis where the basis elements satisfy certain pointwise bound and contains the invariant vector (i.e., the all 1 vector) can be used.

#### <span id="page-5-3"></span><span id="page-5-0"></span>**1.1.2 Fooling symmetric functions and word functions**

We analyze the fooling of symmetric functions, ie functions f : Σ <sup>n</sup> → C that is invariant under permuting the input coordinates, for any finite alphabet Σ.

<span id="page-5-1"></span>**Theorem 1.3** (Fooling symmetric functions, [Theorem 4.5\)](#page-21-0)**.** *Let* f *be any symmetric function,* f : Σ <sup>n</sup> → C *where* Σ *is any finite set. Let* X *be a* λ*-expander such that* λ < 1 16e|Σ| *. Then for any unbiased labelling of* X *with* Σ*,*

$$
|\mathcal{E}_X(f)| \leq (32e\lambda|\Sigma|) \cdot \|f\|_2.
$$

*Moreover, if* ∥f∥<sup>2</sup> = on(1)*—for example, the weight indicator function which satisfies* ∥f∥<sup>2</sup> = n <sup>−</sup>1/4 *one obtains a vanishing decay.*

This improves the previous best bound of (|Σ| O(|Σ|) · λ) due to Golowich and Vadhan [\[GV22\]](#page-33-6). Our analysis relies on using a Fourier basis for such functions that can be obtained by viewing Σ instead as ZΣ, and then applying [Theorem 1.2.](#page-4-1) However, our proof is agnostic to this specific choice of group and can instead work with a Fourier basis over any group (of size |Σ|) by using [Theorem 1.2.](#page-4-1)

**Word Functions and Group Products** Going beyond symmetric functions, we analyze "non-commutative" monomial functions, which we call *word* functions.

**Definition 1.4** (Monomial word function)**.** For an ordered subset S ⊆ [n], a *monomial word* is a map, w<sup>S</sup> : G<sup>n</sup> → G, defined as w<sup>S</sup> = Î <sup>s</sup>∈<sup>S</sup> g es <sup>s</sup> where e<sup>S</sup> ∈ {±1}. A function f : G<sup>n</sup> → C is a *monomial word function* of degree k, if f = h(wS(g1, · · · , gn)) for some S of size k and a function h : G → C.

We give a complete characterization of the Fourier spectrum of *monomial word functions*, and show that these have Fourier support on the highest level and thus are analogs of the PARITY function over Z n 2 . Moreover, this support is sparse (see [Lemma 4.7\)](#page-23-1), and this enables us to use [Theorem 1.2.](#page-4-1) We thus deduce that such functions are exponentially fooled by expander walks.

<span id="page-5-2"></span>**Theorem 1.5** (Fooling word functions, [Theorem 4.8\)](#page-24-1)**.** *Let* f : G<sup>n</sup> → C *be a word function of degree* k *corresponding to a set* S*. Then for any expander* X *with an unbiased* G*-labelling,*

$$
|\mathcal{E}_X(f)| \le \lambda^{\eta(\mathcal{S})} \cdot |G|^{\frac{k}{2}} \cdot ||f||_2 \le (2\lambda)^{\lfloor \frac{k}{2} \rfloor} \cdot |G|^{\frac{k}{2}} \cdot ||f||_2.
$$

One important case of this class of functions is the group product functions, namely, Boolean valued functions f that take x1, . . . , x<sup>k</sup> ∈ G as input and output 1 if and only if the product is equal to some target element t ∈ G. Fooling group product functions is a crucial component in the construction of some pseudorandom generators for branching programs, e.g., [\[MZ09,](#page-33-9) [De11\]](#page-32-8).

We sharpen [Theorem 1.5](#page-5-2) for group product functions by removing the dependence on |G| in the error bound while achieving the same exponential decay in terms of expansion.

<span id="page-6-2"></span>**Theorem 1.6** (Fooling Group Products, [Theorem 4.10\)](#page-24-2)**.** *Let* G *be any finite group,* t ∈ G*, and* <sup>f</sup>(®x) <sup>=</sup> <sup>1</sup>{x1···xk=t} *be a group product. Then for any expander* <sup>X</sup> *with an unbiased* <sup>G</sup>*-labelling,*

$$
|\mathcal{E}_X(f)| \ \leqslant \ (2\lambda)^{k/2} \, .
$$

#### <span id="page-6-0"></span>**1.1.3 Pseudorandomness of structured expanders**

The above results hold for generic expanders, but since our function is defined on a group, it is natural to consider "structured" expanders that gel well with the group. In the case of Abelian groups, these are just *Cayley graphs*, using which we obtain a further improvement to [Theorem 1.3.](#page-5-1)

**Theorem 1.7** (Abelian Groups, [Corollary 3.11](#page-18-0) and [Proposition 5.5\)](#page-27-0)**.** *Let* G *be an Abelian group and* X *be a Cayley graph on* G *and let* {χ<sup>j</sup> | j ∈ [k] } *be a set of non-trivial characters of* G*. Then for any ordered subset* S *of size* k*,*

$$
\mathcal{E}_{X,S}(\chi_1\otimes\cdots\otimes\chi_k)\;\;\leqslant\;\; \lambda^{\eta(\mathcal{S})}\cdot\mathbb{1}_{\{\chi_1\cdots\chi_k=\text{triv}\}}\,.
$$

*As a consequence, for every symmetric function* f : Σ <sup>n</sup> → C *and Cayley expander* X*,*

$$
\big|\mathcal{E}_X(f)\big| \ \leqslant \ O\Big(\sqrt{|\Sigma|} \cdot \lambda\Big) \cdot \|f\|_2 \, .
$$

For G = Z2, this result says that the odd degree characters are perfectly fooled, and thus, every odd function f : Z n <sup>2</sup> <sup>→</sup> <sup>C</sup> is perfectly fooled by such a structured expander. This already illustrates the improvement over generic expanders.

To generalize this to general non-abelian groups, we need to restrict to *class functions*, i.e., functions such that f(gxg −1 ) = f(x) for every x, g ∈ G. Note that for Abelian groups, every function is a class function, as the condition is trivially true due to commutativity. Moreover, we will need a stronger notion of a "pseudo Cayley graph" for which we omit the formal definition here (see [Definition 3.3\)](#page-15-1). The key property of these graphs is that their eigenvectors are given by the Fourier basis functions.

**Tighter Bound for Quasirandom Groups** An often seen phenomenon is that one gets better pseudorandomness properties for groups that are *highly non-abelian*. One way to quantify this is the notion of a D-*quasirandom groups* introduced in a seminal work by Gowers [\[Gow08\]](#page-32-9) which is a group in which the smallest (non-trivial) irreducible representation (see [Definition 2.4\)](#page-11-2) has dimension D. Abelian groups are 1-quasirandom, whereas on the other extreme, there are matrix groups that are |G| 1 <sup>3</sup> -quasirandom (see [\[Gow08\]](#page-32-9)). We show that such a gain does indeed occur in our setting as well.

<span id="page-6-1"></span>**Theorem 1.8** (General Groups, [Corollary 3.11](#page-18-0) and [Proposition 5.5\)](#page-27-0)**.** *Let* G *be a* D*-quasirandom group and let* X *be a "pseudo Cayley" graph on* G*. Let* {χ<sup>j</sup> | j ∈ [k] } *be a set of non-trivial characters of* G*, normalized by their dimension. Then for any ordered subset* S *of size* k*,*

$$
\mathcal{E}_{X,S}(\chi_1 \otimes \cdots \otimes \chi_k) \leq \lambda^{\eta(S)} \cdot \langle \chi_{\text{triv, }\chi_1} \cdots \chi_k \rangle.
$$

<span id="page-7-3"></span>*As a consequence, for every symmetric class function* f : G<sup>n</sup> → C*,*

$$
\big|\mathcal{E}_X(f)\big| \ \leqslant \ O\bigg(\frac{\sqrt{|G|}}{D} \cdot \lambda\bigg) \cdot \|f\|_2.
$$

Apart from the quasirandomness factor, the key improvement from [Theorem 1.2](#page-4-1) here is the extra factor of χtriv, χ<sup>1</sup> · · · χ<sup>k</sup> . This counts the fractional dimension of the trivial irrep inside the tensor representation ρ<sup>1</sup> ⊗ · · · ⊗ ρk. This quantity is much smaller than one, for instance, when k = 2, it is at most <sup>1</sup> D2 . Moreover, this quantity can be computed explicitly using basic representation theory, which yields a more precise upper bound.

#### <span id="page-7-0"></span>**1.1.4 Lower Bounds**

We show that our dependence on λ in the bound of |EX(f)| in [Theorem 1.3](#page-5-1) cannot be improved in general, no matter the choice of group G. Let, A ⊆ G and t ∈ [n]. We define a symmetric boolean function Th<sup>A</sup>,<sup>t</sup> as :

Th<sup>A</sup>,<sup>t</sup>(®x) = 1 if |{i | x<sup>i</sup> ∈ A}| ⩾ t; 0 otherwise.

<span id="page-7-2"></span>**Theorem 1.9** (Lower Bound for any group)**.** *Let* G *be any finite group, and* A ⊆ G *be any subset such that* <sup>|</sup>A<sup>|</sup> |G| = 1 2 *. There exists an* λ*-expander* X *such that for every* n *large enough,*

$$
\left|\mathcal{E}_X\Big(Th_{A,\frac{n+1-\sqrt{n}}{2}}\Big)\right| \ \geqslant \ \Omega(\lambda).
$$

*This lower bound holds even when* X *is a "pseudo Cayley graph" (as in [Theorem 1.8\)](#page-6-1) on* G*.*

This lower bound places a limitation on how much the quasirandomness of the group or the algebraic structure of the expander can be leveraged in terms of the pseudorandomness of expander walks with respect to symmetric functions.

Regardless of how "far" from Abelian the group G is, a lower bound of Ω(λ) still persists. This lower bound rules out the possibility of an upper bound of, say, <sup>λ</sup> <sup>D</sup> for a D-quasirandom group in [Theorem 1.3.](#page-5-1) More importantly, it shows that even if one uses an expander with such Cayley-like algebraic structure, one cannot improve the linear dependence on λ.

We stress that proving this lower bound for general finite groups is substantially more challenging than for the Z k 2 case [\[CMP](#page-32-5)+22]. In general, this requires the function and the graph to "interact" in a non-trivial way, but now, in the presence of (possibly) higherdimensional representations, this is substantially more delicate to achieve (see [Section 1.2\)](#page-7-1).

## <span id="page-7-1"></span>**1.2 Proof techniques**

**A generalized "Ignore First Step" Trick.** To prove our first main result [\(Theorem 1.2\)](#page-4-1), we generalize the technique of [\[RR24\]](#page-33-8) (also, subsequently used in [\[RR23\]](#page-33-10)) that introduced a trick that they called "Ignore First Step" Trick. We generalize this in two significant ways. We first extend it to the setup of general matrix-valued functions. More importantly, we

<span id="page-8-0"></span>perform a finer analysis to obtain a dependence on λ that takes into account the subset of indices S. This is necessary to yield a bound of λ <sup>η</sup>(S) as opposed to λ ⌊k/2⌋ (even for scalar-valued functions) that would be implied by [\[RR24\]](#page-33-8).

We give a quick overview of this technique in the very special setup of {±1}-valued functions that are all identical. We wish to analyze the term:

$$
\mathbb{E}_{(x_1,\ldots,x_n)\sim RW_n}[f_1(x_1)\cdots f_k(x_k)].
$$

This corresponds to S = {1, . . . , k}. Let us start with k = 2. This case can be directly handled by the expander mixing lemma, which says that for a λ-spectral expander,

$$
\Big|\mathop{\mathbb{E}}_{(x_1,x_2)\sim \text{RW}_2} [f(x_1) f(x_2)] - \Big(\mathop{\mathbb{E}}_{x\sim \text{RW}_1} [f(x)]\Big)^2\Big| \leq \lambda \cdot \mathop{\mathbb{E}}_{x\sim \text{RW}_1} [|f(x)|^2].
$$

One interpretation of this lemma is that it reduces the analysis of the mean of the product function over 2-length walks to the analysis of the mean and variance of the function over a walk of length 1. The main idea behind the technique is to do such a reduction from a length k-walk to analyzing mean and variance over (k − 1)-length walks.

We do not get into the details of this reduction but explain the trick used to bound such variance terms, the simplest case of which is when k = 3. For a vertex x, let RW1(x) be the distribution of 1-length walks starting from x. The term we need to analyze is,

$$
\mathop{\mathbb{E}}_{x \sim RW_1} \left[ \left| \mathop{\mathbb{E}}_{y \sim RW_1(x)} [f(x)f(y)] \right|^2 \right] = \mathop{\mathbb{E}}_{x \sim RW_1} \left[ |f(x)|^2 \mathop{\mathbb{E}}_{y,z \sim RW_1(x)} [f(y)\overline{f(z)}] \right]
$$

The key technical point is the following. The expression on the right formally depends on x but since f(x) <sup>2</sup> = 1, this dependence is virtual. More importantly, the distribution on y, z in this expression is the same as sampling y, z independently (of x) at distance 2 in the graph,

$$
\mathop{\mathbb{E}}_{x \sim RW_1} \left[ \mathop{\mathbb{E}}_{y,z \sim RW_1(x)} \left[ f(y) \overline{f(z)} \right] \right] = \mathop{\mathbb{E}}_{(y,z) \sim RW'_2} \left[ f(y) \overline{f(z)} \right].
$$

The right-hand side can now be analyzed by applying the above expander mixing lemma on the graph X 2 . Thus, this trick gets rid of the first variable x, and reduces the variance of 2-length walks to the mean of 1-length walk (on the squared graph).

Our proof follows a similar approach, but there are two key complications. One, the functions we need to analyze are matrix-valued, and secondly, the above analysis does not utilize the gaps in the index set S, and therefore would give a bound akin to [\[JMRW22,](#page-33-7) [TS17\]](#page-34-2) which is too weak for our purposes.

Let S = (i1, · · · ,ik), and let ∆<sup>j</sup> := ij+<sup>1</sup> − i<sup>j</sup> be the j th gap. To bound the recurrence more tightly, we view the random walk as a sequence of k steps, where the j th step is on the graph X ∆<sup>j</sup> . To implement this approach in the general setup of tensors of operator-valued functions, we introduce auxiliary functions such as,

$$
g_j(\vec{x}) \; := \; I_{d_1} \otimes \cdots \otimes I_{d_{j-1}} \otimes f_j(x_{i_j}) \otimes f_{j+1}(x_{i_{j+1}}) \cdots \otimes f_k(x_{i_k}),
$$

that capture the intermediate state of this random process after j steps. This lets us utilize the large gaps, i.e., |∆<sup>j</sup> | in S , to obtain a sharper bound (λ η(S) instead of λ ⌊ k 2 ⌋ ).

<span id="page-9-2"></span>**Beyond Spectral Gap via structured graphs** The above technique is quite general and works beyond the setup of groups, thereby yielding a general result [\(Theorem 1.2\)](#page-4-1). Moreover, it only uses the fact that X is an expander i.e., that it satisfies a spectral gap. While this leads to operator norm bounds, it is not amenable to analyzing trace norms, and one has to appeal to generic bounds such as ∥M∥tr ⩽ dim(M) · ∥M∥op which is suboptimal in many cases. The key insight behind our second main result [\(Theorem 1.8\)](#page-6-1) is to use additional spectral information (eigenvectors) about the expander X, and not just its spectral gap. To do so, we define the notion of *pseudo Cayley graphs*.

**Pseudo Cayley Graphs** These are graphs such that the characters of the group G are its eigenvectors. More precisely, there exists a labeling of its vertices, φ : X → G, such that χ ◦ φ is an eigenvector of the graph adjacency matrix A<sup>X</sup> for every character χ of G. Note that this property is true for Cayley graphs over Abelian groups. Moreover, one can also build examples over non-Abelian groups (see [Examples 3.4](#page-16-1) and [3.6\)](#page-16-2)

To make use of the above structure, we use a key fact from representation theory, which says that the product of characters over any finite group G can be decomposed a linear sum,

$$
\chi_{\alpha}(g) \cdot \chi_{\beta}(g) = \sum_{\gamma} c_{\gamma}^{\alpha, \beta} \cdot \chi_{\gamma}(g).
$$

These coefficients are called Clebsch–Gordan coefficients for G. Therefore, our expression can be inductively unrolled by alternating the operations– (i) taking a step of the walk (which can be handled now that characters are eigenvectors), and (ii) decomposing the product of characters as a linear sum. This leads to a precise calculation of the mean over random walks (see [Theorem 3.8\)](#page-16-3) as opposed to an upper bound for the operator norm.

**Lower Bound** This precise calculation comes in handy not just to prove the sharper bound in [Theorem 1.8,](#page-6-1) but also for the lower bound. The candidate hard function is a generalization of the Boolean threshold function which was used in the analysis of [\[CPTS21\]](#page-32-4). However, their construction of the graph is specific to Z<sup>2</sup> and does not generalize to other groups (even Zp). Moreover, in Abelian groups the representations are 1-dimensional irreps and thus, |tr(M)| = ∥M∥op = ∥M∥tr. However, in higher dimensions even if ∥M∥op ⩾ λ, the trace, tr(M) can be zero which is actually the quantity which we need to lower bound. To tackle this, we compute this trace exactly at level 2 [\(Corollary 5.8\)](#page-28-1) and combine it with the precise computation of the mean for pseudo Cayley graphs (see [Theorem 3.8\)](#page-16-3).

# <span id="page-9-0"></span>**2 Preliminaries**

# <span id="page-9-1"></span>**2.1 Random walks on expander graphs**

Throughout the paper, X = (V, E) will be a d-regular λ-expander graph. We write A<sup>X</sup> to denote the degree normalized adjacency operator of X.

**Definition 2.1** ((d, λ)-expander)**.** A graph d-regular graph X = (V, E) is called (d, λ) expander if max{|λ2|, |λN|} ⩽ λ where λ<sup>1</sup> ⩽ λ<sup>2</sup> ⩽ · · · ⩽ λ<sup>N</sup> are the eigenvalues of AX.

We write x ∼ y denote sampling of an edge, (x, y) from X. A key tool in analyzing expanders is the expander mixing lemma:

<span id="page-10-2"></span>**Lemma 2.2** (Expander mixing lemma)**.** *Let* X *be a* λ*-spectral expander and* f, g : X → C <sup>n</sup> *be two vector-valued functions on the vertex set* X*. Let,* µ<sup>f</sup> = Ex∼X[f(x)] *and* ∥f∥ 2 2 = E[|f(x)|<sup>2</sup> ]*. Then we have:*

$$
\left| \mathbb{E}_{x \sim y} [\langle f(x), g(y) \rangle] - \langle \mu_f, \mu_g \rangle \right| \leq \lambda \cdot \|f\|_2 \|g\|_2.
$$

**Random walk notation** We find it helpful to define a few shortands associated with random walks on X = (V, E) to streamline our presentation. We list them below.

- We write ′′x® ∼ RW′′ <sup>n</sup> to denote uniform sampling of an (n − 1)-step (or, n vertices long) random walk, (x1, x2, . . . , xn) =: x® on X.
- Given, x ∈ V, the notation ′′x® ∼ RWn(x) ′′ denotes uniform sampling of an (n − 1)-step (or, n vertices long) random walk, x® conditioned on x<sup>1</sup> = x.
- The expression "x ∼ <sup>k</sup> y" denotes sampling a pair, (x, y), of vertices from X that are at a distance of k.

<span id="page-10-3"></span>**Fact 2.3** (Distribution for a single)**.** *Fix any* k ∈ [n]*. Then, the marginal distribution on* x<sup>k</sup> *when* x® ∼ RW<sup>n</sup> *is uniform over* X*.*

## <span id="page-10-0"></span>**2.2 The main quantity**

Let G be any finite group and X = (V, E) be an expander graph. A G-labeling (or, simply labeling), φ, of X is a map φ : X → G. Given any such labeling φ, we say φ, is *unbiased* if

$$
\Pr_{x \sim X} [\varphi(x) = g] = |G|^{-1} \text{ for all } g \in G
$$

In this work, our focus is functions of the form f : G<sup>n</sup> → C. We will always assume that the labelling is unbiased and use f(x) to denote f ◦ φ to prevent clutter.

## <span id="page-10-1"></span>**2.3 Inner products and norms**

Let C <sup>d</sup> be the d-dimensional complex inner product space equipped with the inner product. We denote by U<sup>d</sup> the group of d-dimensional unitary matrices. Let A, B ∈ C <sup>d</sup>×<sup>d</sup> be two complex matrices. We have the following inner products and norms:

- 
$$
\langle u, v \rangle := \mathbb{E}_{i \sim [d]}[u_i v_i^*]
$$

$$
- \langle A, B \rangle_{HS} := tr(A^*B) = tr(B^*A)
$$

- 
$$
||A||_{\text{HS}}^2 = \text{tr}(A^*A) = \sum_{i,j} |A_{i,j}|^2
$$

$$
- ||A||_{tr} = tr(\sqrt{A^*A})
$$

- <sup>∥</sup>A∥op <sup>=</sup> sup <sup>∥</sup>x∥=<sup>1</sup> ∥Ax∥ where ∥·∥ denotes the norm associated with C d.

## <span id="page-11-5"></span><span id="page-11-0"></span>**2.4 Fourier Analysis on Finite Groups**

We always use G to denote an arbitrary finite group (not necessarily abelian) unless specified otherwise. Denote by L 2 (G) = {f : G → C}, the space of complex-valued functions equipped with the following inner product,

$$
\langle f, g \rangle = \mathop{\mathbb{E}}_{x \sim G} \left[ \big( g(x)^* f(x) \big) \right].
$$

This induces the norm is ∥f∥ <sup>2</sup> = Ex∼<sup>G</sup> -|f(x)|<sup>2</sup> .

**Group Representations** We will use the notion of a group representation[3](#page-11-3) . *Weyl's unitary trick*, says that for a large family of groups (which includes all finite groups), every representation can be made unitary and thus, we can restrict to studying these.

<span id="page-11-2"></span>**Definition 2.4** (Irreducible Group Representation)**.** Let G be a finite group. A unitary representation of G is a group homomorphism ρ : G → U<sup>d</sup> for some d, i.e., ρ(g1g2) = ρ(g1)ρ(g2) for every g1, g<sup>2</sup> ∈ G. The character, χ<sup>ρ</sup> : G → C associated with ρ is the function: χ<sup>ρ</sup> = tr ◦ ρ. Note, that characters are not necessarily homomorphisms. A representation is called *irreducible* (or irrep) if there exists no subspace of V ⊆ C <sup>d</sup> such that ρ(g)V ⊆ V for all <sup>g</sup> <sup>∈</sup> <sup>G</sup>. The set of irreps of <sup>G</sup> is denoted as <sup>G</sup>b.

When G is abelian, all irreducible representations are one-dimensional. Thus, in this case, the set of characters, and the set of irreps coincide. Moreover, for abelian G, the set of characters form an orthogonal basis of C[G]. This does not hold for arbitrary finite groups G. Nevertheless, even for arbitary finite groups, the set characters do satisfy the orthogonality conditions.

<span id="page-11-4"></span>**Fact 2.5.** *Let,* <sup>ρ</sup>, <sup>γ</sup> <sup>∈</sup> <sup>G</sup><sup>b</sup> *be two irreducible representations. Then,*

$$
\langle \chi_{\rho}, \chi_{\gamma} \rangle = \begin{cases} d_{\rho}, & \text{if } \rho = \gamma, \\ 0, & \text{otherwise.} \end{cases}
$$

*Moreover, for any non-trivial representation* ρ *of any finite group* G*,* Eg∈Gρ(g) = 0*.*

## <span id="page-11-1"></span>**2.5 Complex valued functions on groups**

For every finite group G, the set of functions given by the matrix entries of the irreps, i.e., {ρij <sup>|</sup> <sup>ρ</sup> <sup>∈</sup> <sup>G</sup>b,i, <sup>j</sup> ∈ [dρ]}, form an orthogonal basis for the space of all functions, <sup>L</sup> 2 (G).

**Definition 2.6** (Fourier Coefficient)**.** For any irrep <sup>ρ</sup>, we have <sup>b</sup>f(ρ) :<sup>=</sup> <sup>E</sup><sup>x</sup> f(x) · ρ(x) . The Fourier coefficient of the trivial irrep as <sup>µ</sup>(f) :<sup>=</sup> <sup>b</sup>f(ρtriv).

**Fact 2.7.** *The following identities hold for the Fourier transform,*

- *1.* **(Fourier inversion)** f(x) = P <sup>ρ</sup>∈G<sup>b</sup> <sup>d</sup><sup>ρ</sup> <sup>b</sup>f(ρ), <sup>ρ</sup>(x) *.*
- *2.* **(Plancharel's identity)** ∥f∥ <sup>2</sup> = P <sup>ρ</sup>∈G<sup>b</sup> <sup>d</sup>ρ∥bf(ρ)∥<sup>2</sup> HS*.*

<span id="page-11-3"></span><sup>3</sup>Additional background on representation theory of finite groups can be found in [\[Ser77\]](#page-34-5).

<span id="page-12-3"></span>**Product Groups** In this paper, we will work with product groups. The following fact characterizes the irreducible representations of G<sup>n</sup> in terms of irreps of G.

**Fact 2.8.** <sup>G</sup>c<sup>n</sup> <sup>=</sup> {ρ<sup>1</sup> ⊗ · · · ⊗ <sup>ρ</sup><sup>n</sup> <sup>|</sup> <sup>ρ</sup><sup>i</sup> <sup>∈</sup> <sup>G</sup>b}*. We use* <sup>ρ</sup>®<sup>T</sup> *to represent* <sup>ρ</sup><sup>1</sup> ⊗ · · · ⊗ <sup>ρ</sup><sup>n</sup> *such that* T = {i | ρ<sup>i</sup> ≠ triv}*. Moreover,* |®ρ| := |T |*.*

**Definition 2.9** (Degree Decomposition)**.** For f : G<sup>n</sup> → C, we use f<sup>k</sup> to denote the function corresponding to its k th-level, i.e., fk(®x) = P <sup>ρ</sup>®,| ®ρ|=<sup>k</sup> dρ® <sup>ˆ</sup>f(®ρ), <sup>ρ</sup>®(®x) . In the Boolean case (Z n 2 ), this is also referred to as the degree k component of f.

# <span id="page-12-0"></span>**3 Expander Walks and Product functions**

In this section, we will prove the main claim about the fooling of tensored product matrixvalued functions. This can be seen as the matrix-valued generalization of [\[CPTS21\]](#page-32-4). We will then apply it to our Fourier basis elements, i.e., irreps which are tensor product functions, to obtain our main result for general functions. To state our theorem, we will need a few pieces of notations borrowed from [\[CPTS21\]](#page-32-4) that we describe below.

**Notation** Let S = {i<sup>1</sup> < i<sup>2</sup> < · · · < ik−<sup>1</sup> < ik} be an ordered subset of {1, 2, . . . ,n}. We define the following key quantities:

- 
$$
\mathcal{I}_k = \{ \{1, k-1\} \subseteq I \subseteq [k-1] \mid \forall 1 < j < k-1, \{j, j+1\} \cap I \neq \emptyset \}.
$$
  
-  $\Delta_j(\mathcal{S}) = i_{j+1} - i_j.$ 

In this section, we can state our main theorem that we prove in this section.

<span id="page-12-1"></span>**Theorem 3.1.** *Let,* X *be an* λ*-expander graph and let* S = {i<sup>1</sup> < i<sup>2</sup> < · · · < ik−<sup>1</sup> < ik} *be an ordered subset of* [n]*. Let* {f<sup>j</sup> : X → <sup>M</sup>d<sup>j</sup> (C) | j ∈ [k] } *be set of matrix valued functions such that* Ex∼X[fj(x)] = 0*, and* maxx∥fj(x)∥op ⩽ 1*. Then,*

<span id="page-12-2"></span>
$$
\left\| \mathbb{E}_{\vec{x} \in RW_n} [f_1(x_{i_1}) \otimes \cdots \otimes f_k(x_{i_k})] \right\|_{op} \hspace{2mm} \leqslant \hspace{2mm} \sum_{I \in \mathcal{I}(k)} \lambda^{\sum_{i \in I} \Delta_i(\mathcal{S})}.
$$

*Proof.* For any j ∈ [k], we define the following shorthands:

$$
g_j(\vec{x}) := I_{d_1} \otimes \cdots \otimes I_{d_{j-1}} \otimes f_j(x_{i_j}) \otimes f_{j+1}(x_{i_{j+1}}) \cdots \otimes f_k(x_{i_k}).
$$
  
\n
$$
h_j(\vec{x}) := I_{d_1} \otimes \cdots \otimes I_{d_{j-1}} \otimes f_j(x_{i_j}) \otimes I_{d_{j+1}} \otimes \cdots \otimes I_{d_{j+1}}.
$$
  
\nAnd thus, for  $j < k$ ,  $g_j(\vec{x}) = h_j g_{j+1}$ .  
\n
$$
N_j(y) = \underset{\vec{x} \sim X_{n-i_j}(y)}{\mathbb{E}} [g_j(y, x_{i_{j+1}}, \cdots, x_{i_k})],
$$
  
\n
$$
N_k(y) = g_k(y).
$$
  
\n(2)

Equation [Eq. \(1\)](#page-12-2) follows from the mixed product property of tensors. The last equation here denotes expectation under the distribution in which the random walk starts from a <span id="page-13-2"></span>fixed point y, i.e., xi<sup>j</sup> = y and then continues for n − i<sup>j</sup> steps until it reaches xn. We start by defining two key quantities that we will work with throughout.

$$
\varepsilon_j := \left\| \mathbb{E}_{\vec{x} \sim RW_n}[g_j(\vec{x})] \right\|_{op} = \left\| \mathbb{E}_{y \sim X}[N_j(y)] \right\|_{op'}
$$
$$
\zeta_j^2 := \mathbb{E}_{y \sim X} \left[ \left\| N_j(y) \right\|_{op}^2 \right].
$$

The first equation above has an equality as the distribution that draws a random walk x® ∼ X <sup>n</sup> and outputs the last n − i<sup>j</sup> + 1 co-ordinates of the walk, is equivalent to the distribution that outputs a random sample from X n−ij+1 . Note that our goal is to upper bound ε1, and we recursively bound this by using the technique from [\[RR24\]](#page-33-8). The matrix N<sup>j</sup> essentially denotes the averaging that has been done for the function after fj.

**Base cases** Since we will bound it recursively starting from j = k, that forms the base case. By using the assumptions on fk, we have:

<span id="page-13-1"></span>
$$
\varepsilon_{k} = \left\| \mathbb{E}_{y \sim X} [f_{k}(y)] \right\|_{op} = 0, \quad \zeta_{k}^{2} = \mathbb{E}_{x} \Big[ \left\| f_{k}(x) \right\|_{op}^{2} \Big] \leq 1 \,. \tag{3}
$$

**Bounding** εi<sup>j</sup> **.** We will use the variational definition of the operator norm. To start let u, v be any unit vectors in C <sup>d</sup><sup>j</sup> ⊗ · · · C <sup>d</sup>k. For any y ∈ X, we have:

$$
\langle u, N_{j}(y), v \rangle = \mathbb{E}_{\vec{x} \sim X^{n-i_{j}+1}(y)} \langle u, g_{j}(y, \vec{x}) v \rangle
$$
  
\n
$$
= \mathbb{E}_{\vec{x} \sim X^{n-i_{j}+1}(y)} \langle h_{j}(y)^{*} u, g_{j+1}(\vec{x}) v \rangle
$$
 [By Eq. (1)]  
\n
$$
= \mathbb{E}_{y \sim^{A_{j}} x_{i_{j+1}}} \langle h_{j}(y)^{*} u, \sum_{\vec{x} \sim X_{n-i_{j+1}} (x_{i_{j+1}})} [g_{j+1}(x_{i_{j+1}}, \vec{x})] v \rangle
$$
  
\n
$$
= \mathbb{E}_{y \sim^{A_{j}} x_{i_{j+1}}} \langle h_{j}(y)^{*} u, N_{j+1}(x_{i_{j+1}}) v \rangle.
$$

The main step that happened above was that the sampling of x® was broken into two steps, (i) sampling xij+<sup>1</sup> after a walk of length ∆j, and (ii) the remaining x® starting from this xij+<sup>1</sup> . The key trick now is to interpret this term as a function of xi<sup>j</sup> , y which are neighbouring vertices when sampled from X ∆<sup>j</sup> . Therefore, we can apply EML [\(Lemma 2.2\)](#page-10-2). Note that Ey[h ∗ j u] = I ⊗ Ey[f ∗ j u] ⊗ I = 0 by our assumption on fj. Similarly, maxy∥hj(y)∥<sup>2</sup> op <sup>⩽</sup> 1. Thus,

$$
\left| \mathbb{E}_{y \sim^{\Delta_{j}} x_{i_{j+1}}} \left\langle h_{j}(y)^{*} u, N_{j+1}(x_{i_{j+1}}) v \right\rangle \right|^{2} \leq \lambda^{2\Delta_{j}} \cdot \mathbb{E}_{y \sim X} \Big[ \|h_{j}^{*}(y) u\|^{2} \Big] \cdot \mathbb{E}_{z \sim X} \Big[ \|N_{j+1}(z) v\|^{2} \Big] \leq \lambda^{2\Delta_{j}} \max_{y} \|h_{j}(y)\|_{op}^{2} \cdot \zeta_{j+1}^{2}.
$$
  
\n
$$
\Rightarrow \sup_{u,v} |\langle u, N_{j}(y), v \rangle| \leq \lambda^{\Delta_{j}} \cdot \zeta_{j+1},
$$
  
\n
$$
\varepsilon_{j} \leq \lambda^{\Delta_{j}} \cdot \zeta_{j+1}.
$$
 (4)

**Bounding** ζj**.** To bound this quantity, we will again bound the operator norm by bounding the quadratic form for a fixed unit vector v,

<span id="page-13-0"></span>
$$
\zeta_j^2 = \mathbb{E}_{y \sim X} \Big[ \big\| N_j(y) \big\|_{op}^2 \Big] = \sup_{\nu, \|\nu\| = 1} \mathbb{E}_{y \sim X} \Big[ \big\langle N_j(y) \nu, N_j(y) \nu \big\rangle \Big],
$$

and then apply EML [\(Lemma 2.2\)](#page-10-2) to get a recursive upper bound. Fix a j ∈ [k], and a unit vector v ∈ C <sup>d</sup><sup>j</sup> ⊗ · · · C <sup>d</sup>k. We have:

$$
\mathbb{E}_{y \sim X} \Big[ \langle N_j(y) \nu, N_j(y) \nu \rangle \Big] = \mathop{\mathbb{E}}_{\substack{y \sim X, \\ \vec{x}, \vec{z} \sim \text{RW}_{n-i_j}(y)}} \Big[ \langle g_j(y, \vec{x}) \nu, g_j(y, \vec{z}) \nu \rangle \Big] \n= \mathop{\mathbb{E}}_{\substack{y \sim X, \\ \vec{x}, \vec{z} \sim \text{RW}_{n-i_j}(y)}} \Big[ \langle h_j(y) g_{j+1}(\vec{x}) \nu, h_j(y) g_{j+1}(\vec{z}) \nu \rangle \Big] \n\leq \mathop{\mathbb{E}}_{\substack{y \sim X, \\ \vec{x}, \vec{z} \sim \text{RW}_{n-i_j}(y)}} \Big[ \|h_j(y)\|_{op}^2 \langle g_{j+1}(\vec{x}) \nu, g_{j+1}(\vec{z}) \nu \rangle \Big] \n\leq \mathop{\mathbb{E}}_{\substack{y \sim X, \\ \vec{x}, \vec{z} \sim \text{RW}_{n-i_j}(y)}} \Big[ \langle g_{j+1}(\vec{x}) \nu, g_{j+1}(\vec{z}) \nu \rangle \Big].
$$

The first inequality uses hj(y)u, hj(y)u ⩽ <sup>h</sup>j(y) 2 op ·⟨u, <sup>u</sup>⟩ for <sup>u</sup> <sup>=</sup> <sup>E</sup>x®∼RWn−ij (y) [gj+1(®x) v]. The last inequality follows from our assumption on f<sup>j</sup> as (∥hj(y)∥<sup>2</sup> op <sup>=</sup> <sup>∥</sup>fj(y)∥<sup>2</sup> op <sup>⩽</sup> <sup>1</sup>). The above random process of sampling y and then two paths x®, z® from it is equivalent to sampling the starting points x, z such that are a distance 2∆<sup>j</sup> apart, and then performing a random walk from each giving rise to the paths (®x, z®).

$$
\mathbb{E}_{y \sim X} \Big[ \langle N_j(y) \nu, N_j(y) \nu \rangle \Big] \leq \mathop{\mathbb{E}}_{x \sim^{2\Delta_j} z} \Big[ \langle \mathbb{E}_{\vec{x} \sim RW_{n-i_{j+1}}(x)} g_{j+1}(\vec{x}) \nu, \mathbb{E}_{\vec{z} \sim X^{n-i_{j+1}}(z)} g_{j+1}(\vec{z}) \nu \rangle \Big]
$$
  
\n
$$
= \mathop{\mathbb{E}}_{x \sim^{2\Delta_j} z} \Big[ \langle N_{j+1}(x) \nu, N_{j+1}(z) \nu \rangle \Big]
$$
  
\n
$$
\leq \|\mathbb{E}_{x} [N_{j+1}(x)] \nu\|^2 + \lambda^{2\Delta_j} \cdot \mathbb{E}_{x} [||N_{j+1}(x) \nu||^2], \qquad \text{(EML, Lemma 2.2)}
$$
  
\n
$$
\leq \varepsilon_{j+1}^2 + \lambda^{2\Delta_j} \cdot \zeta_{j+1}^2.
$$
  
\n(Definition of  $\varepsilon_{j+1}, \zeta_{j+1}$ )

Since the above holds for every v, we can deduce:

$$
\zeta_j^2 \leq \varepsilon_{j+1}^2 + \lambda^{2\Delta_j} \cdot \zeta_{j+1}^2,
$$
  
\n
$$
\Rightarrow \zeta_j \leq \varepsilon_{j+1} + \lambda^{\Delta_j} \cdot \zeta_{j+1}.
$$
 (5)

**Bounding** ε1**.** Combing the equations [Eq. \(4\)](#page-13-0) and [Eq. \(5\),](#page-14-0) we get:

<span id="page-14-0"></span>
$$
\zeta_j \ \leqslant \ \lambda^{\Delta_{j+1}} \zeta_{j+2} + \lambda^{\Delta_j} \zeta_{j+1}.
$$

We claim for j = 2, . . . k − 1, it holds that:

<span id="page-14-1"></span>
$$
\zeta_j \leqslant \sum\nolimits_{T \in \mathcal{T}_j} \lambda^{\sum_{t \in T} \Delta_t},\tag{6}
$$

where T<sup>j</sup> := I<sup>k</sup> ∩ {j, . . . , k}, i.e., the set of all ordered sequences from {i<sup>j</sup> < · · · < ik−1} such that last index of each such sequence is ik−<sup>1</sup> and it contains at least one of two consecutive indices. This suffices as we can combine [Eq. \(6\)](#page-14-1) (for j = 2) with [Eq. \(4\)](#page-13-0) for j = 1, to get the main claim:

$$
\epsilon_1 \;\leqslant\; \lambda^{\Delta_1} \cdot \zeta_2 \;\leqslant\; \lambda^{\Delta_1} \sum_{T \in \mathcal{T}_2} \lambda^{\sum_{t \in T} \Delta_t} \; = \; \sum_{I \in \mathcal{I}(k)} \lambda^{\sum_{i \in I} \Delta_i}.
$$

<span id="page-15-3"></span>We prove [Eq. \(6\)](#page-14-1) by induction starting from k − 1 which can be proved by combining [Eq. \(3\)](#page-13-1) and [Eq. \(5\)](#page-14-0) (for j = k − 1),

$$
\zeta_{k-1} \ \leqslant \ \epsilon_k + \lambda^{\Delta_k} \zeta_k \ \leqslant \ \lambda^{\Delta_k}.
$$

Now, assume the claim holds for any k − 1 ⩾ j > 2. Then, we have:

$$
\begin{aligned} \zeta_{j-1} \; &\leqslant \; \lambda^{\Delta_{j-1}} \cdot \sum_{T \in \mathcal{T}_j} \lambda^{\sum_{t \in T} \Delta_t} + \lambda^{\Delta_j} \cdot \sum_{T \in \mathcal{T}_{j+1}} \lambda^{\sum_{t \in T} \Delta_t} \\ &\qquad = \sum_{T \in \mathcal{T}_{j-1} \; : \; i_{j-1} \in T} \lambda^{\sum_{t \in T} \Delta_t} + \sum_{T \in \mathcal{T}_{j-1} \; : \; i_{j-1} \notin T, \; i_j \in T} \lambda^{\sum_{t \in T} \Delta_t} \\ &\leqslant \sum_{T \in \mathcal{T}_{j-1}} \lambda^{\sum_{t \in T} \Delta_t} \end{aligned}
$$

The last line follows because the sets:

$$
\{T\in \mathcal{T}_{j-1}\;:\; i_{j-1}\in T\},\;\;\{T\in \mathcal{T}_{j-1}\;:\; i_{j-1}\notin T,\; i_j\in T\},
$$

are non-intersecting and subsets of Tj−1. Thus [Eq. \(6\)](#page-14-1) holds, which concludes the proof.

<span id="page-15-2"></span>**Corollary 3.2** (Operator version of [\[CPTS21\]](#page-32-4))**.** *Let* X *be a* λ *expander and* φ : V(X) → G *be an unbiased labeling. Let* S = {ii, · · · ,ik} ⊆ [n]*. Then for any set of non-trivial irreps* {ρ1, . . . , ρk} *of* G*,*

$$
\left\|\mathbb{E}_{\vec{x}\in RW_n}[\rho_1(\phi(x_{i_1}))\cdots\otimes\rho_k(\phi(x_{i_k}))]\right\|_{op}\ \leqslant\ \sum_{I\in\mathcal{I}_k}\lambda^{\sum_{j\in I}\Delta_j(\mathcal{S})}.
$$

*Proof.* We only need to check that a non-trivial irrep satisfies the conditions of [Theorem 3.1.](#page-12-1) The max operator norm is 1 as representations map to unitary matrices. The mean zero condition holds from the fact we work with unbiased labelings and from [Fact 2.5.](#page-11-4)

## <span id="page-15-0"></span>**3.1 Walks on "structured" Cayley graphs**

In this section, we will specialize our results and work with a class of Cayley-like graphs. These graphs generalize a very useful property of Cayley graphs over Abelian groups, namely that, its eigenvectors are characters. This knowledge of the graph eigenvectors will enable us to sharpen our computation of the random walk expectation.

<span id="page-15-1"></span>**Definition 3.3** (Pseudo Cayley graph)**.** A graph X is *pseudo-Cayley* with respect to G if there is an unbiased labeling φ : X → G such that for every Fourier basis element ρij, the function, ρij ◦ φ, is an eigenvector of A<sup>X</sup> with eigenvalue λρ.

When working with such graphs, we will implicitly use such a labeling and thus write χ(v) as a shorthand for χ ◦ φ(v). We now give two examples of pseudo-Cayley graphs.

#### <span id="page-16-5"></span>**Examples of pseudo Cayley graphs**

<span id="page-16-1"></span>**Example 3.4** (Quasi-Abelian Cayley graphs)**.** Let X = Cay(G, S) be a graph where G is any finite group and S is a union of conjugacy classes, i.e., if s ∈ S then gsg −1 ∈ S for every g ∈ G. Then,

**Lemma 3.5** ([\[RKHS02,](#page-33-11) Thm. 1.1])**.** *Let* X = Cay(G, S) *be a graph where* G *is any finite group and* S *is a union of conjugacy classes. Then, every orthogonal basis vector,* ρi,<sup>j</sup> *is an eigenvector of* X *with an eigenvalue* λ<sup>ρ</sup> := 1 d<sup>ρ</sup> P <sup>s</sup> <sup>χ</sup>ρ(s)*. Therefore,* <sup>X</sup> *is pseudo Cayley graph (with an identity labeling).*

The above example can be generalized by picking a Cayley graph on a larger group H and labeling it via a group homomorphism. We will need this for our lower bound, so we state it precisely.

<span id="page-16-2"></span>**Example 3.6.** Let H, G be groups such that there exists a surjective homomorphism φ : H → G. Then, the complete graph on H (without self-loops), i.e., X = Cay(H, H \ {1}) is G-generalized Cayley labeled with φ as the labeling. In particular, one may take H = G<sup>r</sup> for any r ⩾ 1. Moreover, it inherits the eigenvalues of X.

#### <span id="page-16-0"></span>**3.1.1 Decay for walks on Pseudo Cayley graphs**

We now prove a finer bound for the decay obtained by performing walks on such an X. The labeling function is just the identity map on G. which is an unbiased labeling. This improves [Theorem 1.2](#page-4-1) by providing an explicit description of the mean EX(®ρ) and not just a norm bound on it. This will be used to give better bounds for conjugacy-invariant function i.e., *class functions* in [Section 5.1.](#page-25-1) We start with a key fact from representation theory.

<span id="page-16-4"></span>**Fact 3.7** (Decomposition of tensor representations)**.** *Let,* <sup>α</sup>,<sup>β</sup> <sup>∈</sup> <sup>G</sup><sup>b</sup> *be two irreps of a finite group* G*. There exists a change of basis transformation* Nα,β*, and non-negative integer coefficients* {c α,β <sup>γ</sup> <sup>|</sup> <sup>γ</sup> <sup>∈</sup> <sup>G</sup>b} *such that for any* <sup>g</sup> <sup>∈</sup> <sup>G</sup>*:*

$$
N_{\alpha,\beta}(\alpha(g) \otimes \beta(g))N_{\alpha,\beta}^* = \bigoplus_{\gamma \in \widehat{G}} \gamma^{\oplus c_{\gamma}^{\alpha,\beta}},
$$
  
$$
\chi_{\alpha}(g) \cdot \chi_{\beta}(g) = \sum_{\gamma} c_{\gamma}^{\alpha,\beta} \cdot \chi_{\gamma}(g),
$$
  
$$
c_{\text{triv}}^{\alpha,\beta} = 1_{\{\alpha = \beta^*\}}.
$$

*These coefficients are called Clebsch-Gordan coefficients for* G*.*

The proof is an inductive unfolding of the expression by applying [Fact 3.7](#page-16-4) and then using that the characters are eigenvectors.

<span id="page-16-3"></span>**Theorem 3.8** (Precise Computation of Expectation)**.** *Let* X *be a pseudo-Cayley graph with respect to* <sup>G</sup>*, with eigenvalues* {λ<sup>α</sup> <sup>|</sup> <sup>α</sup> <sup>∈</sup> <sup>G</sup>b}*. Let* <sup>S</sup> <sup>=</sup> {i1, . . . ,ik} *be any ordered subset of* [n]*, and* {ρ1, . . . , ρk} *be non-trivial irreps of* G *and* {χi} *their associated characters. Then for any* k ⩾ 2*,*

$$
\mathop{\mathbb{E}}_{\vec{x}\sim RW_n}[\chi_1(x_{i_1})\cdots\chi_k(x_{i_k}))]=\sum_{\gamma_1,\ldots,\gamma_{k-2}\in \widehat{G}}\prod_{i=1}^{k-1}\Bigl(c_{\gamma_{i-1}}^{\rho_i,\gamma_i}\lambda_{\gamma_i}^{\Delta_i(\mathcal{S})}\Bigr).
$$

*where* γ<sup>0</sup> = triv, γk−<sup>1</sup> = ρ<sup>k</sup> *are fixed in the summation.*

*Proof.* The proof will be by induction on n. Since the graph is quasi-abelian all the characters are eigenvectors of the random walk matrix, AX. Thus for any fixed xi,

<span id="page-17-0"></span>
$$
\mathbb{E}_{x_{i+1} \sim \Delta_{i} x_i} [ \chi_{\gamma}(x_{i+1}) ] = \chi_{\gamma} ( A_{X}^{\Delta_i} \cdot x_i ) = \chi_{\gamma}(x_i) \cdot \lambda_{\gamma}^{\Delta_i}.
$$
 (7)

We do the base case when n = 2 which corresponds directly to [Fact 3.7.](#page-16-4)

$$
\mathbb{E}_{(\mathbf{x}_1,\mathbf{x}_2)}[\chi_{\rho_1}(\mathbf{x}_1)\cdot\chi_{\rho_2}(\mathbf{x}_2)] = \mathbb{E}_{\mathbf{x}_1}[\chi_{\rho_1}(\mathbf{x}_1)\cdot\mathbb{E}_{\mathbf{x}_2\sim^{\Delta_1}\mathbf{x}_1}[\chi_{\rho_2}(\mathbf{x}_2)]]
$$
\n
$$
= \lambda_{\rho_2}^{\Delta_1}\cdot\mathbb{E}_{\mathbf{x}_1}[\chi_{\rho_1}(\mathbf{x}_1)\cdot\chi_{\rho_2}(\mathbf{x}_1)] \qquad \text{(Using Eq. (7))}
$$
\n
$$
= \lambda_{\rho_2}^{\Delta_1}\cdot\mathbb{E}_{\mathbf{x}_1}\left[\sum_{\gamma} c_{\gamma}^{\rho_1,\rho_2}\chi_{\gamma}(\mathbf{x}_1)\right] \qquad \text{(Using Fact 3.7)} \qquad (8)
$$
\n
$$
= c_{\text{triv}}^{\rho_1,\rho_2}\cdot\lambda_{\rho_2}^{\Delta_1}.
$$

The last step above uses the fact that x<sup>1</sup> is sampled uniformly from X and thus for any non-trivial irrep, E<sup>x</sup><sup>1</sup> [χγ(x1)] = 0.

**Inductive Step** For the inductive step denote θ := χ1(x1) · · · χn−2(xn−2). By our inductive hypothesis, for any irreducible representation γ,

<span id="page-17-1"></span>
$$
\mathop{\mathbb{E}}_{\vec{x}\in\text{RW}_n}\left[\theta(x_1,\cdots,x_{n-2})\cdot\chi_{\gamma}(x_{n-1})\right] = \sum_{\gamma_1\cdots\gamma_{n-3}}\prod_{i=1}^{n-2}\left(c^{\rho_i,\gamma_i}_{\gamma_{i-1}}\lambda^{\Delta_i}_{\gamma_i}\right)
$$
(9)

Here, γn−<sup>2</sup> = γ by the inductive claim. We now compute the inductive step,

$$
\mathcal{E}_{X}(\chi_{\vec{\rho}}) = \mathop{\mathbb{E}}_{(\chi_{1},\cdots,\chi_{n-2})\sim RW_{n-2}}\left[\theta(\chi_{1},\cdots,\chi_{n-2})\cdot \mathop{\mathbb{E}}_{\chi_{n-1},\chi_{n}}[\chi_{\rho_{n-1}}(\chi_{n-1})\chi_{\rho_{n}}(\chi_{n})]\right]
$$
\n
$$
= \mathop{\mathbb{E}}_{(\chi_{1},\cdots,\chi_{n-2})\sim RW_{n-2}}\left[\theta(\chi_{1},\cdots,\chi_{n-2})\cdot \lambda_{\rho_{n}}^{\Delta_{n-1}}\cdot \mathop{\mathbb{E}}_{\chi_{n-1}}\left[\sum_{\gamma_{n-2}\in\widehat{G}}c_{\gamma_{n-2}}^{\rho_{n-1},\rho_{n}}\chi_{\gamma_{n-2}}(\chi_{n-1})\right]\right]
$$
\n
$$
= \sum_{\gamma_{n-2}}c_{\gamma_{n-2}}^{\rho_{n-1},\rho_{n}}\lambda_{\rho_{n}}^{\Delta_{n-1}}\cdot \mathop{\mathbb{E}}_{(\chi_{1},\cdots,\chi_{n-1})\sim X^{n-1}}\left[\theta(\chi_{1},\cdots,\chi_{n-2})\cdot \chi_{\gamma_{n-2}}(\chi_{n-1})\right]
$$
\n
$$
= \sum_{\gamma_{n-2}}c_{\gamma}^{\rho_{n-1},\rho_{n}}\lambda_{\rho_{n}}^{\Delta_{n-1}}\cdot \sum_{\gamma_{1}\cdots,\gamma_{n-3}}\prod_{i=1}^{n-2}\left(c_{\gamma_{i-1}}^{\rho_{i},\gamma_{i}}\lambda_{\gamma_{i}}^{\Delta_{i}}\right) \qquad \text{(Using Eq. (9))}
$$
\n
$$
= \sum_{\gamma_{1}\cdots,\gamma_{n-2}}\prod_{i=1}^{n-1}\left(c_{\gamma_{i-1}}^{\rho_{i},\gamma_{i}}\lambda_{\gamma_{i}}^{\Delta_{i}}\right).
$$

Note the from the expression γn−<sup>1</sup> = ρn−1. Thus, we obtain the RHS.

<span id="page-17-2"></span>We now derive two consequences from the above theorem that we will use later. We start with a simple one that we have already computed as the base case in our above proof. We write out separately as it we will utilize this case later. Moreover, it is conceptually important because it captures the operation of projecting to the space of G-invariants.

**Corollary 3.9.** *Let* X *be any pseudo Cayley graph. and let* ρ® *be such that* |®ρ| = 2 *where* ρ<sup>i</sup> = α *and* <sup>ρ</sup><sup>j</sup> <sup>=</sup> <sup>β</sup> *for* <sup>α</sup>, <sup>β</sup> <sup>∈</sup> <sup>G</sup><sup>b</sup> *and* <sup>1</sup> <sup>⩽</sup> <sup>i</sup> <sup>&</sup>lt; <sup>j</sup> <sup>⩽</sup> <sup>n</sup>*. Then,*

$$
\mathcal{E}_X(\vec{\rho}) = 0 \quad \text{if } \alpha \neq \beta^*,
$$
  
$$
\mathcal{E}_X(\vec{\rho}) = \lambda_\alpha(X)^{j-i} \cdot \mathop{\mathbb{E}}_{g \sim G} [\alpha \otimes \alpha^*(g)] =: \lambda_\alpha^{j-i} \cdot M_\alpha.
$$

*Here,* M<sup>α</sup> *is a* d 2 <sup>α</sup> × d 2 <sup>α</sup> *matrix with* tr(Mα) = 1*.*

*Proof.* This is the same computation as in the proof for the base case of k = 2 but now utilizing the matrix decomposition of α ⊗ β from [Fact 3.7.](#page-16-4)

Notice in the statement of [Theorem 3.8](#page-16-3) that if we have terms with many of the γ<sup>i</sup> being trivial, then this expectation can be large, as λtriv = 1. To see this, assume the extreme case when every λ<sup>γ</sup> = 1. Then, the term is just an inductive way to count the multiplicity of the trivial rep in the tensor-rep, ρ<sup>1</sup> ⊗ · · · ρn. To give a better bound, we make the following important observation that as no two consecutive γj, γj+<sup>1</sup> can be trivial. We recall the definition of Ik,

$$
\mathcal{I}_k = \{ \{1, k-1\} \subseteq I \subseteq [k-1] \mid \forall 1 < j < k-2, \{j, j+1\} \cap I \neq \emptyset \}
$$

**Observation 3.10.** Let ρ be any non-trivial irrep of G. Then, c ρ,triv triv <sup>=</sup> 0. Let {γ0, <sup>γ</sup>1, · · · , <sup>γ</sup>k−1} be a sequence of irreps such that γ<sup>0</sup> = triv and γk−<sup>1</sup> ≠ triv. Define, T<sup>γ</sup> := {i | γ<sup>i</sup> ≠ triv}. Then,

$$
\prod_{i=1}^{k-1} c_{\gamma_{i-1}}^{\rho_i,\gamma_i}=0 \quad \text{if } T_\gamma \notin \mathcal{I}_k \quad.
$$

*Proof.* By definition, c ρ,triv triv is the multiplicty of the trivial representation in <sup>ρ</sup> <sup>⊗</sup> triv which is zero as ρ is a non-trivial irrep. Now, if T<sup>γ</sup> ∉ Ik, either 1 ∉ T<sup>γ</sup> or there exists j such that {j − 1,j} ∉ Tγ. This is because k − 1 ∈ T<sup>γ</sup> by definition. In the first case, γ<sup>0</sup> = γ<sup>1</sup> = triv. In the second, we have γj, γj−<sup>1</sup> = triv. So we have that either the first term or the j th-term in the product is zero.

This shows that the term in [Theorem 3.8](#page-16-3) only sums over a subset of all possible sequences of irreps. To formalize this we make the following definition

<span id="page-18-0"></span>**Corollary 3.11.** *Let* {ρ1, . . . , ρk} *be a set of* k *non-trivial irreps of* G*, and* {χ1, . . . χk} *be the corresponding characters. Let* X *be any pseudo Cayley graph on* G*. Then for any subset* S *of size* k*,*

$$
|\mathcal{E}_{X,\mathcal{S}}(\chi_{\vec{\rho}})| \leq \left\langle \chi_{triv}, \chi_1 \cdots \chi_k \right\rangle \cdot \max_{T \in \mathcal{I}_k} \lambda^{\sum_{i \in T} \Delta_i(\mathcal{S})}
$$

.

*Proof.* Recall from [Theorem 3.8](#page-16-3) that,

$$
\mathcal{E}_{X,\mathcal{S}}(\chi_{\vec{\rho}})\;=\;\sum\limits_{\gamma_{1},\ldots,\gamma_{k-2}\in\widehat{G}}\prod\limits_{i=1}^{k-1}\Bigl(c^{\rho_{i},\gamma_{i}}_{\gamma_{i-1}}\lambda^{\Delta_{i}(\mathcal{S})}_{\gamma_{i}}\Bigr)
$$

$$
\mathcal{E}_{X,S}(\chi_{\vec{\rho}}) = \sum_{\substack{\gamma_{1,\dots,\gamma_{k-2}\in\widehat{G},\\ \tau_{\gamma}\in\mathcal{I}_{k}}}} \prod_{i=1}^{k-1} \left( c_{\gamma_{i-1}}^{\rho_{i},\gamma_{i}} \lambda_{\gamma_{i}}^{\Delta_{i}(s)} \right)
$$
\n
$$
|\mathcal{E}_{X,S}(\chi_{\vec{\rho}})| \leq \sum_{\substack{\gamma_{1,\dots,\gamma_{k-2}\in\widehat{G},\\ \tau_{\gamma}\in\mathcal{I}_{k}}}} \lambda^{\sum_{i\in\tau_{\gamma}} \Delta_{i}(S)} \prod_{i=1}^{k-1} c_{\gamma_{i-1}}^{\rho_{i},\gamma_{i}} \qquad (\text{For } \gamma_{i} \in T_{\gamma}, |\lambda_{\gamma_{i}}| \leq \lambda)
$$
\n
$$
\leq \max_{T\in\mathcal{I}_{k}} \lambda^{\sum_{i\in T} \Delta_{i}(S)} \sum_{\substack{\gamma_{1,\dots,\gamma_{k-2}\in\widehat{G} \\ \gamma_{1,\dots,\gamma_{k-2}\in\widehat{G} \\ T\in\mathcal{I}_{k}}}} \prod_{i=1}^{k-1} c_{\gamma_{i-1}}^{\rho_{i},\gamma_{i}}
$$

The last term just inductively counts the multiplicity of the trivial rep in the tensor representation ρ<sup>1</sup> ⊗ · · · ⊗ ρ<sup>k</sup> which is equal to χtriv, χ<sup>1</sup> · · · χ<sup>k</sup> from [Fact 3.7.](#page-16-4)

# <span id="page-19-0"></span>**4 Fooling Symmetric Functions and Word Functions**

The main goal is to study the pseudorandomness of expander walks via families of test functions. For a function, f : G<sup>n</sup> → C <sup>k</sup>×k, we wish to analyze

$$
\mathcal{E}_X(f) = \underset{\vec{x} \sim \text{RW}_n}{\mathbb{E}} [f(x_1, \ldots, x_n)] - \underset{\vec{x} \sim \text{Unif}_n}{\mathbb{E}} [f(x_1, \ldots, x_n)] .
$$

We have already analyzed this for tensor functions [\(Theorem 1.2\)](#page-4-1). Using Fourier transform, we will first see how studying the fooling of arbitrary functions reduces the problem to measuring the fooling of tensor product of irreducible representations.

## <span id="page-19-1"></span>**4.1 A general reduction to fooling irreps**

<span id="page-19-2"></span>**Claim 4.1.** *Let,* f : G<sup>n</sup> → C *be any function, and denote its degree-*i *component as* fi*. Then,*

$$
\mathcal{E}_X(f) = \sum_{i \ge 2} \mathcal{E}_X(f_i), \text{ and}
$$
  
$$
|\mathcal{E}_X(f_i)| \le \sum_{\vec{p}, |\vec{p}| = i} d_{\vec{p}} ||f(\hat{p})||_{tr} \cdot ||\mathcal{E}_X(\vec{p})||_{op}, \forall i \in [n].
$$

*Proof.* By definition f = P<sup>n</sup> i=0 fi, and by linearity EX(f) = P<sup>n</sup> i=0 EX(fi). We will first show that EX(f0) = EX(f1) = 0 to prove the first claim.

The level 0 function, f<sup>0</sup> is a constant and hence its mean is the same under any distribution. Thus, EX(f0) = ν(f0) − µ(f0) = 0. Applying the Fourier transform to level i,

$$
f_i = \sum_{\vec{\rho} \in \text{Irrep}(G^n), |\vec{\rho}| = i} d_{\vec{\rho}} \langle \hat{f}(\rho), \rho(\vec{g}) \rangle,
$$
  
$$
\mu(f_i) = \sum_{|\vec{\rho}| = i} d_{\vec{\rho}} \langle \hat{f}(\vec{\rho}), \mu(\vec{\rho}) \rangle.
$$

<span id="page-20-4"></span>For level 1, ρ®(®g) = ρk(gk) for some k, and by [Fact 2.3,](#page-10-3) νn(®ρ(®g)) = γk(gk) = ν1(gk) = µ(gk). Thus, νn(®ρ) = µ <sup>n</sup>(®ρ), and EX(f1) = 0. Now, to obtain the second inequality, we use the above equation for our two distributions (the random walk, ν, and the product µ <sup>n</sup>):

$$
\mathcal{E}_X(f_i) = \sum_{|\vec{\rho}|=i} d_{\vec{\rho}} \langle \hat{f}(\vec{\rho}), \nu_n(\vec{\rho}) - \mu^n(\vec{\rho}) \rangle_{HS}
$$
(10)

<span id="page-20-3"></span>
$$
= \sum_{|\vec{\rho}|=i} d_{\vec{\rho}} \langle \hat{f}(\vec{\rho}), \mathcal{E}_X(\vec{\rho}) \rangle_{HS}
$$
 (11)

$$
|\mathcal{E}_X(f_i)| \leq \sum_{|\vec{\rho}|=i} d_{\vec{\rho}} \left\| f(\hat{\rho}) \right\|_{tr} \cdot \left\| \mathcal{E}_X(\vec{\rho}) \right\|_{op}.
$$
 (12)

The last inequality follows by combining Von Neumann's trace inequality and Hölder's inequality.

## <span id="page-20-0"></span>**4.2 Fooling symmetric functions**

Let f : G<sup>n</sup> → C be a function that is invariant under any permutation of the input tuple. Such a function only depends on the counts of each group element in the tuple and, therefore, can be viewed as a symmetric function on Z n |G|+1 . Appealing to the results of Golowich–Vadhan [\[GV22\]](#page-33-6), one gets a decay of O(|G| <sup>O</sup>(|G|)λ). We obtain an exponentially better bound of O(|G|λ) by utilizing a Fourier basis for G.

**Preparatory lemmas** In the Boolean case, the Fourier coefficient of a symmetric function f, is unchanged under permutation of the non-trivial coordinates, i.e., <sup>ˆ</sup>f(χ<sup>T</sup> ) <sup>=</sup> <sup>ˆ</sup>f(χT′) for any subsets T, T ′ of size k. Unsurprisingly, this extends to the case of general groups.

<span id="page-20-1"></span>**Observation 4.2** (Fourier Coefficient under permutation)**.** Let ρ1, · · · ρ<sup>k</sup> be any k non-trivial irreps and let T = {t1, · · · , tk} be some ordered subset of [n]. Denote by ρ®<sup>T</sup> the irrep with (®ρ<sup>T</sup> )t<sup>j</sup> = ρ<sup>j</sup> and trivial otherwise. Let σ be the permutation that maps T → T ′ for any other T of size k. Then for any symmetric function f,

$$
\hat{f}(\vec{\rho}_T) = \mathop{\mathbb{E}}_{\vec{x} \in G^n} [f(\vec{x}) \rho_1(x_{t_1}) \otimes \cdots \otimes \rho_k(x_{t_k})]
$$
\n
$$
= \mathop{\mathbb{E}}_{\vec{x} \in G^n} [f(\sigma^{-1} \cdot \vec{x}) \rho_1(x_{t_1}) \otimes \cdots \otimes \rho_k(x_{t_k})]
$$
\n
$$
= \mathop{\mathbb{E}}_{\vec{y} \in G^n} [f(\vec{y}) \rho_1(y_{\sigma t_1}) \otimes \cdots \otimes \rho_k(y_{\sigma t_k})]
$$
\n
$$
= \mathop{\mathbb{E}}_{\vec{y} \in G^n} [f(\vec{y}) \rho_1(y_{t'_1}) \otimes \cdots \otimes \rho_k(y_{t'_k})] = \hat{f}(\vec{\rho}_{T'}).
$$

In particular, all norms are preserved.

We now obtain a trivial upper bound on the trace-norm of the Fourier transform, in terms of the L <sup>2</sup> norm. This is a fairly standard application of Cauchy-Schwarz.

<span id="page-20-2"></span>**Lemma 4.3** (Trace norm to L2-norm)**.** *For any symmetric function* f : G<sup>n</sup> → C*,*

$$
\sum_{\vec{p} = \rho_1 \otimes \cdots \rho_k \otimes I \cdots \otimes I, \rho_i \neq triv} d_{\vec{p}} \left\| \hat{f}(\vec{p}) \right\|_{tr} \leq \frac{|G|^{\frac{k}{2}}}{\sqrt{\binom{n}{k}}} \cdot \| f_k \|_2.
$$

<span id="page-21-2"></span>*Proof.* Let ℓ denote the LHS of this inequality. By Cauchy-Schwarz inequality,

$$
\ell^{2} \leq \sum_{\vec{\rho} = \rho_{1} \otimes \cdots \rho_{k} \otimes I \cdots \otimes I, \rho_{i} \neq \text{triv}} d_{\vec{\rho}}^{2} \sum_{\vec{\rho} = \rho_{1} \otimes \cdots \rho_{k} \otimes I \cdots \otimes I, \rho_{i} \neq \text{triv}} \|\hat{f}(\vec{\rho})\|_{tr}^{2}
$$
  
$$
\leq (\sum_{\rho \neq \text{triv}} d_{\rho}^{2})^{k} \sum_{\vec{\rho} = \rho_{1} \otimes \cdots \rho_{k} \otimes I \cdots \otimes I, \rho_{i} \neq \text{triv}} \|\hat{f}(\vec{\rho})\|_{tr}^{2}
$$
  
$$
= (|G| - 1)^{k} \sum_{\vec{\rho} = \rho_{1} \otimes \cdots \rho_{k} \otimes I \cdots \otimes I, \rho_{i} \neq \text{triv}} \|\hat{f}(\vec{\rho})\|_{tr}^{2}
$$
  
$$
= |G|^{k} \cdot {n \choose k}^{-1} \sum_{\vec{\rho} \in \text{Irrep}(G^{n}): |\vec{\rho}| = k} \|\hat{f}(\vec{\rho})\|_{tr}^{2}
$$

The last equality above utilizes the symmetry of f and applies [Observation 4.2.](#page-20-1) To compute the remaining term, we use Hölder's inequality, which implies that

$$
\left\|\hat{f}(\vec{\rho})\right\|_{tr}^{2} \leq d_{\rho} \left\|\hat{f}(\vec{\rho})\right\|_{HS}^{2}.
$$

Plugging this in and using the definition of f<sup>k</sup> finishes the proof:

$$
\ell^{2} \leq |G|^{k} \cdot {n \choose k}^{-1} \cdot \sum_{\vec{p} \in \text{Irrep}(G^{n}): |\vec{p}| = k} \|\hat{f}(\vec{p})\|_{tr}^{2}
$$
  
$$
\leq |G|^{k} \cdot {n \choose k}^{-1} \cdot \sum_{\vec{p} \in \text{Irrep}(G^{n}): |\vec{p}| = k} d_{\vec{p}} \|\hat{f}(\vec{p})\|_{HS}^{2}
$$
  
$$
= |G|^{k} \cdot {n \choose k}^{-1} \cdot \|f_{k}\|_{2}^{2}.
$$

We now recall the key combinatorial bound from [\[CPTS21\]](#page-32-4)

<span id="page-21-1"></span>**Lemma 4.4** ([\[CPTS21,](#page-32-4) Lemma 4.4])**.** *For any* 2 ⩽ k ⩽ n*, and* λ < 1/2 *we have*

$$
\beta(k)=\sum_{|S|=k}\lambda^{\Delta(S)/2}~\leqslant~2^k\binom{n-1}{\lfloor k/2\rfloor}\Bigl(\frac{\lambda}{1-\lambda}\Bigr)^{k/2}~\leqslant~\binom{n}{k}^{\frac{1}{2}}(16e\lambda)^{k/2}.
$$

*Proof.* The first inequality is from the reference and the second follows by observing that

$$
\binom{n-1}{\lfloor k/2 \rfloor}^2 \leqslant \binom{n}{k} (2e)^k, \text{ and for } \lambda < 1/2, \left( \frac{\lambda}{1-\lambda} \right) \leqslant 2\lambda.
$$

<span id="page-21-0"></span>**Theorem 4.5.** *Let* f *be any symmetric function over* G<sup>n</sup> *where* G *is any finite group. Let* τ = 16eλ|G|*. Then, for any* k ⩾ 2*,*

$$
|\mathcal{E}_X(f_k)| \ \leq \ \tau^{k/2} \cdot \|f\|_2. \ And \ thus, \ |\mathcal{E}_X(f)| \ \leq \ 2\tau \cdot \|f\|_2, \ if \ \tau < 1.
$$

*Proof.* We will use ρ®<sup>S</sup> to denote the representation given by ρ<sup>i</sup> =.

$$
|\mathcal{E}(f_k)| \leq \sum_{\vec{\rho} \in \text{Irrep}(G^n), |\vec{\rho}| = k} d_{\vec{\rho}} \| \hat{f}(\vec{\rho}) \|_{tr} \cdot \| \mathcal{E}_X(\vec{\rho}) \|_{op}
$$
 (Using Claim 4.1)

$$
\leq \sum_{\vec{\rho}} d_{\vec{\rho}} \| \hat{f}(\vec{\rho}) \|_{tr} \sum_{S \in {n \choose k}} \| \mathcal{E}_{X}(\vec{\rho}_{S}) \|_{op}
$$
 (Using observation 4.2)  
\n
$$
\leq \sum_{\vec{\rho}} d_{\vec{\rho}} \| \hat{f}(\vec{\rho}) \|_{tr} \sum_{S \in {n \choose k}} \lambda^{\Delta(S)/2}
$$
 (Using Corollary 3.2)  
\n
$$
\leq \sum_{\vec{\rho}} d_{\vec{\rho}} \| \hat{f}(\vec{\rho}) \|_{tr} \cdot {n \choose k}^{\frac{1}{2}} (16e\lambda)^{k/2}
$$
 (Using Lemma 4.4)  
\n
$$
\leq (16e\lambda)^{k/2} \cdot |G|^{k/2} \cdot ||f||_{2}
$$
 (Using Lemma 4.3)  
\n
$$
= (\tau)^{k/2} ||f||_{2}.
$$

To get the last inequality, we use [Claim 4.1](#page-19-2) and obtain that:

$$
|\mathcal{E}_X(f)| \leq \sum_{i \geq 2} |\mathcal{E}_X(f_i)| \leq \left(\sum_{k \geq 2} \tau^{k/2}\right) ||f||_2 \leq 2\tau ||f||_2 \quad \text{if } \tau < 1. \qquad \blacksquare
$$

## <span id="page-22-0"></span>**4.3 Word functions**

A *word map* of a finite group G is an element of the free group on G. Given any h : G → C and a word map w : G<sup>n</sup> → G, one can consider the composed map h(w(·)) : G<sup>n</sup> → C, which is commonly referred to as a *word function*. Word functions are ubiquitous in mathematics and computer science literature.

The main result of this section is to give a complete characterization of the Fourier spectrum of a certain subclass of word functions that will be termed *monomial word functions*. In particular, first we will show that these have Fourier support on the highest level and thus are analogs of the PARITY function over Z n 2 . Moreover, this support is also sparse. Combining this with [Corollary 3.2,](#page-15-2) we deduce that such functions are exponentially fooled by expander walks.

**Definition 4.6** (Monomials and Word function)**.** For an ordered subset S ⊆ [n], a *word map* of *degree* k = |S| is a G-valued function w<sup>S</sup> : G<sup>n</sup> → G, defined as w<sup>S</sup> = Î <sup>s</sup>∈<sup>S</sup> g es <sup>s</sup> where e<sup>S</sup> ∈ Z. A word is *monomial* if the variables are non-repeating and the exponent is ±1. A function f : G<sup>n</sup> → C is a *monomial word function* of degree k, if f = h(w(g1, · · · , gn)) for a monomial word w of degree k and a function h : G → C.

In the second half of this section, we consider a subclass of functions within monomial word functions that we call *monotone word functions*. Essentially, these are word functions for which corrresponding word, w is monotone i.e., w = xi<sup>1</sup> · · · xi<sup>k</sup> for i<sup>1</sup> ⩽ · · ·ik. We already mentioned that for monomial word functions gets fooled by expander walks upto an exponentially decaying error. However, the error bound has dependence on |G|. For monotone word functions we remove this dependence while achieving the same decay in terms of expansion.

#### <span id="page-23-0"></span>**4.3.1 Fourier Spectrum of Word functions**

We begin by proving a structural claim about the fourier coefficients of word functions. The claim that we prove below essentially says that a word function f : G<sup>n</sup> → C that only utilizes a subset S ⊆ [n] of the input co-ordinates is only supported on representations ρ® such that ρ<sup>i</sup> = triv for i ∉ S and ρ<sup>i</sup> ∈ {ρ, ρ ∗ } otherwise. Note that, the fourier structure of these word functions on more general groups closely resemble the special case of parities.

<span id="page-23-1"></span>**Lemma 4.7** (Fourier Mass Support)**.** *Let* f : G<sup>n</sup> → C *be a word function of degree* k *corresponding to a set* S*. Let* S <sup>+</sup> *(resp.* S <sup>−</sup>*) be the subset of elements such that* <sup>e</sup><sup>s</sup> <sup>=</sup> <sup>1</sup> *(resp.,* <sup>−</sup>1*). Then,* <sup>ˆ</sup>f(®ρ) <sup>≠</sup> <sup>0</sup> *only if*

- *1. For every* i ∉ S*,* ρ<sup>i</sup> = triv*.*
- *2. For every* i ∈ S <sup>+</sup> ρ<sup>i</sup> = ρ *for some* ρ ∈ Irrep(G)*.*
- *3. For every* i ∈ S <sup>−</sup> ρ<sup>i</sup> = ρ ∗ *for the same* ρ *as above.*

*Proof.* We will permute the operators and push the spaces we argue about to the end. Claim (1) is quite easy to prove and intuitive as the function does not depend on variable i and thus cannot have mass on those irreps. Formally, let i ∉ S. Then,

$$
\hat{f}(\vec{\rho}) = \mathop{\mathbb{E}}_{\vec{g}_i} \bigg[ \rho_1(g_1) \otimes \cdots \otimes \rho_n(g_n) \otimes \mathop{\mathbb{E}}_{g_i} \big[ \rho_i(g_i) f(\vec{g}) \big] \bigg]
$$
\n
$$
= \mathop{\mathbb{E}}_{\vec{g}_i} \bigg[ \rho_1(g_1) \otimes \cdots \otimes \rho_n(g_n) \otimes f(\vec{g}) \mathop{\mathbb{E}}_{g_i} \big[ \rho_i(g_i) \big] \bigg] = 0.
$$

Any h : G → C can be written as h(x) = P <sup>t</sup> <sup>h</sup>(t)I[<sup>x</sup> <sup>=</sup> <sup>t</sup>]. Since the Fourier transform is linear it suffices to prove it for the indicator functions. Thus, we let f(®g) = I[w(®g) = t], and pick any i < j ∈ S <sup>+</sup>. Let <sup>w</sup>(®g) <sup>=</sup> <sup>w</sup>1giw2gjw<sup>3</sup> <sup>=</sup> <sup>t</sup>. Assume that <sup>ρ</sup><sup>i</sup> <sup>≠</sup> <sup>ρ</sup>j.

$$
\hat{f}(\vec{\rho}) = \mathop{\mathbb{E}}_{\vec{\rho}_{i,j}} \bigg[ \rho_1(g_1) \otimes \cdots \otimes \rho_n(g_n) \otimes \mathop{\mathbb{E}}_{g_{i},g_j} \big[ \rho_i(g_i) \otimes \rho_j(g_j) \mathbb{I}[w(g) = t] \big] \bigg]
$$
\n
$$
= \mathop{\mathbb{E}}_{\vec{\rho}_{i,j}} \bigg[ \rho_1(g_1) \otimes \cdots \otimes \rho_n(g_n) \otimes \mathop{\mathbb{E}}_{g_{i},g_j} \big[ \rho_i(g_i) \otimes \rho_j(w_2^{-1}g_i^{-1}w_1^{-1}tw_3^{-1}) \big] \bigg]
$$
\n
$$
= \mathop{\mathbb{E}}_{\vec{\rho}_{i,j}} \bigg[ \rho_1(g_1) \otimes \cdots \otimes \rho_n(g_n) \otimes \big[ (\mathbb{I} \otimes \rho_j(w_2^{-1})) \mathop{\mathbb{E}}_{g_{i},g_j} \big[ \rho_i(g_i) \otimes \rho_j(g_i^{-1}) \big] (\mathbb{I} \otimes \rho_j(w_1^{-1}tw_3^{-1})) \big] \bigg]
$$
\n
$$
= \mathop{\mathbb{E}}_{\vec{\rho}_{i,j}} \bigg[ \rho_1(g_1) \otimes \cdots \otimes \rho_n(g_n) \otimes \big[ (\mathbb{I} \otimes \rho_j(w_2^{-1})) \mathop{\mathbb{E}}_{g_{i},g_j} \big[ \rho_i(g_i) \otimes \rho_j^*(g_i) \big] (\mathbb{I} \otimes \rho_j(w_1^{-1}tw_3^{-1})) \big] \bigg]
$$
\n
$$
= 0 \qquad \text{(Using Fact 3.7)}.
$$

The proof for claim (3) is identical but now we consider i ∈ S <sup>+</sup>, j ∈ S <sup>−</sup>. The term is then ρ(gi) ⊗ ρj(gj) which is non-zero unless ρ<sup>i</sup> = ρ ∗ j .

#### <span id="page-24-3"></span><span id="page-24-0"></span>**4.3.2 Fooling Word Functions**

Before we state our first theorem in this section we recall two notations from [Section 3.](#page-12-0) Let S = {i<sup>1</sup> < i<sup>2</sup> < · · · < ik−<sup>1</sup> < ik} be an ordered subset of {1, 2, . . . , n}. We define the following key quantities:

- 
$$
\mathcal{I}_k = \{ \{1, k-1\} \subseteq I \subseteq [k-1] \mid \forall 1 < j < k-1, \{j, j+1\} \cap I \neq \emptyset \}.
$$
  
-  $\Delta_j(\mathcal{S}) = i_{j+1} - i_j.$ 

We have the following theorem on monomial word functions.

<span id="page-24-1"></span>**Theorem 4.8** (Fooling for degree k word functions)**.** *Let* f : G<sup>n</sup> → C *be a monomial word function of degree* k *corresponding to a set* S*. Then for any expander* X *with an unbiased* G*-labelling,*

$$
|\mathcal{E}_X(f)| \ \leqslant \ \sum_{I \in \mathcal{I}_k} \lambda^{\sum_{j \in I} \Delta_j(\mathcal{S})} \cdot |G|^{k/2} \cdot \|f\|_2 \ .
$$

*In particular, we have* |EX(f)| ⩽ λ −1 (λ|G|)k/<sup>2</sup> · ∥f∥<sup>2</sup>

*Proof.* Let ρ <sup>S</sup> denote the representation ρ<sup>1</sup> ⊗ ρ<sup>2</sup> ⊗ · · · ⊗ ρ<sup>n</sup> where ρ<sup>i</sup> = ρ if i ∈ S + I , ρ<sup>i</sup> = ρ ∗ if i ∈ S − I , and is trivial otherwise, i.e., ρ<sup>i</sup> = 1. From [Lemma 4.7,](#page-23-1) we know that the only nonzero Fourier coefficients are for such ρ <sup>S</sup>. Thus we will consider these irreps for expander walk fooling.

$$
\mathcal{E}(f) \leq \sum_{\psi \in \text{Irrep}(G^n)} d_{\psi} \|\hat{f}(\psi)\|_{tr} \cdot \left\| \underset{\vec{g} \sim X^n}{\mathbb{E}} [\psi(\vec{g})] \right\|_{op}
$$
 (Using Claim 4.1)  
\n
$$
\leq \sum_{\rho \in \text{Irrep}(G)} d_{\rho s} \|\hat{f}(\rho^s)\|_{tr} \cdot \left\| \underset{\vec{g}}{\mathbb{E}} [\rho^s(\vec{g})] \right\|_{op}
$$
 (Using Lemma 4.7)  
\n
$$
\leq \sum_{I \in \mathcal{I}_k} \lambda^{\sum_{j \in I} \Delta_j(\mathcal{S})} \sum_{\rho \in \text{Irrep}(G)} d_{\rho}^k \|\hat{f}(\rho^S)\|_{tr}
$$
 (Using Corollary 3.2)  
\n
$$
\leq \sum_{I \in \mathcal{I}_k} \lambda^{\sum_{j \in I} \Delta_j(\mathcal{S})} \cdot |G|^{k/2} \cdot \|f\|_{2}.
$$

The last line follows from Cauchy-Schwarz and Hölder's inequality.

We now give an alternate proof of the above result in the special case that the word is monotone i.e., w = xi<sup>1</sup> · · · xi<sup>k</sup> for i<sup>1</sup> < · · · < ik. The change is that we now the Fourier decomposition of h : G → C i.e., over G rather than of f directly. To analyze this, we will need the result from [\[JMRW22\]](#page-33-7).

**Theorem 4.9** ( [\[JMRW22\]](#page-33-7))**.** *Let* X *be any* λ*-expander with an unbiased labelling of* G*. Then for any non-trivial irrep* ρ *of* G*,*

$$
\|\mathcal{E}_X(\rho(x_1\cdots x_k))\|_{op} \ \leqslant \ \lambda^{k/2}.
$$

<span id="page-24-2"></span>The result in [\[JMRW22\]](#page-33-7) works for any product function and thus if x<sup>i</sup> contains an inverse then, we can pick f<sup>i</sup> = ρ ∗ instead of ρ as ρ ∗ (xi) = ρ(x<sup>i</sup> −1 )

**Theorem 4.10.** *Let* f(®x) = h(x<sup>1</sup> · · · xk) *be a monotone word function for some* h : G → C*. Then for any expander* X *with an unbiased* G*-labelling,*

$$
|\mathcal{E}_X(f)| \ \leqslant \ \left(\sqrt{|G|}\cdot \|f\|_2\right) \cdot (2\lambda)^{k/2}.
$$

*In particular, for* <sup>f</sup>(®x) <sup>=</sup> <sup>1</sup>{x1···xk=t} *for any* t ∈ G*, one has* |EX(f)| ⩽ (2λ) k/2 *.*

*Proof.* We assume that the word does not contain inverses and is x<sup>1</sup> · · · x<sup>k</sup> which is true up to renumbering the coordinates. By the Fourier transform on G,

$$
h(t)=\sum_{\rho\in\operatorname{Irrep}(G)}d_{\rho}\bigl\langle\widehat{h}(\rho),\,\rho(t)\bigr\rangle.
$$

Now we feed in t = x<sup>1</sup> · · · x<sup>n</sup> into the function h.

$$
f(\vec{x}) = h(x_1 \cdots x_k) = \sum_{\rho \in \text{Irrep}(G)} d_{\rho} \langle \hat{h}(\rho), \rho(x_1 \cdots x_k) \rangle
$$
  
$$
\mathcal{E}_X(f) = \sum_{\rho \in \text{Irrep}(G)} d_{\rho} \langle \hat{h}(\rho), \mathcal{E}_X(\rho(x_1 \cdots x_k)) \rangle
$$
  
$$
|\mathcal{E}_X(f)| \le \sum_{\rho \in \text{Irrep}(G), \rho \ne \text{triv}} d_{\rho} ||\hat{h}(\rho)||_{tr} ||\mathcal{E}_X(\rho(x_1 \cdots x_k))||_{op}
$$
  
$$
\le \lambda^{k/2} \cdot \sqrt{|G|} \cdot ||h||_2 = \lambda^{k/2} \cdot \sqrt{|G|} \cdot ||f||_2.
$$

The last equality is a simple calculation that uses that for any fixed x1, . . . , x<sup>i</sup> the word x<sup>1</sup> · · · x<sup>i</sup> · g is uniform over G if g is sampled uniformly from G.

$$
||f||_2^2 = \mathop{\mathbb{E}}_{x_1, ..., x_k} [|h(x_1 \cdots x_k)|^2] = \mathop{\mathbb{E}}_{x_1, ..., x_{k-1}} \bigg[ \mathop{\mathbb{E}}_{x_k} [|h(x_1 \cdots x_k)|^2] \bigg] = \mathop{\mathbb{E}}_{x_1, ..., x_{k-1}} [||h||_2^2].
$$

When h = 1x=t, then ∥h∥<sup>2</sup> = |G| −1/2 and the second claim follows.

# <span id="page-25-0"></span>**5 Function Classes with Group Symmetry**

A general group G has a much richer symmetry structure than Z2, and this opens up the possibility of studying functions, f : G<sup>n</sup> → C, that respect this additional symmetry (beyond permutation of coordinates).

# <span id="page-25-1"></span>**5.1 Symmetric Class Functions**

A function over G<sup>n</sup> is a *class function* if it is invariant under conjugation, i.e., for any x®, g® ∈ Gn, f(g1x1g<sup>1</sup> −1 , . . . , gnxng<sup>n</sup> −1 ). In other words, the function value depends only on the input's conjugacy class. In this subsection, we will give a better bound for symmetric class functions than the one for general symmetric functions. The improvement for class functions will come from a precise calculation of our EX(f) expression, without resorting to a Cauchy-Schwarz–type bound to go from L1-norm to L2-norm [\(Lemma 4.3\)](#page-20-2). To do this, we need to use the group structure.

**Representation theory facts** We now state some basic facts about the representation theory of groups that we will need only in this subsection. These are well-known facts and proofs can be found in any introductory text.

**Fact 5.1** (Class Function Fourier Coefficients)**.** *For any class function* f : H → C*,*

$$
\widehat{f}(\vec{\rho}) = c_{\vec{\rho}} I_{d_{\vec{\rho}}}, \qquad ||f||_2^2 = \sum_{\vec{\rho}} d_{\rho} ||\widehat{f}(\vec{\rho})||_{\text{HS}}^2 = \sum_{\vec{\rho}} d_{\rho}^2 c_{\vec{\rho}}^2.
$$

<span id="page-26-0"></span>**Fact 5.2** (Schur Orthogonality Relation)**.** *For any* g, h ∈ G*, we denote* g ∼ h *if they belong to the same conjugacy class, say* Cg*. Then, we have,*

$$
\sum_{\rho \in \text{Irrep}\, G} \chi_{\rho}(g) \overline{\chi_{\rho}}(h) \ = \ \frac{|G|}{|C_g|} \cdot 1\!\!1_{\{g \sim h\}}.
$$

<span id="page-26-1"></span>**Fact 5.3.** *Let* G *be a* D*-quasirandom, i.e., the smallest non-trivial irrep has dimension* D*. Let* C(G) *denote the conjugacy classes of* G*. Then,*

$$
|C(G)| = |\widehat{G}| \leq \frac{|G|}{D^2} + 1.
$$

*Proof.* The first equality follows from the fact that characters form a basis for class functions (or in other words, the character table is square). The second follows from the following:

$$
\sum_{\rho \in \widehat{G}} d_{\rho}^2 = |G| \geq 1 + D^2 \cdot (|\mathcal{C}(G)| - 1). \qquad \blacksquare
$$

We are now ready to assemble the above facts to bound Eg∼G[χρ1⊗···⊗ρ<sup>k</sup> ] which counts the multiplicity of trivial rep in ρ<sup>1</sup> ⊗ · · · ⊗ ρk. This claim allows us to improve upon [Lemma 4.3](#page-20-2) which would be analogous to a bound of |G| <sup>k</sup> in the below term.

**Corollary 5.4.** *For any finite group* G *denote by* C(G) *the conjugacy classes of* G*. For any* k ⩾ 1*,*

$$
\eta_{k,G}^2 \;:=\; \sum_{\rho_1,\cdots,\rho_k\in \operatorname{Irrep}\backslash \operatorname{triv}} \Bigl(\mathop{\mathbb{E}}_g\bigl[\chi_{\rho_1\otimes \cdots \otimes \rho_k}\bigr]\Bigr)^2 \;\leqslant\; \; \sum_{C\in \mathcal{C}(G)} \frac{|G|^{k-2}}{|C|^{k-2}} + 1.
$$

*In particular, if* G *is* D*-quasirandom, then* η 2 k,G ⩽ 4 · |G| k−1 D2 *.*

*Proof.* The proof is a simple computation given the above fact.

$$
\sum_{\rho_1,\dots,\rho_k \in \text{Irrep}\backslash \text{triv}} \left( \mathbb{E} \left[ \chi_{\vec{\rho}} \right] \right)^2 = \sum_{\rho_i} \prod_i \left( \mathbb{E}_{g,h} \left[ \chi_{\rho_i}(g) \overline{\chi_{\rho_i}}(h) \right] \right)
$$
  
$$
= \mathbb{E}_{g,h} \left[ \sum_{\rho_i} \prod_i \left( \chi_{\rho_i}(g) \overline{\chi_{\rho_i}}(h) \right) \right]
$$
  
$$
= \mathbb{E}_{g,h} \left[ \prod_i \sum_{\rho_i \neq \text{triv}} \left( \chi_{\rho_i}(g) \overline{\chi_{\rho_i}}(h) \right) \right].
$$

Now we use [Fact 5.2](#page-26-0) and subtract off the summand corresponding to the trivial irrep (which is just 1).

$$
\begin{aligned} \sum_{\rho_1,\cdots,\rho_k\in\operatorname{Irrep}\backslash\operatorname{triv}} \left(\underset{g}{\mathbb{E}}\big[X_{\vec{\rho}}\big]\right)^2 \; &= \; \underset{g,h}{\mathbb{E}}\Bigg[\prod_i \left(\frac{|G|}{|C_g|}\mathbb{1}_{\{g\sim h\}}-1\right)\Bigg] \\ &\leqslant \; \underset{g,h}{\mathbb{E}}\Bigg[\left(\frac{|G|}{|C_g|}\right)^k \mathbb{1}_{\{g\sim h\}} + 1\Bigg] \\ &\leqslant \; \sum_{C\in\mathcal{C}(G)} \frac{|C|^2}{|G|^2} \frac{|G|^k}{|C|^k} + 1 = \sum_{C\in\mathcal{C}(G)} \frac{|G|^{k-2}}{|C|^{k-2}} + 1. \end{aligned}
$$

Now, we use [Fact 5.3](#page-26-1) to conclude that

$$
\eta_{k,G} \ \leqslant \ 2 \sum_{C \in \mathcal{C}(G)} \frac{|G|^{k-2}}{|C|^{k-2}} \ \leqslant \ 2|G|^{k-2} \cdot |\mathcal{C}(G)| \ \leqslant \ 4 \frac{|G|^{k-1}}{D^2} . \qquad \blacksquare
$$

<span id="page-27-0"></span>**Proposition 5.5.** *Let* G *be a* D*-quasirandom group and* f : G<sup>n</sup> :→ C *be a class function that is also symmetric. Let* X *be a pseudo Cayley graph with expansion* λ*. Then,*

$$
|\mathcal{E}_X(f)| \leqslant O\Big(\frac{|G|^{\frac{1}{2}}}{D}\lambda\Big) \cdot \|f\|_2.
$$

*In particular, for every symmetric function on an Abelian group, we get a bound of* O( p |G| · λ)*.*

*Proof.* We first prove a bound for the degree k component of f.

$$
\mathcal{E}_{X}(f_{k}) = \sum_{\vec{\rho} \in Irrep(G^{n})} d_{\vec{\rho}} c_{\vec{\rho}} \cdot \mathcal{E}_{X}(\chi_{\vec{\rho}})
$$
\n
$$
= \sum_{\rho_{1}, \dots \rho_{k} \in Irrep(G) \setminus triv} \sum_{S \subseteq {n \choose k}} d_{\vec{\rho}} c_{\vec{\rho}} \cdot \mathcal{E}_{X}(\chi_{\vec{\rho}})
$$
\n
$$
|\mathcal{E}_{X}(f_{k})| \leq \sum_{\rho_{1}, \dots \rho_{k} \in Irrep(G) \setminus triv} d_{\vec{\rho}} \sum_{S \subseteq {n \choose k}} |c_{\vec{\rho}}| \cdot |\mathcal{E}_{X}(\chi_{\vec{\rho}})|
$$
\n
$$
\leq \sum_{\rho_{1}, \dots \rho_{k} \in Irrep(G) \setminus triv} |d_{\vec{\rho}} c_{\vec{\rho}}| \cdot (\mathbb{E}[X_{\vec{\rho}}]) \sum_{S \subseteq {n \choose k}} \lambda^{\Delta(S)/2}
$$
\n
$$
\leq \beta(k) \sum_{\rho_{1}, \dots \rho_{k}} |d_{\vec{\rho}} c_{\vec{\rho}}|^{2} \cdot \sqrt{\sum_{\rho_{1}, \dots \rho_{k}} (\mathbb{E}[X_{\vec{\rho}}])^{2}}
$$
\n
$$
\leq \beta(k) \cdot \frac{||f_{k}||_{2}}{\sqrt{\binom{n}{k}} \cdot \sqrt{n_{k,G}^{2}}}
$$
\n
$$
\leq (16e\lambda)^{k/2} \cdot \eta_{k,G} \cdot ||f_{k}||_{2}
$$
\n
$$
\leq (16e\lambda \cdot 2|G|)^{k/2} \cdot \frac{1}{D\sqrt{|G|}} \cdot ||f||_{2}.
$$

Therefore,

$$
|\mathcal{E}_X(f)| \ \leqslant \ \sum_{k=2}^n \left|\mathcal{E}_X\big(f_k\big)\right| \ \leqslant \ \Big(\frac{64e\lambda |G|}{D\sqrt{|G|}}\Big) \cdot \|f\|_2\ = \ O\Bigg(\frac{\lambda\sqrt{|G|}}{D}\Bigg) \cdot \|f\|_2 \quad . \qquad \blacksquare
$$

# <span id="page-28-0"></span>**5.2 Diagonal action and** G**-invariant functions**

**Definition 5.6** (Diagonal action and Projection)**.** Let h ∈ G and f : G<sup>n</sup> → C. Define (h · f)(®x) := f(hx1, . . . , hxn) = f(h · ®x). The projection to the space of functions invariant under this action is PGf(®x) := Eh∼G[(h · f)(®x)].

This generalizes the notion of even and odd functions over Z n <sup>2</sup> which are the special cases when PG(f) = f and PGf = 0, respectively. We now make a simple observation that walks over Cayley graphs smooth out the function via this projection.

**Observation 5.7.** If X is a Cayley graph, then EX(f) = EX(PGf).

We will now compute the Fourier spectrum of PGf and utilize this to get a precise calculation of level-2 mass. While this can be generalized to state a more general claim, we just include the version we will need later for the lower bound.

<span id="page-28-1"></span>**Corollary 5.8.** *Let* f : G × G → C*, and* X *be a quasi-Ableian Cayley expander such that all non-trivial eigenvalues are* λ*. Then,*

$$
\mathcal{E}_X(f) = \lambda \cdot (P_G f(\vec{1}) - \mu(f)).
$$

*Proof.* We start by computing the Fourier coefficient of PGf.

$$
\widehat{P_G f}(\vec{\rho}) = \mathop{\mathbb{E}}_{\vec{y} \in G^n} [(P_G f)(\vec{y})\vec{\rho}(\vec{y})]
$$
\n
$$
= \mathop{\mathbb{E}}_{\vec{y} \in G^n} \left[ \mathop{\mathbb{E}}_{h \in G} \left[ f(h \cdot y) \vec{\rho}(\vec{y}) \right] \right]
$$
\n
$$
= \mathop{\mathbb{E}}_{h \in G} \left[ \mathop{\mathbb{E}}_{\vec{x} \in G^n} \left[ f(\vec{x}) \vec{\rho} (h^{-1} \vec{x}) \right] \right]
$$
\n
$$
= \mathop{\mathbb{E}}_{h \in G} \left[ \vec{\rho} (h^{-1}, \dots, h^{-1}) \mathop{\mathbb{E}}_{\vec{x} \in G^n} \left[ f(\vec{x}) \vec{\rho}(\vec{x}) \right] \right]
$$
\n
$$
= \mathop{\mathbb{E}}_{h} \left[ \vec{\rho}(h) \right] \hat{f}(\rho).
$$

Observe that if ρ® is trivial, then the Fourier coefficient is unchanged ie the mean of the function remains the same. If |®ρ| = 1, then, Eh[®ρ(h)] = 0. For level-2, we use [Corollary 3.9](#page-17-2) to say that Eh[α ⊗ α ∗ (h)] = M, and for β ≠ α, Eh[α ⊗ β(h)] = 0. Using the Fourier decomposition for the function PGf:

$$
P_{G}f(1,1) = \widehat{P_{G}f}(triv) + \sum_{\alpha} d_{\alpha \otimes \alpha} \langle \widehat{P_{G}f}(\alpha \otimes \alpha), \alpha \otimes \alpha^{*}(1,1) \rangle
$$
  
=  $\mu(f) + \sum_{\alpha} d_{\alpha \otimes \alpha} \langle \mathbb{E}[\alpha \otimes \alpha^{*}(h)] \widehat{f}(\alpha \otimes \alpha), \alpha \otimes \alpha^{*}(1,1) \rangle$ 

$$
P_{G}f(1,1) - \mu(f) = \sum_{\alpha} d_{\alpha \otimes \alpha} \left\{ \widehat{f}(\alpha \otimes \alpha), \mathbb{E}[\alpha \otimes \alpha^{*}(h)] \right\}
$$
 [M = M<sup>\*</sup>] (13)

$$
= \sum_{\alpha} d_{\alpha \otimes \alpha} \langle \widehat{f}(\alpha \otimes \alpha), \frac{1}{\lambda_{\alpha}} \mathcal{E}_X(\alpha \otimes \alpha^*) \rangle \qquad \qquad \text{[Corollary 3.9]}
$$

<span id="page-29-3"></span>(14)

$$
\lambda \big( P_G f(1,1) - \widehat{f}(triv) \big) \ = \ \mathcal{E}_X(f). \tag{ \lambda_{\alpha} = \lambda, \forall \alpha \}
$$

The last equation follows by the Fourier expression for EX(f) [\(Eq. \(11\)\)](#page-20-3) and by using [Claim 4.1](#page-19-2) to nly consider level-2 coefficients.

**Remark 5.9.** Another way to deduce the Fourier coefficient of PGf is to observe that this operator is a convolution, PGf = f ∗ 1<sup>D</sup> where 1<sup>D</sup> is the indicator of the diagonal subgroup i.e., 1D(®x) = |G| n−1 if x<sup>1</sup> = x<sup>2</sup> · · · = xn, and 0 otherwise.

# <span id="page-29-0"></span>**6 Lower Bounds for decay of Symmetric functions**

# <span id="page-29-1"></span>**6.1 Fourier Coefficient of Threshold Function**

**Threshold Function** Let, A ⊆ G and t ∈ [n]. We define a boolean function Th<sup>A</sup>,<sup>t</sup> as :

$$
Th_{A,t}(\vec{x}) = 1 \text{ if } |\{i \mid x_i \in A\}| \geq t; \text{ 0 otherwise.}
$$

This function will be our candidate for the lower bound for an appropriate choice of A, t to be decided later. We first compute the second-level Fourier coefficients that hold for any A, t. The level-k coefficients can be computed in the same way, but we will not require it and hence omit the calculation.

<span id="page-29-2"></span>**Claim 6.1.** *Let,* <sup>ρ</sup>® <sup>=</sup> <sup>ρ</sup><sup>1</sup> <sup>⊗</sup> <sup>ρ</sup><sup>2</sup> <sup>⊗</sup> . . . <sup>ρ</sup><sup>n</sup> <sup>∈</sup> <sup>G</sup>c<sup>n</sup> *such that* <sup>ρ</sup><sup>i</sup> <sup>=</sup> <sup>α</sup>, <sup>ρ</sup><sup>j</sup> <sup>=</sup> <sup>α</sup> ∗ *for some* <sup>α</sup> <sup>∈</sup> <sup>G</sup><sup>ˆ</sup> *and* 1 ⩽ i < j ⩽ n *and* ρ<sup>k</sup> = triv *for any* k ∉ {i, j}*. Then,*

$$
\widehat{\text{Th}_{\text{A},\text{t}}}(\vec{\rho}) = \left(\frac{\mathfrak{a}_{\text{t}-2}^{\mathfrak{n}-2} - \mathfrak{a}_{\text{t}-1}^{\mathfrak{n}-2}}{|G|^{\mathfrak{n}-2}}\right) \cdot \widehat{\text{I}_{\text{A}}}(\alpha) \otimes \widehat{\text{I}_{\text{A}}}(\alpha^*)
$$

*where* a n t := n t |A| t |A<sup>c</sup> | n−t *.*

*Proof.* For x® ∈ Gn, we will denote the tuple obtained be removing x<sup>i</sup> and x<sup>j</sup> as x®ij ∈ Gn−<sup>2</sup> .

$$
|G^{n}| \cdot \widehat{\text{Th}_{A,t}}(\vec{\rho}) = \sum_{\vec{x} \in G^{n}} \text{Th}_{A,t}(\vec{x}) \cdot \vec{\rho}(\vec{x})
$$
  
= 
$$
\sum_{\vec{x} \in G^{n}} \text{Th}_{A,t}(\vec{x}) \cdot \alpha(x_{i}) \otimes \alpha^{*}(x_{j})
$$
  
= 
$$
\sum_{x_{i} \in G, x_{j} \in G} \alpha(x_{i}) \otimes \alpha^{*}(x_{j}) \sum_{x_{ij}^{*} \in G^{n-2}} \text{Th}_{A,t}(\vec{x}).
$$

Now observe that if r = |{xi, xj} ∩ A| then, Th<sup>A</sup>,<sup>t</sup>x® = Th<sup>A</sup>,t−rx®ij. Moreover,

$$
\sum_{\vec{x_{ij}} \in G^{n-2}} \text{Th}_{A,t-r}(\vec{x}_{ij}) = \sum_{k=t-r}^{n-2} \alpha_k^{n-2} =: \alpha_{\geq t-r}^{n-2}.
$$

Hence, we have 3 possible cases corresponding to each r ∈ {0, 1, 2} and a total of four terms:

$$
|\widehat{G}^n|\cdot \widehat{Th_{A,t}}(\vec{\rho})\; =\; \sum_{r=0}^2 \mathfrak{a}_{\geqslant t-r}^{n-2} \sum_{|\{x_i,x_j\}\cap A|=r} (\alpha(x_i)\otimes \alpha^*(x_j)).
$$

We compute each of these now. Recall that P <sup>x</sup>∈<sup>A</sup> <sup>α</sup>(x) <sup>=</sup> <sup>|</sup>G| · <sup>1</sup>c<sup>A</sup>(α) <sup>=</sup> <sup>−</sup> P <sup>x</sup>∈A<sup>c</sup> <sup>α</sup>(x). Using this readily gives us,

$$
|\mathsf{G}^n| \cdot \widehat{\text{Th}_{\text{A},t}}(\vec{\rho}) \ = \ |\mathsf{G}|^2 \cdot \widehat{\text{IA}}(\alpha) \otimes \widehat{\text{IA}}(\alpha^*) \cdot \big[\mathsf{a}_{\geqslant \mathsf{t}-2}^{n-2} - 2 \cdot \mathsf{a}_{\geqslant \mathsf{t}-1}^{n-2} + \mathsf{a}_{\geqslant \mathsf{t}}^{n-2} \big].
$$

To finish the proof, we do the following computation,

$$
\begin{array}{ll} \alpha^{n-2}_{\geq t-2} - 2 \cdot \alpha^{n-2}_{\geq t-1} + \alpha^{n-2}_{\geq t} & = \left( \alpha^{n-2}_{\geq t-2} - \alpha^{n-2}_{\geq t-1} \right) - \left( \alpha^{n-2}_{\geq t-1} - \alpha^{n-2}_{\geq t} \right) \\ & = \left( \alpha^{n-2}_{t-2} \right) - \left( \alpha^{n-2}_{t-1} \right) \end{array}
$$

<span id="page-30-1"></span>**Proposition 6.2.** *If* |A| = |G| 2 *and* t = n+1− n 2 *, then*

$$
C_{A,n,t}:=\left(\frac{\mathfrak{a}_{t-1}^{n-2}-\mathfrak{a}_{t-2}^{n-2}}{|G|^{n-2}}\right) \,\geq\, \Omega\Big(\frac{1}{n-1}\Big).
$$

*Proof.* The proof is a simple calculation that we carry out below.

$$
C_{A,n,t} = \left(\frac{a_{t-1}^{n-2} - a_{t-2}^{n-2}}{|G|^{n-2}}\right)
$$
  
= 
$$
\left(\frac{\binom{n-2}{t-1}|A|^{t-1}|A^c|^{n-1-t} - \binom{n-2}{t-2}|A|^{t-2}|A^c|^{n-t}}{|G|^{n-2}}\right)
$$
  
= 
$$
\frac{1}{2^{n-2}}\left(\binom{n-2}{t-1} - \binom{n-2}{t-2}\right)
$$
  
= 
$$
\frac{1}{2^{n-2}}\frac{1}{n-1} \cdot \binom{n-1}{t-1} \cdot \frac{(n+1-2t)}{2}
$$
  
\$\geqslant \frac{1}{2^{n-2}}\frac{1}{n-1} \cdot \frac{\Omega(2^n)}{\sqrt{n}} \cdot \sqrt{n} \geqslant \Omega\left(\frac{1}{n-1}\right).

The last inequality follows from our choice of t = n+1− n 2 . for which, <sup>n</sup>−<sup>1</sup> t−1 = Ω( 2 n √ n ).

<span id="page-30-0"></span>**Claim 6.3** (Lower Bound on fooling level-2 component)**.** *Let* X *be a pseudo Cayley graph such that all non-trivial eigenvalues are equal to* λ < 1/2*. Let* A *be any subset of* G*. Then for the level-2 component of the threshold function, the following holds:*

$$
\big|\mathcal{E}_X\big((Th_{A,t})_2\big)\big| \ \geqslant \ (n-2)\cdot \lambda \cdot C_{A,n,t}\cdot \mu_A \cdot \mu_{A^c} \ .
$$

*Proof.* We will use the notation αij to mean the irrep, αij = ρ<sup>1</sup> ⊗ · · · ⊗ ρ<sup>n</sup> that is ρ<sup>i</sup> = α and ρ<sup>j</sup> = α ∗ , and the rest are trivial. Since X is a pseudo Cayley graph, we can apply, [Corollary 3.9,](#page-17-2) Thus, for any ρ® such that |®ρ| = 2 (i.e., a level-2 irrep), we have EX(®ρ) = M if ρ® = αij for any irrep α ∈ Irrep(G). Else, it is 0. Therefore,

$$
\mathcal{E}_{X}((\text{Th}_{A,t})_{2}) = \sum_{\vec{\rho} \in \text{Irrep}(G^{n}), |\vec{\rho}|=2} d_{\vec{\rho}} \cdot \left\langle \widehat{\text{Th}_{A,t}}(\vec{\rho}), \mathcal{E}_{X}(\vec{\rho}) \right\rangle_{HS}
$$
\n
$$
= \sum_{1 \leq i < j \leq n} \sum_{\text{triv} \neq \alpha \in \hat{G}} d_{\vec{\rho}} \cdot \left\langle \widehat{\text{Th}_{A,t}}(\alpha_{ij}), \mathcal{E}_{X}(\alpha_{ij}) \right\rangle_{HS} \qquad [\text{X is quasi-Abelian}]
$$
\n
$$
= \sum_{1 \leq i < j \leq n} \text{C}_{A,n,t} \cdot \lambda^{j-i} \cdot \sum_{\text{triv} \neq \alpha \in \hat{G}} d_{\alpha_{ij}} \left\langle \widehat{\text{In}_{A}}(\alpha) \otimes \widehat{\text{In}_{A}}(\alpha^{*}), \text{M} \right\rangle_{HS} \quad [\text{Using Claim 6.1}]
$$

For a fixed i, j, we can interpret the inner coefficent as the Fourier coefficient of 1A×<sup>A</sup> := 1{xi,xj∈A} : G × G → C. Thus, using [Corollary 5.8](#page-28-1) and [Eq. \(13\)](#page-29-3) , we get:

$$
\sum_{\text{triv} \neq \alpha \in \hat{G}} d_{\alpha_{ij}} \left\{ \widehat{\mathbb{1}_A}(\alpha) \otimes \widehat{\mathbb{1}_A}(\alpha^*), M \right\}_{HS} = P_G(\mathbb{1}_{A \times A})(1,1) - \mu(\mathbb{1}_{A \times A})
$$
$$
= \mathbb{E}[(g, g) \in A \times A] - \mu(A)^2
$$
$$
= \mu(A) - \mu(A)^2 = \mu_A \cdot \mu_{A^c}.
$$

Plugging this back in out expression we get,

$$
\mathcal{E}_{X}((\text{Th}_{A,t})_2) = \sum_{1 \leq i < j \leq n} C_{A,n,t} \cdot \lambda^{j-i} \cdot \mu_A \cdot \mu_{A^c}
$$
\n
$$
= C_{A,n,t} \cdot \mu_A \cdot \mu_{A^c} \cdot \lambda \cdot \left(n - \frac{1}{1 - \lambda}\right) \cdot \frac{1 - \lambda^n}{1 - \lambda}
$$
\n
$$
\left| \mathcal{E}_{X}\big((\text{Th}_{A,t})_2\big) \right| \geq C_{A,n,t} \cdot \mu_A \cdot \mu_{A^c} \cdot (n - 2) \cdot |\lambda| \quad \text{if } \lambda < 1/2.
$$

**Theorem 6.4.** *Let* <sup>G</sup> *be any finite group,* <sup>A</sup> <sup>⊆</sup> <sup>G</sup> *such that* <sup>|</sup>A<sup>|</sup> |G| = 1 2 *, and* X = Cay(G<sup>r</sup> , G<sup>r</sup> \ {1}) *be the complete graph on* G<sup>r</sup> *without self-loops for some* r ⩾ 4*. Then for every* n *large enough,*

$$
\left|\mathcal{E}_X\Big(\text{Th}_{A,\frac{n+1-\sqrt{n}}{2}}\Big)\right| \geqslant \Omega\big(\lambda(X)\big).
$$

*Proof.* Using [Claim 4.1](#page-19-2) we can separate the calculation into fooling the level-2 function and those beyond it, and thus for any function we have:

$$
\mathcal{E}_X(f) = \sum_{i=2}^n \mathcal{E}_X(f),
$$
  
$$
|\mathcal{E}_X(f)| \ge |\mathcal{E}_X(f_2)| - \left| \sum_{k=3}^n \mathcal{E}_X(f_k) \right|.
$$

We now let f be the threshold function, f = Th A, n+1− √ n 2 . The graph X has all non-trivial eigenvalues to be equal to <sup>−</sup><sup>1</sup> |G| <sup>r</sup> < 1/2. We can then apply [Claim 6.3,](#page-30-0) which when combined with [Proposition 6.2,](#page-30-1) we get <sup>E</sup>X(f2) <sup>⩾</sup> <sup>Ω</sup>(λ). To bound the remaining part, we use our upper bound [Theorem 4.5](#page-21-0) and obtain that,

$$
\Bigl|\sum_{i=3}^n\mathcal{E}_X(f_i)\Bigr|\ \leqslant\ 2(16e|G|\lambda)^{\frac{3}{2}}\cdot\|f\|_2\ \leqslant\ \mathbf{o}\Bigl(\lambda^{\frac{3(r-1)}{2r}}\Bigr)=\mathbf{o}(\lambda). \qquad \blacksquare
$$

# **References**

- <span id="page-32-3"></span>[AKS87] M. Ajtai, J. Komlos, and E. Szemeredi. Deterministic simulation in LOGSPACE. In *Proceedings of the 19th ACM Symposium on Theory of Computing*, 1987. [doi:](https://doi.org/10.1145/28395.28410) [10.1145/28395.28410](https://doi.org/10.1145/28395.28410). [1](#page-0-0)
- <span id="page-32-7"></span>[Bar89] David A. Mix Barrington. Bounded-Width Polynomial-Size Branching Programs Recognize Exactly Those Languages in NC<sup>1</sup> . *J. Comput. Syst. Sci.*, 38(1), 1989. [doi:10.1016/0022-0000\(89\)90037-8](https://doi.org/10.1016/0022-0000(89)90037-8). [2](#page-1-0)
- <span id="page-32-5"></span>[CMP+22] Gil Cohen, Dor Minzer, Shir Peleg, Aaron Potechin, and Amnon Ta-Shma. Expander Random Walks: The General Case and Limitations. In *Proceedings of the 49th International Colloquium on Automata, Languages and Programming*, 2022. [doi:10.4230/LIPIcs.ICALP.2022.43](https://doi.org/10.4230/LIPIcs.ICALP.2022.43). [1,](#page-0-0) [6](#page-7-3)
- <span id="page-32-4"></span>[CPTS21] Gil Cohen, Noam Peri, and Amnon Ta-Shma. Expander Random Walks: A Fourier-Analytic Approach. In *Proceedings of the 53nd ACM Symposium on Theory of Computing*, 2021. [doi:10.1145/3406325.3451049](https://doi.org/10.1145/3406325.3451049). [1,](#page-0-0) [2,](#page-1-0) [3,](#page-4-4) [8,](#page-9-2) [11,](#page-12-3) [14,](#page-15-3) [20](#page-21-2)
- <span id="page-32-8"></span>[De11] Anindya De. Pseudorandomness for Permutation and Regular Branching Programs. In *Proceedings of the 26th IEEE Conference on Computational Complexity*, 2011. [doi:10.1109/CCC.2011.23](https://doi.org/10.1109/CCC.2011.23). [4](#page-5-3)
- <span id="page-32-0"></span>[Gil52] E.N. Gilbert. A Comparison of Signalling Alphabets. *Bell System Technical Journal*, 31:504–522, 1952. [doi:10.1002/j.1538-7305.1952.tb01393.x](https://doi.org/10.1002/j.1538-7305.1952.tb01393.x). [1](#page-0-0)
- <span id="page-32-1"></span>[Gil93] D. Gillman. A Chernoff Bound for Random Walks on Expander Graphs. In *focs93*, pages 680–691, 1993. [doi:10.1109/SFCS.1993.366819](https://doi.org/10.1109/SFCS.1993.366819). [1](#page-0-0)
- <span id="page-32-2"></span>[GLSS18] Ankit Garg, Yin Tat Lee, Zhao Song, and Nikhil Srivastava. A matrix expander Chernoff bound. In *Proceedings of the 50th ACM Symposium on Theory of Computing*, 2018. [doi:10.1145/3188745.3188890](https://doi.org/10.1145/3188745.3188890). [1](#page-0-0)
- <span id="page-32-6"></span>[Gol23] Louis Golowich. A New Berry-Esseen Theorem for Expander Walks. In *Proceedings of the 55nd ACM Symposium on Theory of Computing*, 2023. [doi:](https://doi.org/10.1145/3564246.3585141) [10.1145/3564246.3585141](https://doi.org/10.1145/3564246.3585141). [1](#page-0-0)
- <span id="page-32-9"></span>[Gow08] W. T. Gowers. Quasirandom groups. *Comb. Probab. Comput.*, 2008. [doi:10.](https://doi.org/10.1017/S0963548307008826) [1017/S0963548307008826](https://doi.org/10.1017/S0963548307008826). [5](#page-6-2)

- <span id="page-33-6"></span>[GV22] Louis Golowich and Salil Vadhan. Pseudorandomness of Expander Random Walks for Symmetric Functions and Permutation Branching Programs. In *Proceedings of the 37th IEEE Conference on Computational Complexity*, 2022. [doi:10.4230/LIPIcs.CCC.2022.27](https://doi.org/10.4230/LIPIcs.CCC.2022.27). [1,](#page-0-0) [4,](#page-5-3) [19](#page-20-4)
- <span id="page-33-5"></span>[HH24] Pooya Hatami and William Hoza. Paradigms for Unconditional Pseudorandom Generators. *Found. Trends Theor. Comput. Sci.*, 16(1-2), 2024. [doi:10.1561/](https://doi.org/10.1561/0400000109) [0400000109](https://doi.org/10.1561/0400000109). [1](#page-0-0)
- <span id="page-33-0"></span>[HLW06] Shlomo Hoory, Nathan Linial, and Avi Wigderson. Expander Graphs and Their Applications. *Bull. Amer. Math. Soc.*, 43(04):439–562, aug 2006. [1](#page-0-0)
- <span id="page-33-4"></span>[INW94] Russell Impagliazzo, Noam Nisan, and Avi Wigderson. Pseudorandomness for network algorithms. In *Proceedings of the 26th ACM Symposium on Theory of Computing*, 1994. [doi:10.1145/195058.195190](https://doi.org/10.1145/195058.195190). [1](#page-0-0)
- <span id="page-33-7"></span>[JMRW22] Fernando Granha Jeronimo, Tushant Mittal, Sourya Roy, and Avi Wigderson. Almost Ramanujan Expanders from Arbitrary Expanders via Operator Amplification. In *Proceedings of the 63st IEEE Symposium on Foundations of Computer Science*, 2022. [doi:10.1109/FOCS54457.2022.00043](https://doi.org/10.1109/FOCS54457.2022.00043). [2,](#page-1-0) [3,](#page-4-4) [7,](#page-8-0) [23](#page-24-3)
- <span id="page-33-3"></span>[JMST25] Fernando Granha Jeronimo, Tushant Mittal, Shashank Srivastava, and Madhur Tulsiani. Explicit Codes approaching Generalized Singleton Bound using Expanders. 2025. [doi:10.48550/arXiv.2502.07308](https://doi.org/10.48550/arXiv.2502.07308). [1](#page-0-0)
- <span id="page-33-1"></span>[Lub94] Alexander Lubotzky. *Discrete Groups, Expanding Graphs and Invariant Measures*, volume 125 of *Progress in mathematics*. Birkhäuser, 1994. [1](#page-0-0)
- <span id="page-33-9"></span>[MZ09] Raghu Meka and David Zuckerman. Small-Bias Spaces for Group Products. In *APPROX-RANDOM 2009 Proceedings*, 2009. [doi:10.1007/](https://doi.org/10.1007/978-3-642-03685-9_49) [978-3-642-03685-9\\_49](https://doi.org/10.1007/978-3-642-03685-9_49). [4](#page-5-3)
- <span id="page-33-11"></span>[RKHS02] Dan Rockmore, Peter Kostelec, Wim Hordijk, and Peter F. Stadler. Fast Fourier Transform for Fitness Landscapes. *Applied and Computational Harmonic Analysis*, 12(1):57–76, jan 2002. [doi:10.1006/acha.2001.0346](https://doi.org/10.1006/acha.2001.0346). [15](#page-16-5)
- <span id="page-33-2"></span>[Rot22] Ron M. Roth. Higher-Order MDS Codes. *IEEE Transactions on Information Theory*, 68(12):7798–7816, 2022. [doi:10.1109/TIT.2022.3194521](https://doi.org/10.1109/TIT.2022.3194521). [1](#page-0-0)
- <span id="page-33-10"></span>[RR23] Silas Richelson and Sourya Roy. Gilbert and Varshamov Meet Johnson: List-Decoding Explicit Nearly-Optimal Binary Codes. In *Proceedings of the 64st IEEE Symposium on Foundations of Computer Science*, 2023. [doi:10.1109/](https://doi.org/10.1109/FOCS57990.2023.00021) [FOCS57990.2023.00021](https://doi.org/10.1109/FOCS57990.2023.00021). [6](#page-7-3)
- <span id="page-33-8"></span>[RR24] Silas Richelson and Sourya Roy. Analyzing Ta-Shma's Code via the Expander Mixing Lemma. *IEEE Trans. Inf. Theory*, 70(2):1040–1049, 2024. [doi:10.1109/](https://doi.org/10.1109/TIT.2023.3304614) [TIT.2023.3304614](https://doi.org/10.1109/TIT.2023.3304614). [2,](#page-1-0) [6,](#page-7-3) [7,](#page-8-0) [12](#page-13-2)

- <span id="page-34-5"></span>[Ser77] Jean-Pierre Serre. *Linear Representations of Finite Groups*, volume 42 of *Graduate Texts in Mathematics*. Springer New York, 1977. [10](#page-11-5)
- <span id="page-34-3"></span>[ST20] Chong Shangguan and Itzhak Tamo. Combinatorial list-decoding of Reed-Solomon codes beyond the Johnson radius. In *Proceedings of the 52nd ACM Symposium on Theory of Computing*, 2020. [doi:10.1145/3357713.3384295](https://doi.org/10.1145/3357713.3384295). [1](#page-0-0)
- <span id="page-34-2"></span>[TS17] Amnon Ta-Shma. Explicit, Almost Optimal, Epsilon-balanced Codes. In *Proceedings of the 49th ACM Symposium on Theory of Computing*, pages 238–251. ACM, 2017. [doi:10.1145/3055399.3055408](https://doi.org/10.1145/3055399.3055408). [1,](#page-0-0) [3,](#page-4-4) [7](#page-8-0)
- <span id="page-34-4"></span>[TSZ24] Amnon Ta-Shma and Ron Zadicario. The Expander Hitting Property When the Sets Are Arbitrarily Unbalanced. In *Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM 2024)*, 2024. [doi:10.4230/LIPIcs.APPROX/RANDOM.2024.31](https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.31). [1](#page-0-0)
- <span id="page-34-0"></span>[Vad12] Salil P. Vadhan. *Pseudorandomness*. Now Publishers Inc., 2012. [doi:10.1561/](https://doi.org/10.1561/0400000010) [0400000010](https://doi.org/10.1561/0400000010). [1](#page-0-0)
- <span id="page-34-1"></span>[Var57] R.R. Varshamov. Estimate of the number of signals in error correcting codes. *Doklady Akademii Nauk SSSR*, 117:739–741, 1957. [1](#page-0-0)